{"0": {
    "doc": "Add a private constructor to hide the implicit public one",
    "title": "problem",
    "content": "Utility classes should not have public constructors . 유틸리티 클래스는 public 생성자를 갖고 있으면 안된다. Utility classes, which are collections of static members, are not meant to be instantiated. Even abstract utility classes, which can be extended, should not have public constructors. static 멤버만 갖고 있는 클래스를 유틸리티 클래스로 보고, (추상화된 클래스더라도) public 생성자를 갖고 있으면 안된다. Java adds an implicit public constructor to every class which does not define at least one explicitly. Hence, at least one non-public constructor should be defined. 자바는 모든 클래스에 public 생성자를 갖고 있다. (선언하지 않아도) . 그러므로 적어도 public하지 않은 생성자를 한개는 정의해야함. [잘못된 코드] . class StringUtils { // Noncompliant public static String concatenate(String s1, String s2) { return s1 + s2; } } . [옳은 코드] . class StringUtils { // Compliant private StringUtils() { throw new IllegalStateException(\"Utility class\"); } public static String concatenate(String s1, String s2) { return s1 + s2; } } . [이 rule의 예외] . | 클래스에 main 메소드가 포함되어있으면 유틸리티 클래스라고 보지 않고, 이 규칙 적용에 제외됨. | . 문제가 되었던 코드에는 static 메소드 한개만 존재했음 . public class JsonParseUtil { public static getJson() { } } . ",
    "url": "http://localhost:4000/docs/quality/sonarqube/S1118/#problem",
    "relUrl": "/docs/quality/sonarqube/S1118/#problem"
  },"1": {
    "doc": "Add a private constructor to hide the implicit public one",
    "title": "solve",
    "content": "@NoArgsConstructor(access = AccessLevel.PRIVATE) // 파라미터없는 기본생성자를 생성 public class JsonParseUtil { public static getJson() { } } . ",
    "url": "http://localhost:4000/docs/quality/sonarqube/S1118/#solve",
    "relUrl": "/docs/quality/sonarqube/S1118/#solve"
  },"2": {
    "doc": "Add a private constructor to hide the implicit public one",
    "title": "Add a private constructor to hide the implicit public one",
    "content": " ",
    "url": "http://localhost:4000/docs/quality/sonarqube/S1118/",
    "relUrl": "/docs/quality/sonarqube/S1118/"
  },"3": {
    "doc": "Synchronized classes Vector, Hashtable, Stack and StringBuffer should not be used",
    "title": "Synchronized classes Vector, Hashtable, Stack and StringBuffer should not be used.",
    "content": "[원인] . java:s1149 룰에 대한 것으로 . 여기에 위반되는 이유는 static 메소드나 클래스에 StringBuilder가 아닌 StringBuffer등 멀티쓰레드에 적합한 API를 사용했기 떄문이다. [해결] . 나 같은 경우는 StringBuilder로 변경. [참고] . https://stackoverflow.com/questions/16672730/which-class-to-use-for-this-static-method-stringbuffer-or-stringbuilder . ",
    "url": "http://localhost:4000/docs/quality/sonarqube/S1149/#synchronized-classes-vector-hashtable-stack-and-stringbuffer-should-not-be-used",
    "relUrl": "/docs/quality/sonarqube/S1149/#synchronized-classes-vector-hashtable-stack-and-stringbuffer-should-not-be-used"
  },"4": {
    "doc": "Synchronized classes Vector, Hashtable, Stack and StringBuffer should not be used",
    "title": "Synchronized classes Vector, Hashtable, Stack and StringBuffer should not be used",
    "content": " ",
    "url": "http://localhost:4000/docs/quality/sonarqube/S1149/",
    "relUrl": "/docs/quality/sonarqube/S1149/"
  },"5": {
    "doc": "Convert the abstract class \"TemplateContentHandler\" into an interface",
    "title": "Convert the abstract class “TemplateContentHandler” into an interface.",
    "content": "Abstract classes without fields should be converted to interfaces. 필드가 없는 추상화 클래스는 인터페이스로 되어야한다. With Java 8’s “default method” feature, any abstract class without direct or inherited field should be converted into an interface. However, this change may not be appropriate in libraries or other applications where the class is intended to be used as an API. java8에서 제공하는 “default method” 기능으로, 어떤 추상화 클래스든 인터페이스로 바뀔수 있다. 그러나 이렇게 변경하는게 API로 제공된 어플리케이션이나 라이브러리인 경우는 맞지 않을 수 있다. (반드시 적용하는 룰은 아님) . Note that this rule is automatically disabled when the project’s sonar.java.source is lower than 8. ‘sonar.java.source’가 8보다 낮으면, 이 규칙은 자동적으로 disable상태 . [잘못된 코드] . public abstract class Car { public abstract void start(Environment c); public void stop(Environment c) { c.freeze(this); } } . [맞는 코드] . public interface Car { public void start(Environment c); public default void stop(Environment c) { c.freeze(this); } } . ",
    "url": "http://localhost:4000/docs/quality/sonarqube/S1610/#convert-the-abstract-class-templatecontenthandler-into-an-interface",
    "relUrl": "/docs/quality/sonarqube/S1610/#convert-the-abstract-class-templatecontenthandler-into-an-interface"
  },"6": {
    "doc": "Convert the abstract class \"TemplateContentHandler\" into an interface",
    "title": "Convert the abstract class \"TemplateContentHandler\" into an interface",
    "content": " ",
    "url": "http://localhost:4000/docs/quality/sonarqube/S1610/",
    "relUrl": "/docs/quality/sonarqube/S1610/"
  },"7": {
    "doc": "A \"NullPointerException\" could be thrown; \"getListenerContainer()\" can return null.",
    "title": "problem",
    "content": ". | java:S2259 | . private final KafkaListenerEndpointRegistry registry; public void register() { try { registry.getListenerContainer(LicenseEventSubscriber.ID).start(); } catch (Exception e) { log.error(\"registry load failed.\", e); } } . | 서비스가 올라가면 kafka listener에 해당 이벤트 수신을 등록하려는 코드인데, spring boot 버전을 2.7로 올리고 나서 갑자기 sonarqube에서 버그로 잡혔다. | . ",
    "url": "http://localhost:4000/docs/quality/sonarqube/S2259/#problem",
    "relUrl": "/docs/quality/sonarqube/S2259/#problem"
  },"8": {
    "doc": "A \"NullPointerException\" could be thrown; \"getListenerContainer()\" can return null.",
    "title": "cause",
    "content": "sonarqube 설명을 보면 . [Null pointers should not be dereferenced] A reference to null should never be dereferenced/accessed. Doing so will cause a NullPointerException to be thrown. At best, such an exception will cause abrupt program termination. At worst, it could expose debugging information that would be useful to an attacker, or it could allow an attacker to bypass security measures. Note that when they are present, this rule takes advantage of @CheckForNull and @Nonnull annotations defined in JSR-305 to understand which values are and are not nullable except when @Nonnull is used on the parameter to equals, which by contract should always work with null. | registry가 null이 될 수 있는데, null을 참조하거나 액서스하면 안된다는 뜻인 것 같다. | . ",
    "url": "http://localhost:4000/docs/quality/sonarqube/S2259/#cause",
    "relUrl": "/docs/quality/sonarqube/S2259/#cause"
  },"9": {
    "doc": "A \"NullPointerException\" could be thrown; \"getListenerContainer()\" can return null.",
    "title": "solve",
    "content": ". | 실제로 null이 될 가능성이 없다면, surpress를 주거나, fixed 처리를 하면 되고 | 만약에 method파라미터라면 @NotNull annotation을 줘서 처리할 수 있다. | . ",
    "url": "http://localhost:4000/docs/quality/sonarqube/S2259/#solve",
    "relUrl": "/docs/quality/sonarqube/S2259/#solve"
  },"10": {
    "doc": "A \"NullPointerException\" could be thrown; \"getListenerContainer()\" can return null.",
    "title": "reference",
    "content": "A “NullPointerException” could be thrown; “context” is nullable here . ",
    "url": "http://localhost:4000/docs/quality/sonarqube/S2259/#reference",
    "relUrl": "/docs/quality/sonarqube/S2259/#reference"
  },"11": {
    "doc": "A \"NullPointerException\" could be thrown; \"getListenerContainer()\" can return null.",
    "title": "A \"NullPointerException\" could be thrown; \"getListenerContainer()\" can return null.",
    "content": " ",
    "url": "http://localhost:4000/docs/quality/sonarqube/S2259/",
    "relUrl": "/docs/quality/sonarqube/S2259/"
  },"12": {
    "doc": "An 'int' is expected rather than a Object.",
    "title": "cause",
    "content": "**Printf-style format strings should not lead to unexpected behavior at runtime** . Because printf -style format strings are interpreted at runtime, rather than validated by the Java compiler, they can contain errors that lead to unexpected behavior or runtime errors. This rule statically validates the good behavior of printf -style formats when calling the format(...)  methods of java.util.Formatter , java.lang.String , java.io.PrintStream , MessageFormat , and java.io.PrintWriter  classes and the printf(...)  methods of java.io.PrintStream  or java.io.PrintWriter  classes. ",
    "url": "http://localhost:4000/docs/quality/sonarqube/S2275/#cause",
    "relUrl": "/docs/quality/sonarqube/S2275/#cause"
  },"13": {
    "doc": "An 'int' is expected rather than a Object.",
    "title": "code",
    "content": "private String parsingAppUserId(Object appUserId) { try { return String.format(\"%d\", appUserId); } catch(Exception e) { return StringUtils.EMPTY; } return StringUtils.EMPTY; } . int로 변환하는 포맷인데 Object타입으로 받아서 발생한 것 . ",
    "url": "http://localhost:4000/docs/quality/sonarqube/S2275/#code",
    "relUrl": "/docs/quality/sonarqube/S2275/#code"
  },"14": {
    "doc": "An 'int' is expected rather than a Object.",
    "title": "solution",
    "content": "int로 변환함 . private String parsingAppUserId(Object appUserId) { try { return String.format(\"%d\", Integer.valueOf((String) appUserId)); } catch(Exception e) { return StringUtils.EMPTY; } return StringUtils.EMPTY; } . ",
    "url": "http://localhost:4000/docs/quality/sonarqube/S2275/#solution",
    "relUrl": "/docs/quality/sonarqube/S2275/#solution"
  },"15": {
    "doc": "An 'int' is expected rather than a Object.",
    "title": "An 'int' is expected rather than a Object.",
    "content": " ",
    "url": "http://localhost:4000/docs/quality/sonarqube/S2275/",
    "relUrl": "/docs/quality/sonarqube/S2275/"
  },"16": {
    "doc": "Source files should not have any duplicated blocks",
    "title": "Source files should not have any duplicated blocks",
    "content": " ",
    "url": "http://localhost:4000/docs/quality/sonarqube/S2440/",
    "relUrl": "/docs/quality/sonarqube/S2440/"
  },"17": {
    "doc": "Source files should not have any duplicated blocks",
    "title": "1 duplicated blocks of code must be removed.",
    "content": "[원인] . block자체가 중복되는 코드들이 존재할 때 발생 . 의존성이 없는 컴포넌트였지만, 한개의 서비스안에 위치했기 때문에 발생 . [해결] . 중복되는 파일 중 한개를 열어서 왼쪽 회색 부분에 마우스 오버하면 duplicated된 block을 확인할 수 있다. 해결 방법은 여러가지가 되겠지만, 중복적인 코드가 필요한 이유 파악하고 제거 또는 대체를 하면 된다. ",
    "url": "http://localhost:4000/docs/quality/sonarqube/S2440/#1-duplicated-blocks-of-code-must-be-removed",
    "relUrl": "/docs/quality/sonarqube/S2440/#1-duplicated-blocks-of-code-must-be-removed"
  },"18": {
    "doc": "Refactor this method to reduce its Cognitive Complexity from 20 to the 15 allowed",
    "title": "Refactor this method to reduce its Cognitive Complexity from 20 to the 15 allowed.",
    "content": "try { String conversationId = kakaoMessageFlowService.open(kakaoMessage.getKakaoUser().getSenderKey()); if (StringUtils.isNotEmpty(conversationId)) { activeKakaoFlowService.register(activeKakaoKey, kakaoMessage.toConversationDomain(conversationId)); } } catch (Exception e) { if (e instanceof DataIntegrityViolationException || e instanceof ResourceAlreadyExistsException) { for (int i = 0; i &lt; 3; i++) { log.warn(\"ActiveKakao DuplicateKeyException occurred. - retrying..\" + activeKakaoKey); Optional&lt;KakaoRdo&gt; kakaoRdo = findAllByUserStatus(kakaoMessage.getKakaoUser()); if (kakaoRdo.isPresent()) { break; } try { Thread.sleep(500L); } catch (Exception ex) { log.error(ExceptionUtils.getStackTrace(e)); } } } else { try { activeKakaoFlowService.remove(activeKakaoKey); } catch (Exception ex) { log.warn(e.getMessage()); } } } . 문제 : 인지 복잡도가 높아서 문제 (빨간색 block된 부분) - 총 20개의 복잡도 발생한 코드 . 해결: instanceof로 익셉션 구분한 부분을 catch로 올림 . } catch (DataIntegrityViolationException | ResourceAlreadyExistsException e) { } catch (Exception ex) { } . ",
    "url": "http://localhost:4000/docs/quality/sonarqube/S3776/#refactor-this-method-to-reduce-its-cognitive-complexity-from-20-to-the-15-allowed",
    "relUrl": "/docs/quality/sonarqube/S3776/#refactor-this-method-to-reduce-its-cognitive-complexity-from-20-to-the-15-allowed"
  },"19": {
    "doc": "Refactor this method to reduce its Cognitive Complexity from 20 to the 15 allowed",
    "title": "Refactor this method to reduce its Cognitive Complexity from 20 to the 15 allowed",
    "content": " ",
    "url": "http://localhost:4000/docs/quality/sonarqube/S3776/",
    "relUrl": "/docs/quality/sonarqube/S3776/"
  },"20": {
    "doc": "Alarm Bot",
    "title": "게시물 업데이트 알람 봇 만들기",
    "content": ":: 요구사항 . | 카카오 비지니스API 공지사항 중 신규 게시물이 등록되면 슬랙DM으로 전송 | . :: 개발항목 . | 일배치 체크 | python slack 라이브러리 이용 | . ",
    "url": "http://localhost:4000/docs/sub-projects/alarm_bot/#%EA%B2%8C%EC%8B%9C%EB%AC%BC-%EC%97%85%EB%8D%B0%EC%9D%B4%ED%8A%B8-%EC%95%8C%EB%9E%8C-%EB%B4%87-%EB%A7%8C%EB%93%A4%EA%B8%B0",
    "relUrl": "/docs/sub-projects/alarm_bot/#게시물-업데이트-알람-봇-만들기"
  },"21": {
    "doc": "Alarm Bot",
    "title": "Alarm Bot",
    "content": " ",
    "url": "http://localhost:4000/docs/sub-projects/alarm_bot/",
    "relUrl": "/docs/sub-projects/alarm_bot/"
  },"22": {
    "doc": "BrowserMatch",
    "title": "BrowserMatch",
    "content": "기본 아파치를 윈도우에 설치하고 나니 httpd-ssl.conf에 . 아래 설정이 있었다. BrowserMatch “.MSIE.” \\nokeepalive ssl-unclean-shutdown \\downgrade-1.0 force-response-1.0 . 콘솔에 로그인해서 상담하기까지 활성화하는데 1분이나 걸리게 되어서 . 주석을 하고 재시작하니, 엄청 빨라짐. 파악해본결과 이 블로그에서 (http://blogs.msdn.com/b/ieinternals/archive/2011/03/26/https-and-connection-close-is-your-apache-modssl-server-configuration-set-to-slow.aspx) . Four years ago, there was apublic callto update the guidance to reflect the fact that users of more modern browsers were paying an unneeded performance penalty. Finally, in June 2010, the default guidance was changed in recognition of the fact that the problem never affected IE6 and later: . BrowserMatch “.MSIE [1-5].” \\nokeepalive ssl-unclean-shutdown \\downgrade-1.0 force-response-1.0 . Unfortunately, many major Apache installations still haven’t been updated with even this guidance. Also, alert readers will spot a very obvious problem with the “new” regular expression. In the expression above, any IE version that starts with“1” will be treated as outdated and served connection slowly without Keep-Alive. Internet Explorer 1.0 didn’t even support SSL at all (SSL was added in 2.0), but worse, this loosely-written regular expression will also matchfutureMSIE 10.0,MSIE 11.0,MSIE 12.0(etc)**user-agent strings. Hence, Apache hosts will one day find that thenewestbrowsers are forced into the “slow” lane! . At the very least, Apache hosts should update their regular expression to this: . BrowserMatch “.MSIE [2-5]..” \\nokeepalive ssl-unclean-shutdown \\downgrade-1.0 force-response-1.0 . …but ultimately, they should probably remove this hack altogether. The ancient Internet Explorer 6’s marketshare is in decline, and there’s almost never any business reason to try to accommodate even older browsers. 요약하면 삭제해야할 설정인데 아파치에서 아직도 껴서 배포하고 있다는 것.. 원래 BrowserMatch로 사용할 수 있는 유요한 설정은 특정 버전의 브라우저에 문제가 있어서 아래처럼 분기하고자 할때 쓴다. (http://webdir.tistory.com/178) . BrowserMatch “Mozilla/2” nokeepalive . BrowserMatch “MSIE 4.0b2;” nokeepalive downgrade-1.0 force-response-1.0 . BrowserMatch “RealPlayer 4.0” force-response-1.0 . BrowserMatch “Java/1.0” force-response-1.0 . BrowserMatch “JDK/1.0” force-response-1.0 . BrowserMatch 지시자는 특정 브라우저들에 대한 특정 수행을 지시하기 위한 설정들이다. | 첫번째 것은 네스케이프 2.x 또는 그를 흉내내는 브라우저에 대하여 KeepAlive 기능을 쓰지 않도록 한다. 이 브라우저들은 KeepAlive 구현에 문제점을 갖고 있기 때문이다. | 두번째 것은 HTTP/1.1을 잘못 구현하였고 301 또는 302 (redirect)반응에 대하여 KeepAlive를 제대로 지원하지 못하는 마이크로소프트 인터넷 익스플로러 4.0b2를 위한 것이다. | 세번째 것은 네번째 다섯번째 것들은 기본적인 1.1 반응도 제대로 처리하지 못함으로써 HTTP/1.1 스펙을 위반하고 있는 브라우저에 대하여 HTTP/1.1 반응을 하여 하지 않도록 한다. | . BrowserMatch “Microsoft Data Access Internet Publishing Provider” redirect-carefully . BrowserMatch “MS FrontPage” redirect-carefully . BrowserMatch “^WebDrive” redirect-carefully . BrowserMatch “^WebDAVFS/1.[0123]” redirect-carefully . BrowserMatch “^gnome-vfs/1.0” redirect-carefully . BrowserMatch “^XML Spy” redirect-carefully . BrowserMatch “^Dreamweaver-WebDAV-SCM1” redirect-carefully . 위 지시자들도 구현에 문제가 있는 것들에 대한 처리방식을 지정한 것이다. ",
    "url": "http://localhost:4000/docs/errors/apache1/",
    "relUrl": "/docs/errors/apache1/"
  },"23": {
    "doc": "실전 아파치 카프카",
    "title": "실전 아파치 카프카",
    "content": " ",
    "url": "http://localhost:4000/docs/clipping/msa/apachekafka/",
    "relUrl": "/docs/clipping/msa/apachekafka/"
  },"24": {
    "doc": "Api",
    "title": "Api",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/api/api/",
    "relUrl": "/docs/msa/api/api/"
  },"25": {
    "doc": "asciidoc conditional tag using",
    "title": "problem",
    "content": "사내에서 api doc으로 asciidoc을 쓰고 있는데요. 일부 api들은 파라미터 정보나 보안요건 등을 기술하고 있고, 일부 api들은 헤더정보등이 표시되어야 하는 등 . include되는 adoc파일의 그룹핑? 이 필요했습니다. ",
    "url": "http://localhost:4000/docs/msa/api/asciidoc_conditional_tag_using/#problem",
    "relUrl": "/docs/msa/api/asciidoc_conditional_tag_using/#problem"
  },"26": {
    "doc": "asciidoc conditional tag using",
    "title": "try",
    "content": "검색해보니 별도로 함수를 만들지 않는 한, 불가능해 보였는데요 . tag기능을 쓰면 될 듯해서 적용해봤습니다. [api.adoc] . === findAll Center 목록을 가져오는 API 입니다. :class-path: {snippets}/CenterResourceTest :api-name: findAll :tag: permissions include::{include-template-dir}/include-template.adoc[] . [include-template.adoc] . ifeval::[{tags} == \"permissions\"] include::{class-path}/{api-name}/required-permissions.adoc[leveloffset=+1,opts=optional] endif::[] include::{class-path}/{api-name}/curl-request.adoc[leveloffset=+1,opts=optional] include::{class-path}/{api-name}/http-request.adoc[leveloffset=+1,opts=optional] ifeval::[{tag} == \"headers\"] include::{class-path}/{api-name}/request-headers.adoc[leveloffset=+1,opts=optional] endif::[] . ",
    "url": "http://localhost:4000/docs/msa/api/asciidoc_conditional_tag_using/#try",
    "relUrl": "/docs/msa/api/asciidoc_conditional_tag_using/#try"
  },"27": {
    "doc": "asciidoc conditional tag using",
    "title": "reference",
    "content": "AsciiDoc - Conditionals . AsciiDoc - Include Content by Tagged Regions . ",
    "url": "http://localhost:4000/docs/msa/api/asciidoc_conditional_tag_using/#reference",
    "relUrl": "/docs/msa/api/asciidoc_conditional_tag_using/#reference"
  },"28": {
    "doc": "asciidoc conditional tag using",
    "title": "asciidoc conditional tag using",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/api/asciidoc_conditional_tag_using/",
    "relUrl": "/docs/msa/api/asciidoc_conditional_tag_using/"
  },"29": {
    "doc": "asciidoctor multiple pages from a single page",
    "title": "asciidoctor multiple pages from a single page",
    "content": "check asciidoctor extension . 먼저 extension이 있는지 체크했다. https://asciidoctor.org/docs/extensions/ . exist asciidoctor-multipage plugin . asciidoctor-multipage . exampe page: https://owenh.net/static/portfolio/nxlog/guide/nxlog-user-guide.html . but ruby base. asciidoctor multipage maver example . So, I made a maven version project. https://github.com/tnfhrnsss/asciidoctor-multipage-maven-example . maven clean install . 하면, . 기존에는 index.html 페이지 한개로 렌더링되던 부분이 . 각각의 페이지로 구성 . reference . https://discuss.asciidoctor.org/Using-the-multi-page-converter-from-maven-td8549.html . https://rubygems.org/gems/asciidoctor-multipage . https://github.com/asciidoctor/asciidoctor-maven-examples에서 revealjs가 maven-gem구성 . ",
    "url": "http://localhost:4000/docs/msa/api/asciidoctor_multipage/",
    "relUrl": "/docs/msa/api/asciidoctor_multipage/"
  },"30": {
    "doc": "Error attempting to apply AttributeConverter",
    "title": "Error attempting to apply AttributeConverter; nested exception is javax.persistence.PersistenceException: Error attempting to apply AttributeConverter",
    "content": "error . 10:40:52.851 40-exec-10 INFO r.m.e.DevModeRestMessage: 19 process rest message is for development mode 10:40:52.852 40-exec-10 ERROR .ExceptionHandlerManager: 34 handleResponse [status] 500 INTERNAL_SERVER_ERROR, [code]: 500999, [message] Unexpected error occurred., [detail message] Error attempting to apply AttributeConverter; nested exception is javax.persistence.PersistenceException: Error attempting to apply AttributeConverter, org.springframework.orm.jpa.JpaSystemException: Error attempting to apply AttributeConverter; nested exception is javax.persistence.PersistenceException: Error attempting to apply AttributeConverter at org.springframework.orm.jpa.EntityManagerFactoryUtils.convertJpaAccessExceptionIfPossible(EntityManagerFactoryUtils.java:408) at org.springframework.orm.jpa.vendor.HibernateJpaDialect.translateExceptionIfPossible (HibernateJpaDialect.java:257) at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.translateExceptionIfPossible(AbstractEntityManagerFactoryBean.java:531) . Caused by: CryptoException: com.fasterxml.jackson.core.JsonParseException: Unrecognized token ‘test’: was expecting (JSON String, Number, Array, Object or token ‘null’, ‘true’ or ‘false’) at [Source: (String)”test”; line: 1, column: 5] at org.hibernate.metamodel.model.convert.internal.JpaAttributeConverterImpl.toRelationalValue(JpaAttributeConverterImpl.java:50) at org.hibernate.type.descriptor.converter.AttributeConverterSqlTypeDescriptorAdapter$1.bind(AttributeConverterSqlTypeDescriptorAdapter.java:78) … 161 common frames omitted Caused by: com.fasterxml.jackson.core.JsonParseException: Unrecognized token ‘test’: was expecting (JSON String, Number, Array, Object or token ‘null’, ‘true’ or ‘false’) at [Source: (String)”test”; line: 1, column: 5] at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1851) at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:717) at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._reportInvalidToken(ReaderBasedJsonParser.java:2898) at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._reportInvalidToken(ReaderBasedJsonParser.java:2876) at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._matchToken2(ReaderBasedJsonParser.java:2673) at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._matchToken(ReaderBasedJsonParser.java:2651) at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._matchTrue(ReaderBasedJsonParser.java:2609) at com.fasterxml.jackson.core.json.ReaderBasedJsonParser.nextToken(ReaderBasedJsonParser.java:741) at com.fasterxml.jackson.databind.ObjectMapper._readTreeAndClose(ObjectMapper.java:4555) at com.fasterxml.jackson.databind.ObjectMapper.readTree(ObjectMapper.java:2974) … 166 common frames omitted . cause . @Lob @Convert(converter = JsonCryptoConverter.class) @Comment(value = \"메시지 내용\") private String message; . converter를 지정했는데, json으로 읽어야하는 과정에서 일반 string으로 message를 넣어서 발생한 오류 . converter 클래스부터 의심하자! . ",
    "url": "http://localhost:4000/docs/errors/attributeConverter_error/#error-attempting-to-apply-attributeconverter-nested-exception-is-javaxpersistencepersistenceexception-error-attempting-to-apply-attributeconverter",
    "relUrl": "/docs/errors/attributeConverter_error/#error-attempting-to-apply-attributeconverter-nested-exception-is-javaxpersistencepersistenceexception-error-attempting-to-apply-attributeconverter"
  },"31": {
    "doc": "Error attempting to apply AttributeConverter",
    "title": "Error attempting to apply AttributeConverter",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/attributeConverter_error/",
    "relUrl": "/docs/errors/attributeConverter_error/"
  },"32": {
    "doc": "우아한 객체지향 강의 (by 우형) 정리",
    "title": "강의",
    "content": "[우아한테크세미나] 190620 우아한객체지향 by 우아한형제들 개발실장 조영호님 . ",
    "url": "http://localhost:4000/docs/mooc/etc/baemin_object_oriented/#%EA%B0%95%EC%9D%98",
    "relUrl": "/docs/mooc/etc/baemin_object_oriented/#강의"
  },"33": {
    "doc": "우아한 객체지향 강의 (by 우형) 정리",
    "title": "Github",
    "content": "https://github.com/eternity-oop . ",
    "url": "http://localhost:4000/docs/mooc/etc/baemin_object_oriented/#github",
    "relUrl": "/docs/mooc/etc/baemin_object_oriented/#github"
  },"34": {
    "doc": "우아한 객체지향 강의 (by 우형) 정리",
    "title": "수강후기",
    "content": ". | 전체적으로 제품이 하려는 방향과 일치해서 이해하기 어렵지 않았다. | 협력관계에 대해, 객체에 대해 좀더 정리해 볼 수 있는 시간으로 유익한 강의! | . ",
    "url": "http://localhost:4000/docs/mooc/etc/baemin_object_oriented/#%EC%88%98%EA%B0%95%ED%9B%84%EA%B8%B0",
    "relUrl": "/docs/mooc/etc/baemin_object_oriented/#수강후기"
  },"35": {
    "doc": "우아한 객체지향 강의 (by 우형) 정리",
    "title": "강의 요약",
    "content": "클래스 의존성의 종류 . | Association 연관관계 = 탐색가능성(navigability) . | A클래스에서 B클래스로 영구적으로 갈 수 있는 통로(영구적인 탐색 구조). 영구적으로 유지가 되어야 한다는 판단근거가 있어야 한다. | 두 객체 사이에 협력이 필요하고 두 객체의 관계가 영구적이라면, 연관 관계를 이용해 탐색 경로 구현 | ex) Order가 뭔지 알면, Order를 통해 원하는 OrderLineItem을 찾을 수 있다 | 방법 . | 객체 참조를 이용한 연관관계 구현 | . | . | Dependency 의존관계 - 일시적으로 협력을 요하는 시점에 관계를 맺는것(파라미터, 리턴타입, 지역변수) | Inheritance 상속관계 - extends | Realization 실체화 관계 - implement | . 설계할 때 기본적 의존성 법칙 . | 양방향 의존성을 피하라 | 다중성이 적은 방향을 선택하라 . | one to many 보다 many to one으로 | . | 의존성이 필요없다면 제거하라 | Uni-Directional : 패키지 사이의 의존성 사이클을 제거하라 | . ",
    "url": "http://localhost:4000/docs/mooc/etc/baemin_object_oriented/#%EA%B0%95%EC%9D%98-%EC%9A%94%EC%95%BD",
    "relUrl": "/docs/mooc/etc/baemin_object_oriented/#강의-요약"
  },"36": {
    "doc": "우아한 객체지향 강의 (by 우형) 정리",
    "title": "협력 설계하기",
    "content": ". | 요구사항 정리 → 클래스 다이어그램 표현 | 관계에는 방향성이 필요 . | 어떤 객체가 다른 객체와 어떤 의존성을 갖는지 정적인 코드로 표현이 되어야 한다 | 관계의 방향 = 협력의 방향 = 의존성의 방향 | 객체는 방향성이 필요하다 : 어떤 객체가 어떤 객체에 의존성을 갖는지 | 런타임의 객체들이 어떻게 협력하는 가가 중요하다. | . | 관계의 종류 결정하기 . | 연관/의존/상속/실체화 관계 중 | 연관관계 : 협력을 위해 필요한 영구적인 탐색 구조를 잡아야 할 때. 실질적으로 데이터의 흐름에 따라가게 된다. 어떤 객체에서 어떤 객체로 빈번하게 호출해야할 때 영구적으로 잡는 것 | 의존 관계 : 협력을 위해 일시적으로 필요한 의존성(파라미터, 리턴타입, 지연변수) | . | . ",
    "url": "http://localhost:4000/docs/mooc/etc/baemin_object_oriented/#%ED%98%91%EB%A0%A5-%EC%84%A4%EA%B3%84%ED%95%98%EA%B8%B0",
    "relUrl": "/docs/mooc/etc/baemin_object_oriented/#협력-설계하기"
  },"37": {
    "doc": "우아한 객체지향 강의 (by 우형) 정리",
    "title": "설계 개선하기",
    "content": ". | dependency를 그려본다. | 협력관계가 이상하면, 잘못된 코드일 가능성이 크다 | cycle이 걸리지 않았는지 체크 | . | 일단 우선 절차적으로 코딩했다가 dependency를 그려보자 | 문제상황 . | 객체 참조로 인한 결합도 상승 | 패키지 의존성 사이클 | 수정할 때 도메인 규칙을 함께 적용할 경계는? 즉, 객체의 상태를 변경할 때 연관된 도메인 규칙을 함께 적용해야하는 객체의 범위는? = 결국 이말은 트랜잭션 경계가 어디까지인가와 같다 . | 중간객체를 통해 참조할 경우에도 트랜잭션이 하나로 묶이게 되므로 어디까지인가 경계를 정하는 것이 필요하다 | 중간객체로 묶인 도메인의 갱신 주기가 다를 수 있다. = 이러면 트랜잭션 경합이 발생해서 성능이 떨어질 수 있다. | . | 객체 참조의 문제점 . | 모든 객체가 연결돼 있기 때문에 어떤 객체라도 접근가능하게 되고 모두 수정이 가능하게 된다는 문제가 있다. | 객체 참조는 결합도가 가장 높은 의존성이다 | 객체 참조를 끊어야 한다. | 어떤 객체들을 묶고 어떤 객체들을 분리할 것인가? ( = 트랜잭션 경계 = 조회 경계) . | 함께 생성되고 함께 삭제되는 객체들을 함께 묶는다. | 경계 안의 객체는 참조를 이용해서 접근한다. | 경계 밖의 객체는 ID를 이용해 접근한다(=Repository를 통한 탐색) | 왜냐하면 같이 조회되어야 하니까 | 이걸 구분하면 언제 lazyloading할지 ignoreloading할지 경계가 구분된다 | . | 도메인 제약 사항을 공유하는 객체들을 함께 묶어라 . | 그룹은 트랜잭션/조회/비즈니스 제약의 단위가 된다 | . | 가능하면 분리하라 | 객체를 참조하는 로직을 일단 다른 객체로 옮겨버린다. | 예를 들어서 validation을 체크하는 로직을 Validator객체로 생성해서 로직을 모은다. 때로는 절차지향이 객체지향보다 좋다. 객체안에 validation을 담아야한다는 것은 무조건적이지 않다. | . | . | 도메인 로직의 순차적 실행이 필요할 때 . | 객체를 분리한 상황에서는 컴파일 에러가 발생하게 된다. | 이 경우는 . | 절차지향 객체를 생성해서 분리 . | 만약 패키지에 의존성 사이클이 발생한다면 . | 인터페이스를 이용해서 추상화를 넣어서 의존성을 역전시킨다. (dependency inversion principle) | . | . | 도메인 이벤트 퍼블리싱을 통해 협력 . | 로직의 순서를 느슨하게 만들고 싶을 때 사용 | spring data Aggregate Abstraction 이용 - 동기/비동기, 트랜잭션 단위별로 사용가능 | . public class Order extends AbstractAggregateRoot&lt;Order&gt; { } . | . | . | . | . | . | 해결 . | 중간 객체를 이용한 의존성 사이클 끊기 . | 이것도 문제 발생 | . | Repository를 통한 탐색(약한 결합도) . | Jpo에 컬럼을 추가하는 것을 의미 (ex. Order Jpo에 shopId를 컬럼으로 추가) | . | . | . ",
    "url": "http://localhost:4000/docs/mooc/etc/baemin_object_oriented/#%EC%84%A4%EA%B3%84-%EA%B0%9C%EC%84%A0%ED%95%98%EA%B8%B0",
    "relUrl": "/docs/mooc/etc/baemin_object_oriented/#설계-개선하기"
  },"38": {
    "doc": "우아한 객체지향 강의 (by 우형) 정리",
    "title": "우아한 객체지향 강의 (by 우형) 정리",
    "content": " ",
    "url": "http://localhost:4000/docs/mooc/etc/baemin_object_oriented/",
    "relUrl": "/docs/mooc/etc/baemin_object_oriented/"
  },"39": {
    "doc": "BeanInstantiationException Failed to instantiate",
    "title": "problem",
    "content": "Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.security.config.annotation.web.reactive.WebFluxSecurityConfiguration': Unsatisfied dependency expressed through method 'setSecurityWebFilterChains' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'filterChain' defined in class path resource [spectra/attic/coreasset/ecosystem/barista/config/WebFluxSecurityConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.security.web.server.SecurityWebFilterChain]: Factory method 'filterChain' threw exception; nested exception is java.lang.NullPointerException 11:26:43.768 main ERROR o.s.b.SpringApplication :824 reportFailure Application run failed Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'filterChain' defined in class path resource [spectra/attic/coreasset/ecosystem/barista/config/WebFluxSecurityConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.security.web.server.SecurityWebFilterChain]: Factory method 'filterChain' threw exception; nested exception is java.lang.NullPointerException Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.security.web.server.SecurityWebFilterChain]: Factory method 'filterChain' threw exception; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:653) ... 36 common frames omitted Caused by: java.lang.NullPointerException: null at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ... 37 common frames omitted . 현상은 springboot 서비스 run할 때, 위의 에러를 내뱉고 죽었다. run할 때 발생하는 에러에서 npe나 bean create못한다는 에러이면, yml설정을 의심해보는 것이 좋다 . ",
    "url": "http://localhost:4000/docs/errors/beanInstantiationException/#problem",
    "relUrl": "/docs/errors/beanInstantiationException/#problem"
  },"40": {
    "doc": "BeanInstantiationException Failed to instantiate",
    "title": "cause",
    "content": "위의 경우는 . SecurityWebFilterChain을 bean으로 등록하는 클래스에 아래의 코드가 있었는데 . @Value(\"${attic.buzzer.security.ignores:}\") private String[] securityIgnores; . | property를 설정한 yml을 읽어오지 못해서 npe가 발생하고 bean등록에 실패한 것이였다 | yml을 못가져온 것은 application.yml의 search-locations 끝에 / 슬래시가 없어서 (window는 끝에 슬래시 필수) | . ",
    "url": "http://localhost:4000/docs/errors/beanInstantiationException/#cause",
    "relUrl": "/docs/errors/beanInstantiationException/#cause"
  },"41": {
    "doc": "BeanInstantiationException Failed to instantiate",
    "title": "reference",
    "content": "Error creating bean with name ‘springSecurityFilterChain’ . ",
    "url": "http://localhost:4000/docs/errors/beanInstantiationException/#reference",
    "relUrl": "/docs/errors/beanInstantiationException/#reference"
  },"42": {
    "doc": "BeanInstantiationException Failed to instantiate",
    "title": "BeanInstantiationException Failed to instantiate",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/beanInstantiationException/",
    "relUrl": "/docs/errors/beanInstantiationException/"
  },"43": {
    "doc": "★bookmark",
    "title": "★bookmark",
    "content": "I will keep looking. https://baek.dev/ . https://greensock.com/ . ",
    "url": "http://localhost:4000/docs/bookmark/",
    "relUrl": "/docs/bookmark/"
  },"44": {
    "doc": "Bridge pattern",
    "title": "Bridge pattern",
    "content": " ",
    "url": "http://localhost:4000/docs/patterns/bridge_pattern/",
    "relUrl": "/docs/patterns/bridge_pattern/"
  },"45": {
    "doc": "burrow Failed to compile TemplateOpen",
    "title": "burrow Failed to compile TemplateOpen",
    "content": "burrow Failed to compile TemplateOpen [recovered] . /root/go/bin/Burrow –config-dir=/usr/local/Burrow/config로 시작하려고 하면 실패나는 것 . [root@victory-dev-105 config]# cat burrow.out | more panic: Failed to compile TemplateOpen [recovered] panic: Failed to compile TemplateOpen [recovered] panic: Failed to compile TemplateOpen goroutine 1 [running]: main.handleExit() /usr/local/Burrow/main.go:64 /usr/local/go/src/runtime/panic.go:1038 +0x215 go.uber.org/zap/zapcore.(*CheckedEntry).Write /root/go/pkg/mod/go.uber.org/zap@v1.20.0/zapcore/entry.go:232 github.com/linkedin/Burrow/core.configureCoordinators.func1() /usr/local/Burrow/core/burrow.go:97 +0x56 panic({0xb3c200, 0xc0001b3a10}) /usr/local/go/src/runtime/panic.go:1038 +0x215 go.uber.org/zap/zapcore.(*CheckedEntry).Write /root/go/pkg/mod/go.uber.org/zap@v1.20.0/zapcore/entry.go:232 +0x446 go.uber.org/zap.(*Logger).Panic /root/go/pkg/mod/go.uber.org/zap@v1.20.0/logger.go:230 +0x59 github.com/linkedin/Burrow/core/internal/notifier.(*Coordinator).Configure(0xc000184880) /usr/local/Burrow/core/internal/notifier/coordinator.go:217 +0xd91 github.com/linkedin/Burrow/core.configureCoordinators /usr/local/Burrow/core/burrow.go:104 +0xc2 github.com/linkedin/Burrow/core.Start(0xc0003288a0, 0xc0001c3ef0) /usr/local/Burrow/core/burrow.go:152 +0x3fb main.main() /usr/local/Burrow/main.go:115 +0x4f3 . try~ . https://github.com/linkedin/Burrow/issues/414에서 시키는대로 burrow.toml에서 template-open 부분 수정 . 기본 파일이 conf/로 되어있어서 경로변경했는데도 아래 에러 발생 . panic: no url-close specified [recovered] panic: no url-close specified [recovered] panic: no url-close specified goroutine 1 [running]: main.handleExit() /usr/local/Burrow/main.go:64 +0xfe panic({0xb3c200, 0xc000292a70}) /usr/local/go/src/runtime/panic.go:1038 /root/go/pkg/mod/go.uber.org/zap@v1.20.0/logger.go:230 +0x59 github.com/linkedin/Burrow/core.configureCoordinators.func1() /usr/local/Burrow/core/burrow.go:97 /usr/local/go/src/runtime/panic.go:1038 +0x215 go.uber.org/zap/zapcore.(*CheckedEntry).Write /root/go/pkg/mod/go.uber.org/zap@v1.20.0/logger.go:230 +0x59 github.com/linkedin/Burrow/core/internal/notifier.(*HTTPNotifier).Configure /usr/local/Burrow/core/internal/notifier/http.go:78 +0x64b github.com/linkedin/Burrow/core/internal/notifier.(*Coordinator).Configure /usr/local/Burrow/core/internal/notifier/coordinator.go:232 +0x7d1 github.com/linkedin/Burrow/core.configureCoordinators /usr/local/Burrow/core/burrow.go:104 +0xc2 github.com/linkedin/Burrow/core.Start /usr/local/Burrow/core/burrow.go:152 +0x3fb main.main() /usr/local/Burrow/main.go:115 +0x4f3 . solved . just delete this part -&gt; [notifier.default] . 다시 nuhup으로 시작 . nohup /root/go/bin/Burrow –config-dir=/usr/local/Burrow/config 1&gt; /dev/null 2&gt;&amp;1 &amp; . reference . [Kafka] install Burrow to linux (centos) . [Kafka] 카프카 Burrow 설치 (카프카 모니터링) . ",
    "url": "http://localhost:4000/docs/etc/burrow_fail/",
    "relUrl": "/docs/etc/burrow_fail/"
  },"46": {
    "doc": "Chain of Responsibility",
    "title": "AS-IS.",
    "content": ". | 하나의 서비스에서 접수 처리와 메시지 전송 기능이 혼재 | . ",
    "url": "http://localhost:4000/docs/patterns/chain_of_responsibility/#as-is",
    "relUrl": "/docs/patterns/chain_of_responsibility/#as-is"
  },"47": {
    "doc": "Chain of Responsibility",
    "title": "TO-BE.",
    "content": ". | 접수 처리 프로세스와 메시지 전송 프로세스를 별개로 분리 | 프로세스 순서를 체인으로 강제 ( 접수 프로세스 진행 후 → 메시지 전송 프로세스 진행) | . :: Client . // 우선순위 btalkMessageProcessor -&gt; btalkReceptionProcessor public void message(ConversationMessage conversationMessage) { btalkMessageProcessor.setNext(btalkReceptionProcessor); btalkMessageProcessor.support(conversationMessage); } . :: Handler Processor . @Slf4j public abstract class BtalkProcessor { private BtalkProcessor next = null; public BtalkProcessor setNext(BtalkProcessor next) { this.next = next; return next; } public final void support(ConversationMessage conversationMessage) { if (process(conversationMessage)) { action(conversationMessage); } else if (next != null) { next.support(conversationMessage); } else { log.error(\"There is no next process of btalk.\"); } } public abstract boolean process(ConversationMessage conversationMessage); public abstract void action(ConversationMessage conversationMessage); } . :: Sub Processor . [btalkMessageProcessor] public class BtalkMessageProcessor extends BtalkProcessor { @Override public boolean process(ConversationMessage conversationMessage) { return isPresent(conversationMessage); } @Override public void action(ConversationMessage conversationMessage) { sendMessage(conversationMessage); } } [btalkReceptionProcessor] public class BtalkReceptionProcessor extends BtalkProcessor { @Override public boolean process(ConversationMessage conversationMessage) { return !isPresent(conversationMessage); } @Override public void action(ConversationMessage conversationMessage) { reception(conversationMessage); } } . 참고. https://lktprogrammer.tistory.com/45 . ",
    "url": "http://localhost:4000/docs/patterns/chain_of_responsibility/#to-be",
    "relUrl": "/docs/patterns/chain_of_responsibility/#to-be"
  },"48": {
    "doc": "Chain of Responsibility",
    "title": "Chain of Responsibility",
    "content": "역학 사슬 패턴 . | 체인에 묶인 객체들끼리 순서대로 책임을 넘기는 구조 | . ",
    "url": "http://localhost:4000/docs/patterns/chain_of_responsibility/",
    "relUrl": "/docs/patterns/chain_of_responsibility/"
  },"49": {
    "doc": "Clipping",
    "title": "Clipping",
    "content": " ",
    "url": "http://localhost:4000/docs/clipping",
    "relUrl": "/docs/clipping"
  },"50": {
    "doc": "Confluent & Imply 웨비나 온라인 참석 후기",
    "title": "Contents",
    "content": ". | kafka, druid/imply 소개 | 데이터 산업에서 언제 imply를 쓸 수 있는가? . | 기존에는 원천 데이터 소스를 elt를 통해 목적에 맞게 가공/처리해서 데이터웨어 하우스나 데이터 레이크에 저장하는 방식이였다면, 이제는 kafka 스트리밍 데이터를 받아 imply 통해서 분석을 할 수 있다. | . | 분석어플리케이션 데모 . | druid웹콘솔을 통해서 간단히 토픽 생성하고 kafka 데이터 수집하는 데모였는데, 복잡한 프로그래밍이 필요없어서 편해보이지만 kafka를 잘 모르면 사용하기 어려울 것 같습니다. | . | k2d stack(kafka+druid) 활용사례 . | kafka이벤트를 받아서 imply에 넘겨서 druid를 통해 실시간 분석을 하고 어플리케이션에 전달하는 것 | 장점 : netflow 수집 및 분석, 스트림 분석 , Application 성능 관리 | . | kafk 모니터링이 가능한 대시보드 . | 현재 회사에서 사용하는 그라파나로는 토픽별 lag이나 cpu점유 정도 확인할 수 있는데요. 이 제품은 뭔가 더 디테일하게 다른 정보도 확인할 수 있는 것 같습니다. | . | . ",
    "url": "http://localhost:4000/docs/mooc/etc/confluent_imply_webinar/#contents",
    "relUrl": "/docs/mooc/etc/confluent_imply_webinar/#contents"
  },"51": {
    "doc": "Confluent & Imply 웨비나 온라인 참석 후기",
    "title": "후기",
    "content": "k2d stack에 대해 알 수 있어서 좋았습니다. 구축 사례를 좀 더 알고 싶었는데요. 기회가 된다면 다음에도 참석하고 싶네요. 참고로 2022년 10월 20일에 druid 오프라인 summit이 개최된다고 합니다. ",
    "url": "http://localhost:4000/docs/mooc/etc/confluent_imply_webinar/#%ED%9B%84%EA%B8%B0",
    "relUrl": "/docs/mooc/etc/confluent_imply_webinar/#후기"
  },"52": {
    "doc": "Confluent & Imply 웨비나 온라인 참석 후기",
    "title": "Confluent & Imply 웨비나 온라인 참석 후기",
    "content": "22-07-21에 Confluent와 Imply가 주최한 실시간 데이터 구축 웨비나에 참석했습니다 . 14시부터 약 50분 정도 진행된 것 같습니다. ",
    "url": "http://localhost:4000/docs/mooc/etc/confluent_imply_webinar/",
    "relUrl": "/docs/mooc/etc/confluent_imply_webinar/"
  },"53": {
    "doc": "ConversionNotSupportedException",
    "title": "ConversionNotSupportedException",
    "content": "error log . expressed through field ‘expirations’; nested exception is org.springframework.beans.ConversionNotSupportedException: Failed to convert value of type ‘java.lang.String’ to required type ‘java.util.List’; nested exception is java.lang.IllegalStateException: . Cannot convert value of type ‘java.lang.String’ to required type ‘spectra.attic.talk.mocha.authentication.authentication.domain.device.DeviceExpiration’: . no matching editors or conversion strategy found . 설정yml . mocha: login: expirations: - device: pc limit: 5 - device: mobile limit: 1440 - device: tablet limit: 1440 . cause . @Value(\"${attic.mocha.login.expirations:}\") private List&lt;DeviceExpiration&gt; expirations; . solution . To mapping Object, using @ConfigurationProperties로 선언해야한다. @Getter @Component @ConfigurationProperties(\"attic.mocha.login\") public class ExpirationConfig { private List&lt;DeviceExpiration&gt; expirations; public void setExpirations(List&lt;DeviceExpiration&gt; expirations) { this.expirations = expirations; } } . 이렇게 하니 된다 . ",
    "url": "http://localhost:4000/docs/errors/conversionError/",
    "relUrl": "/docs/errors/conversionError/"
  },"54": {
    "doc": "Data Analyst Nanodegree Program 후기",
    "title": "Data Analyst Nanodegree Program 후기",
    "content": " ",
    "url": "http://localhost:4000/docs/mooc/udacity/data_analyst/",
    "relUrl": "/docs/mooc/udacity/data_analyst/"
  },"55": {
    "doc": "Data Analyst Nanodegree Program 후기",
    "title": "강의 URL",
    "content": "2017년도에 수강했던 강의라 지금은 해당 강좌가 없어지고, 대체 강좌들이 생긴 것 같다. ",
    "url": "http://localhost:4000/docs/mooc/udacity/data_analyst/#%EA%B0%95%EC%9D%98-url",
    "relUrl": "/docs/mooc/udacity/data_analyst/#강의-url"
  },"56": {
    "doc": "Data Analyst Nanodegree Program 후기",
    "title": "학습 툴",
    "content": ". | python | jupyter notebook | anaconda | 노트와 연필 ← 필수 | ztable.jpg ← 소중… | . ",
    "url": "http://localhost:4000/docs/mooc/udacity/data_analyst/#%ED%95%99%EC%8A%B5-%ED%88%B4",
    "relUrl": "/docs/mooc/udacity/data_analyst/#학습-툴"
  },"57": {
    "doc": "Data Analyst Nanodegree Program 후기",
    "title": "강의 구성",
    "content": ". | udacity에서 전문대학처럼 전문가를 양성하고자 2017년도에 nanodegree강좌를 여러개 만들었었고, 이 수업은 그 중 하나로 한달에 30~40만원했던 수업;; | 강좌를 모두 학습하고 과제를 모두 통과하면 degree를 주고 채용연계까지 시켜주는 커리큘럼이 있었다. | . ",
    "url": "http://localhost:4000/docs/mooc/udacity/data_analyst/#%EA%B0%95%EC%9D%98-%EA%B5%AC%EC%84%B1",
    "relUrl": "/docs/mooc/udacity/data_analyst/#강의-구성"
  },"58": {
    "doc": "Data Analyst Nanodegree Program 후기",
    "title": "선수 학습 조건",
    "content": " ",
    "url": "http://localhost:4000/docs/mooc/udacity/data_analyst/#%EC%84%A0%EC%88%98-%ED%95%99%EC%8A%B5-%EC%A1%B0%EA%B1%B4",
    "relUrl": "/docs/mooc/udacity/data_analyst/#선수-학습-조건"
  },"59": {
    "doc": "Data Analyst Nanodegree Program 후기",
    "title": "언어 지원",
    "content": " ",
    "url": "http://localhost:4000/docs/mooc/udacity/data_analyst/#%EC%96%B8%EC%96%B4-%EC%A7%80%EC%9B%90",
    "relUrl": "/docs/mooc/udacity/data_analyst/#언어-지원"
  },"60": {
    "doc": "Data Analyst Nanodegree Program 후기",
    "title": "학습 후기",
    "content": ". | 저는 총 3개월동안 평일엔 퇴근해서 강의듣고, 주말엔 과제하면서 공부했던 기억이 난다. | 과제를 제출하면, 첨삭을 잘 해줬던 것도 기억이 난다. 타이타닉 과제는 리뷰를 여러번 받아서, 아직도 기억이 생생~ | . ",
    "url": "http://localhost:4000/docs/mooc/udacity/data_analyst/#%ED%95%99%EC%8A%B5-%ED%9B%84%EA%B8%B0",
    "relUrl": "/docs/mooc/udacity/data_analyst/#학습-후기"
  },"61": {
    "doc": "datatable lib 적용 (2020)",
    "title": "요구사항",
    "content": ". | 2개의 테이블로 구분 | 각 row에 dropdown 제공 | 리스트 검색 | 컬럼별 정렬 제공 | . ",
    "url": "http://localhost:4000/docs/etc/datatable_lib/#%EC%9A%94%EA%B5%AC%EC%82%AC%ED%95%AD",
    "relUrl": "/docs/etc/datatable_lib/#요구사항"
  },"62": {
    "doc": "datatable lib 적용 (2020)",
    "title": "개발",
    "content": ". | 라이브러리를 검색하다가 datatable 발견해서 간단하게 청사진(?)을 그려본 담에 내부 검토를 거쳐서 적용하게 되었습니다. | 적용하면서 라이브러리에 대해 정리한 것들입니다. | . 1. datatable생성되고 로드되고 콜백 정의 . datatable({ stateLoadCallback: function(settings) { return true; // 리턴 반드시 정의(리턴 빠지면 생성안됨) } }) . 2. row항목별 클릭이벤트 정의 . datatable({ fnRowCallback: function( nRow, aData, iDisplayIndex, iDisplayIndexFull ) { $('td &gt; i', nRow).on('click', function() { // if you have the property \"data\" in your columns, access via aData.property_name // if not, access data array from parameter aData, aData[0] = data for field 0, and so on...* var btnAction = $(this).data('toggle'); if (btnAction === 'dropdown'){ // $(this).trigger('click'); $(this).closest('div').find('.subMenu').addClass('open'); } else if (btnAction === 'appdetail'){ // do something...... } }); }}) . 3. row별로 속성주기 . var aaa = new Datatable(); aaa.rows().every( function () { this.child( this.index() ); } ); . 4. class속성 변경 . $.extend( $.fn.dataTableExt.oStdClasses, { \"sFilterInput\": \"form-control\" // 필터영역에 className 정의 }); . 5. row 빼기 . $.fn.dataTable.ext.search.push( function(settings, data, dataIndex) { alert(data[1] == \" \"); return data[1] == \" \"; } ); aaa.draw(); . 6. row빼기 - 2 . // (3)으로 child주고 하고 나서 var bb = $('#listViewTableY tbody'); var child = aaa.row( bb ).child; if ( child.isShown() ) { child.hide(); } else { child.show(); } . 7. 테이블 그려질 때 디폴트로 특정 컬럼으로 sorting되게 . order: [[3, 'desc']], // 4번째 컬럼으로 descending되게 한다. | datatables가 생성되었는지 체크하는 방법 . if (table instanceof $.fn.dataTable.Api) { // datatable ... do datatable stuff } else { // not a datatable... do other stuff } . OR . *$*.**fn**.dataTable.isDataTable(**'#listViewTableMain'**) . | . 8. get  row data . columnDefs : [{targets:0, width:'33%'}, {targets:1, width:'10%'}, {targets:2, width:'27%'}, {targets:3, width:'15%'}, {targets:4, width:'14%', sortable: false}, {targets:[5, 6], width:'1%', visible: false}], columns: [ { \"data\": \"scenarioName\" }, { \"data\": \"status\" }, { \"data\": \"description\" }, { \"data\": \"updatedDate\" }, { \"data\": \"applyBtn\" }, { \"data\": \"scenarioId\" }, { \"data\": \"isMain\" } ], alert(loadedDatatable.rows( { selected: true } ).data()[0].scenarioId); &lt;th class=\"hide\"&gt;&lt;/th&gt; &lt;th class=\"hide\"&gt;&lt;/th&gt; &lt;td class=\"hide\"&gt;&lt;/td&gt; &lt;td class=\"hide\"&gt;&lt;/td&gt; . 기타. 로딩이 느려서 테스트해 본 옵션들 . | fixedHeader : true로 하면 헤더는 고정되지만 약간 느린것 같음 | stateSave : true로 하면 마지막 정렬조건이라든지 마지막 설정을 저장해서 가져오고 있어서 좋지만, 느린것 같음 | columnDefs: 컬럼별로 설정이 많을 수록 느림 | responsive: true로 하면 느림 | . ",
    "url": "http://localhost:4000/docs/etc/datatable_lib/#%EA%B0%9C%EB%B0%9C",
    "relUrl": "/docs/etc/datatable_lib/#개발"
  },"63": {
    "doc": "datatable lib 적용 (2020)",
    "title": "datatable lib 적용 (2020)",
    "content": "ℹ️ 1.10.20버전 기준 . ",
    "url": "http://localhost:4000/docs/etc/datatable_lib/",
    "relUrl": "/docs/etc/datatable_lib/"
  },"64": {
    "doc": "how to connect elasticsearch in dbeaver",
    "title": "1. 메뉴 [데이터베이스] → [새 데이터베이스 연결]",
    "content": ". ",
    "url": "http://localhost:4000/docs/etc/dbeaver1/#1-%EB%A9%94%EB%89%B4-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4--%EC%83%88-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EC%97%B0%EA%B2%B0",
    "relUrl": "/docs/etc/dbeaver1/#1-메뉴-데이터베이스--새-데이터베이스-연결"
  },"65": {
    "doc": "how to connect elasticsearch in dbeaver",
    "title": "2. host, port, auth정보 입력하고 [Test Connection] 클릭",
    "content": ". ",
    "url": "http://localhost:4000/docs/etc/dbeaver1/#2-host-port-auth%EC%A0%95%EB%B3%B4-%EC%9E%85%EB%A0%A5%ED%95%98%EA%B3%A0-test-connection-%ED%81%B4%EB%A6%AD",
    "relUrl": "/docs/etc/dbeaver1/#2-host-port-auth정보-입력하고-test-connection-클릭"
  },"66": {
    "doc": "how to connect elasticsearch in dbeaver",
    "title": "3. 드라이브가 없는 경우, Download버튼을 통해 다운받습니다.",
    "content": ". ",
    "url": "http://localhost:4000/docs/etc/dbeaver1/#3-%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C%EA%B0%80-%EC%97%86%EB%8A%94-%EA%B2%BD%EC%9A%B0-download%EB%B2%84%ED%8A%BC%EC%9D%84-%ED%86%B5%ED%95%B4-%EB%8B%A4%EC%9A%B4%EB%B0%9B%EC%8A%B5%EB%8B%88%EB%8B%A4",
    "relUrl": "/docs/etc/dbeaver1/#3-드라이브가-없는-경우-download버튼을-통해-다운받습니다"
  },"67": {
    "doc": "how to connect elasticsearch in dbeaver",
    "title": "4. 설치한 es버전은 7.6.2인데, jdbc드라이버는 7.8.1이여서 발생한 에러",
    "content": ". This version of the JDBC driver is only compatible with Elasticsearch version 7.9 or newer; attempting to connect to a server version 7.6.2 . ",
    "url": "http://localhost:4000/docs/etc/dbeaver1/#4-%EC%84%A4%EC%B9%98%ED%95%9C-es%EB%B2%84%EC%A0%84%EC%9D%80-762%EC%9D%B8%EB%8D%B0-jdbc%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B2%84%EB%8A%94-781%EC%9D%B4%EC%97%AC%EC%84%9C-%EB%B0%9C%EC%83%9D%ED%95%9C-%EC%97%90%EB%9F%AC",
    "relUrl": "/docs/etc/dbeaver1/#4-설치한-es버전은-762인데-jdbc드라이버는-781이여서-발생한-에러"
  },"68": {
    "doc": "how to connect elasticsearch in dbeaver",
    "title": "5. elasticsearch 버전에 맞는 jdbc드라이버를 다운받습니다",
    "content": "Past Releases of Elastic Stack Software . ",
    "url": "http://localhost:4000/docs/etc/dbeaver1/#5-elasticsearch-%EB%B2%84%EC%A0%84%EC%97%90-%EB%A7%9E%EB%8A%94-jdbc%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B2%84%EB%A5%BC-%EB%8B%A4%EC%9A%B4%EB%B0%9B%EC%8A%B5%EB%8B%88%EB%8B%A4",
    "relUrl": "/docs/etc/dbeaver1/#5-elasticsearch-버전에-맞는-jdbc드라이버를-다운받습니다"
  },"69": {
    "doc": "how to connect elasticsearch in dbeaver",
    "title": "6. 그럼 다시 test connection을 통해서 driver를 다운받은걸 교체합니다.",
    "content": ". [Edit Driver Settings]를 눌러서 교체 . 7.9.1은 Delete하고 . Add File을 통해서 다운받은 jar파일로 지정합니다 . 그리고 다시 Test Connection 클릭하면 성공 . Dbeaver에 connection 추가한것 확인하고 + 버튼으로 테이블 확인합니다. current license is non-compliant for [jdbc] . ",
    "url": "http://localhost:4000/docs/etc/dbeaver1/#6-%EA%B7%B8%EB%9F%BC-%EB%8B%A4%EC%8B%9C-test-connection%EC%9D%84-%ED%86%B5%ED%95%B4%EC%84%9C-driver%EB%A5%BC-%EB%8B%A4%EC%9A%B4%EB%B0%9B%EC%9D%80%EA%B1%B8-%EA%B5%90%EC%B2%B4%ED%95%A9%EB%8B%88%EB%8B%A4",
    "relUrl": "/docs/etc/dbeaver1/#6-그럼-다시-test-connection을-통해서-driver를-다운받은걸-교체합니다"
  },"70": {
    "doc": "how to connect elasticsearch in dbeaver",
    "title": "7. 에러..에러…….발생",
    "content": " ",
    "url": "http://localhost:4000/docs/etc/dbeaver1/#7-%EC%97%90%EB%9F%AC%EC%97%90%EB%9F%AC%EB%B0%9C%EC%83%9D",
    "relUrl": "/docs/etc/dbeaver1/#7-에러에러발생"
  },"71": {
    "doc": "how to connect elasticsearch in dbeaver",
    "title": "결론",
    "content": "basic버전은 jdbc지원 안한다는..플래티넘부터 지원한다고 함. 슬픈 결론 . programador clic . ",
    "url": "http://localhost:4000/docs/etc/dbeaver1/#%EA%B2%B0%EB%A1%A0",
    "relUrl": "/docs/etc/dbeaver1/#결론"
  },"72": {
    "doc": "how to connect elasticsearch in dbeaver",
    "title": "how to connect elasticsearch in dbeaver",
    "content": " ",
    "url": "http://localhost:4000/docs/etc/dbeaver1/",
    "relUrl": "/docs/etc/dbeaver1/"
  },"73": {
    "doc": "Decorator pattern",
    "title": "Decorator pattern",
    "content": "데코레이터 패턴 . | 예를 들어서, Set인스턴스를 감싸는(wrap) 래퍼 클래스를 만들고, 이 클래스에 계측 기능을 덧씌우는 것을 말함 | . static void walk(Set&lt;Dog&gt; dogs) { InstrumentedSet&lt;Dog&gt; iDogs = new InstrumentedSet&lt;&gt;(dogs); } . ",
    "url": "http://localhost:4000/docs/patterns/decorator_pattern/",
    "relUrl": "/docs/patterns/decorator_pattern/"
  },"74": {
    "doc": "DNS_PROBE_FINISHED_NXDOMAIN",
    "title": "try1..",
    "content": "혹시 회사망에서 막혔나 싶어서, 핸폰에서 lte로 했는데도 마찬가지 . ",
    "url": "http://localhost:4000/docs/errors/dns_probe_finished_nxdomain/#try1",
    "relUrl": "/docs/errors/dns_probe_finished_nxdomain/#try1"
  },"75": {
    "doc": "DNS_PROBE_FINISHED_NXDOMAIN",
    "title": "try2..",
    "content": "whois에서 도메인검색하면 없는 도메인이라고 나온다… . ",
    "url": "http://localhost:4000/docs/errors/dns_probe_finished_nxdomain/#try2",
    "relUrl": "/docs/errors/dns_probe_finished_nxdomain/#try2"
  },"76": {
    "doc": "DNS_PROBE_FINISHED_NXDOMAIN",
    "title": "try3..",
    "content": "일단 로컬pc 호스트파일에 공인ip와 도메인을 추가하고 . 크롬에서 다시 띄워보니 . ",
    "url": "http://localhost:4000/docs/errors/dns_probe_finished_nxdomain/#try3",
    "relUrl": "/docs/errors/dns_probe_finished_nxdomain/#try3"
  },"77": {
    "doc": "DNS_PROBE_FINISHED_NXDOMAIN",
    "title": "try4..",
    "content": "ssl이 잘못되었나 싶어서..다시 만들어보고 흠.. ",
    "url": "http://localhost:4000/docs/errors/dns_probe_finished_nxdomain/#try4",
    "relUrl": "/docs/errors/dns_probe_finished_nxdomain/#try4"
  },"78": {
    "doc": "DNS_PROBE_FINISHED_NXDOMAIN",
    "title": "solved",
    "content": "원인은 . https://maivve.tistory.com/301 . 이렇다고 함 . 하루 지나니 정상화되었다;;;; . 그냥 사내 멀티 도메인에 추가신청했다. ",
    "url": "http://localhost:4000/docs/errors/dns_probe_finished_nxdomain/#solved",
    "relUrl": "/docs/errors/dns_probe_finished_nxdomain/#solved"
  },"79": {
    "doc": "DNS_PROBE_FINISHED_NXDOMAIN",
    "title": "DNS_PROBE_FINISHED_NXDOMAIN",
    "content": "freenom에 등록한 도메인주소로 잘 써왔는데 . 갑자기 접속이 안되어서 . 공인ip로 접속해보니 . NET::ERR_CERT_COMMON_NAME_INVALID 에러가 나고 있었다 . 도메인 주소로 nslookup 하면 . DNS request timed out. timeout was 2 seconds. DNS request timed out. timeout was 2 seconds. *** DC1.spectra.co.kr에 대한 요청이 제한 시간을 초과했습니다. ",
    "url": "http://localhost:4000/docs/errors/dns_probe_finished_nxdomain/",
    "relUrl": "/docs/errors/dns_probe_finished_nxdomain/"
  },"80": {
    "doc": "docker elasticsearch shutdown cause",
    "title": "problem 1",
    "content": "ERROR: [2] bootstrap checks failed. You must address the points described in the following [2] lines before starting Elasticsearch. bootstrap check failure [1] of [2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] bootstrap check failure [2] of [2]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured . ",
    "url": "http://localhost:4000/docs/errors/docker_elasticsearch/#problem-1",
    "relUrl": "/docs/errors/docker_elasticsearch/#problem-1"
  },"81": {
    "doc": "docker elasticsearch shutdown cause",
    "title": "solved",
    "content": "window으ㅣ m.max_map_count는 cmd창 열어서 . 1) wsl -d docker-desktop 2) sysctl -w vm.max_map_count=262144 . ElasticSearch in Windows docker image vm max map count . ",
    "url": "http://localhost:4000/docs/errors/docker_elasticsearch/#solved",
    "relUrl": "/docs/errors/docker_elasticsearch/#solved"
  },"82": {
    "doc": "docker elasticsearch shutdown cause",
    "title": "problem 2",
    "content": "the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured . docker-compose.yml에 아래 추가 . environment: discovery.seed_hosts: \"elasticsearch\" cluster.initial_master_nodes: \"node\" . Elasticsearch 설치 시 오류 . ",
    "url": "http://localhost:4000/docs/errors/docker_elasticsearch/#problem-2",
    "relUrl": "/docs/errors/docker_elasticsearch/#problem-2"
  },"83": {
    "doc": "docker elasticsearch shutdown cause",
    "title": "docker elasticsearch shutdown cause",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/docker_elasticsearch/",
    "relUrl": "/docs/errors/docker_elasticsearch/"
  },"84": {
    "doc": "docker hazelcast management-center start error",
    "title": "docker hazelcast management-center start error",
    "content": "problem . docker에 한번 올리고 . 다시 재부팅 후 올리면 . error . management-center | ERROR: Could not lock home directory. Make sure that Management Center web application is stopped (offline) before starting this command. If you are sure the application is stopped, it means that lock file was not deleted properly. Please delete 'mc.lock' file in the home directory manually before using the command. solved . 홈 디렉토리에 있는 mc.lock을 수동으로 삭제하라고 하라는 에러 메시지라서 삭제했다. management 홈 디렉토리 위치는 INSPECT 화면에서 MC_HOME을 확인한다 . 서버가 제대로 구동안된 상태이기 때문에, docker의 cli로 못들어가서 . 도커에 올라가 있는 다른 서비스를 통해서 삭제했던 것 같다. ",
    "url": "http://localhost:4000/docs/errors/docker_hazelcast_start_error/",
    "relUrl": "/docs/errors/docker_hazelcast_start_error/"
  },"85": {
    "doc": "Unknown Faceted Project Problem",
    "title": "problem",
    "content": "이클립스에서 아래처럼 나오면 . Description     Resource     Path     Location     Type Java compiler level does not match the version of the installed Java project facet. webapps Unknown Faceted Project Problem (Java Version Mismatch) . ",
    "url": "http://localhost:4000/docs/errors/eclipse_error1/#problem",
    "relUrl": "/docs/errors/eclipse_error1/#problem"
  },"86": {
    "doc": "Unknown Faceted Project Problem",
    "title": "solution",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/eclipse_error1/#solution",
    "relUrl": "/docs/errors/eclipse_error1/#solution"
  },"87": {
    "doc": "Unknown Faceted Project Problem",
    "title": "try1",
    "content": "properties &gt; project facet &gt; java버전을 낮추는데 . ",
    "url": "http://localhost:4000/docs/errors/eclipse_error1/#try1",
    "relUrl": "/docs/errors/eclipse_error1/#try1"
  },"88": {
    "doc": "Unknown Faceted Project Problem",
    "title": "try2",
    "content": "dynamic web module버전이 3.0에서 2.5로 안내려간다면 .setting&gt; &gt; org.eclipse.wst.common.project.facet.core.xml . 파일을 열어 jst.web을 2.5로 변경하거나 컴파일 버전을 바꾼다 . ",
    "url": "http://localhost:4000/docs/errors/eclipse_error1/#try2",
    "relUrl": "/docs/errors/eclipse_error1/#try2"
  },"89": {
    "doc": "Unknown Faceted Project Problem",
    "title": "Unknown Faceted Project Problem",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/eclipse_error1/",
    "relUrl": "/docs/errors/eclipse_error1/"
  },"90": {
    "doc": "AngularJS Advanced Framework Techniques",
    "title": "[EDX] AngularJS 수강 후 정리",
    "content": ". | 개발 : visual studio code | Data Access방법 세가지 . | Service :You are returning an object with methods. | Factory : The value you are providing needs to be calculated based on other data. | Provider : You want to be able to configure, during the config phase, the object that is going to be created before it’s created. Use the Provider mostly in the app config, before the app has fully initialized. | 세개의 차이점은 복잡도 차이다. Service가 가장 간단하고 Provider가 실시간으로 설정이 가능하다. | . | Service 싱글톤 . | 싱글톤은 new로 한다. | Angular는 $http같은 서비스를 제공한다. 내장된 서비스들이 $를 붙인다. 그 외에 자체적으로 angular identifier를 만들 수 있다. | https://github.com/johnpapa/angular-styleguide/tree/master/a1#services | . | 싱글톤 서비스 사용하기 . | 선언한다 . myApp.service('thisService', function(){ }) . | this를 써서 함수를 set한다 . myApp.service('thisService', function(){ var _food = 'Chicken'; var _drink = 'Soda'; this.getFood = function(){ return _food; } this.getDrink = function(){ return _drink; } return this; }) . | 만약에 새 인스턴스로 생성하고 싶다면 . myApp.service('thisService', function(){ var _food = 'Chicken'; var _drink = 'Soda'; this.getFood = function(){ return _food; } this.getDrink = function(){ return _drink; } return new this; }) . | . | . | . | -컨트롤러단에 생성한 서비스를 호출하려면, dependency로 선언해야한다. | . myApp.controller(‘myController’, [‘thisService’, function(thisService){ . }]) . | -서비스를 초기화하려면 new로한다. | . myApp.controller(‘myController’, [‘thisService’, function(thisService){ . var serviceInstance = new thisService; . }]) . | . | 서비스에 선언한 것들에 접근하려면 메소드를 사용한다, | . | . myApp.controller(‘myController’, [‘thisService’, function(thisService){ . var serviceInstance = new thisService; . var someFood = thisService.getFood(); . var someDrink = thisService.getDrink(); . }]) . | Factory 싱글톤 | . (1) Service가 new키워드로 생성하는거랑 다르게 Factory는 새 오브젝트 생성전에 조작이 가능하다. | -Factory선언 | . myApp.factory(‘thisFactory’, function(){ . }) . | -factory로 리턴받을 때 속성 지정 | . myApp.factory(‘thisFactory’, function(){ . var factoryObject = {}; . factoryObject.food = ‘Chicken’; . factoryObject.drink = ‘Soda’; . factoryObject.getAll = function(){ . return factoryObject.food + ‘ ‘ + factoryObject.drink; . } . return factoryObject; . }) . | -새로운 생성자로 리턴받기 | . myApp.factory(‘thisFactory’, function(){ . var factoryObject = {}; . factoryObject.food = ‘Chicken’; . factoryObject.drink = ‘Soda’; . factoryObject.getAll = function(){ . return factoryObject.food + ‘ ‘ + factoryObject.drink; . } . return new factoryObject; . }) . | -컨트롤러에 factory를 선언할때, dependency로 선언한다 | . myApp.controller(‘myController’, [‘thisFactory’, function(thisFactory){ . }]) . | -factory의 하위 속성에 접근해서 함수를 사용하고자 할떄 | . myApp.controller(‘myController’, [‘thisFactory’, function(thisFactory){ . var someFood = thisFactory.food; . var someDrink = thisFactory.drink; . var someOfAll = thisFactory.getAll(); . }]) . ",
    "url": "http://localhost:4000/docs/mooc/etc/edx_angularjs/#edx-angularjs-%EC%88%98%EA%B0%95-%ED%9B%84-%EC%A0%95%EB%A6%AC",
    "relUrl": "/docs/mooc/etc/edx_angularjs/#edx-angularjs-수강-후-정리"
  },"91": {
    "doc": "AngularJS Advanced Framework Techniques",
    "title": "reference",
    "content": "https://docs.angularjs.org/api/ng . ",
    "url": "http://localhost:4000/docs/mooc/etc/edx_angularjs/#reference",
    "relUrl": "/docs/mooc/etc/edx_angularjs/#reference"
  },"92": {
    "doc": "AngularJS Advanced Framework Techniques",
    "title": "AngularJS Advanced Framework Techniques",
    "content": " ",
    "url": "http://localhost:4000/docs/mooc/etc/edx_angularjs/",
    "relUrl": "/docs/mooc/etc/edx_angularjs/"
  },"93": {
    "doc": "Effective Java",
    "title": "effective java 정리",
    "content": ". | 생성자 대신 정적 팩터리 메서드를 고려하라 . ex1) valueOf public static Boolean valueOf(boolean b) { return b ? Boolean.TRUE : Boolean.FALSE; } ex2) instance or getInstance Object newArray = Array.newInstance(classObject, arrayLen); // instance 혹은 //getInstance와 같지만, 매번 새로운 인스턴스를 생성해 반환함을 보장한다. ex3) getType FileStore fs = Files.getFileStore(path); // getInstance와 같으나, 생성할 클래스가 아닌 다른 클래스에 팩터리 메서드를 정의할 때 쓴다. \"Type\"은 팩터리 메서드가 반환할 객체의 타입이다. (1) 장점 . | 이름을 가질 수 있다. : 생성자만으로는 반환될 객체의 특성을 제대로 설명하지 못한다. 여러개의 생성자만으로는 어떤 역할을 하는지 구분하기 어렵다. | 호출될 때마다 인스턴스를 새로 생성하지 않아도 된다. : 생성 비용이 큰 객체가 자주 요청되는 상황이라면 성능을 높일 수 있다. 플라이웨이트 패턴도 비슷한 기법이라고 할 수 있다. | 인스턴스 통제가 가능하다. : 반복되는 요청에 같은 객체를 반환하는 식으로 언제 어느 인스턴스를 살아 있게 할지 철저히 통제할 수 있다. 즉, 싱글턴으로 만들수 있고 인스턴스화불가 상태로 만들 수도 있다. 예를 들어 인스턴스 통제를 통해 Enum타입을 인스턴스가 하나만 만들어짐을 보장한다. | 반환 타입의 하위 타입 객체를 반환할 수 있는 능력이 있다. : API를 만들때 응용하면 구현 클래스를 공개하지 않고도 그 객체를 반환할 수 있어서 API를 작게 유지할 수 있다. | 입력 매개변수에 따라 매번 다른 클래스의 객체를 반환할 수 있다. :반환 타입의 하위 타입이기만 하면 어떤 클래스의 객체를 반환하든 상관없다. (예. EnumSet클래스에선 원소의 수에 따라 RegularEnumSet 또는 JumboEnumSet의 인스턴스를 반환) | 정적 팩터리 메서드를 작성하는 시점에는 반환할 객체의 클래스가 존재하지 않아도 된다. : service provider framework가 그런 경우인데, 클라이언트는 서비스 접근 api를 사용할 때 원하는 구현체의 조건을 명시할 수 있다. 조건이 없으면 기본 구현체를 반환하거나 다른 구현체를 반환한다. | . (2) 단점 . | 상속을 할 수 없다 : 상속을 하려면 public이나 protected 생성자가 필요하니 정적 팩터리 메서드만 제공하면 하위 클래스를 만들 수 없다. | 정적 팩터리 메서드는 프로그래머가 찾기 어렵다. : 생성자처럼 API 문서에 명확히 드러나지 않으니 정적 팩터리 메서드 방식 클래스를 인스턴스화할 방법을 알아내야한다. | . 2. 생성자에 매개변수가 많다면 빌더를 고려하라 . [문제상황] . 매개변수가 많고 호출 경우가 다양해서 생성자로 설정을 하게 되면 보통 사용자가 설정하기 원치 않는 매개변수까지 설정해야하는 경우가 생기는데, 필드가 더 많아지게 되면 값의 의미가 무엇인지 헷갈릴 것이고 매개변수가 몇 개인지도 주의해서 세어보아야 할 것이다. ** 자바빈즈 패턴 : 선택 매개변수가 많을 때 활용할 수 있는데, 매개변수가 없는 생성자로 객체를 만든 후, setter메서드들을 호출해서 원하는 매개변수의 값을 설정하는 방식. 근데 이 자바빈즈 패턴은 일관성이 깨지고, 불변으로 만들수 없다. 디버깅도 어렵고 스레드 안전성도 보장하기 어려움 . [빌더패턴 활용] . | 필수 매개변수만으로 생성자 혹은 정적 팩터리를 호출해서 빌더 객체를 얻는다. | . public class NutritionFacts { private final int servingSize; private final int servings; public static class Builder { private final int servingSize; private final int servings; public Builder(int servingSize, int servings) { this.servingSize = servingSize; this.servings = servings; } } private NutritionFacts(Builder builder) { serviceSize = builder.servingSize; servings = builder.servings; } } . [caller] NutritionFacts cocaCola = new NutritionFacts.Builder(240 ,8) .calories(100).sodium(35).carbohydrate(27).build(); . | 빌더 패턴은 계층적으로 설계된 클래스와 함께 쓰기에 좋다. (피자 예시) . | 각 계층의 클래스에 관련 빌더를 멤버로 정의하고 | 추상 클래스는 추상 빌더를 | 구현 클래스는 구현 빌더를 둔다. | . | 단점 . | 빌더 생성비용에 따라서 성능에 문제가 될 수 있다. | 매개변수가 4개 이상일 때, 점층적 생성자 패턴보다 활용 | . | . | private 생성자나 열거 타입으로 싱글턴임을 보증하라 | . | 생성자를 만들지 않으면 자동으로 기본생성자가 만들어지기때문에 인스턴스화가 되버린다. 이때 private생성자를 추가해서 인스턴스화를 막는다. —&gt; 이 방식으로 상속도 막게 된다. (상위 클래스의 생성자에 접근못하므로) | . | 인스턴스화를 막으려거든 private 생성자를 사용하라 . | 자원을 직접 명시하지 말고 의존 객체 주입을 사용하라 . | . | 많은 클래스가 의존하는 자원일 경우, 많이들 정적 클래스로 선언해서 사용하는데, 사용하는 자원에 따라 동작이 달라진다면 정적 유틸리티 클래스나 싱글턴 방식은 맞지 않다. | 인스턴스를 생성할 때 생성자에 필요한 자원을 넘겨주는 방식으로 해본다. | . public class SpellChecker { private final Lexiton dictionary; public SpellCheck(Lexiton dictionary) { this.dictionary = Objects.requireNonNull(dictionary); } } . | 불필요한 객체 생성을 피하라 . | . | 생성자 대신 정적 팩터리 메서드를 만들면 불필요한 객체 생성을 피할 수 있다. | . (ex. Boolean.valueOf(String) ) . | 하지만 문자열을 검사하는 메소드의 경우는 비용이 드므로, 캐싱해서 재사용하도록 한다. | . (ex. Pattern은 정규표현식에 해당하는 finite state machine을 만들기 때문에 인스턴스 생성 비용이 높다. —&gt; 이 경우는 Pattern 인스턴스를 클래스 초기화할 때 캐싱해두고 인스턴스를 재사용하면 된다.) . | 오토박싱의 경우도 비용이 든다. 박싱된 기본 타입보다 기본타입을 사용하고 오토박싱이 되지 않도록 한다. | . | finalizer와 cleaner사용을 피하라 | . | 언제 실행될지 예측할 수 없고, 실행될 때까지 열어둔다면 열수 있는 파일 개수에 영향이 가게된다. | 수행여부조차 보장하지 않는다. | 가비지 컬렉터의 효율을 떨어뜨린다 | . | equals | . | 동치성 검사는 언제 하는가, 즉 재정의가 필요할 때는? . | 상위 클래스의 equals가 재정의되지 않았을 때, 주로 값 관련 클래스들이 그렇다 | . | equals를 재정의했으면 반드시 hashcode도 재정의해야한다. | . | toString을 재정의해야하는 이유 . | Object의 기본 toString으로는 정보를 알수 없으므로, 사람이 알아볼수 있는 포맷을 갖춰서 반환하도록 해야한다. | 쓸모없는 메시지로 표시되는 것보단, 알아볼수 있다면 디버깅에도 도움 | toString이 필요없는 경우 | . | 정적 유틸리티 클래스 | 열거타입 클래스 - 자바가 이미 제공하는 것으로 추운 | . | 상속보다는 컴포지션을 사용하라 . | 상속 후 재정의로 인해 발생할 수 있는 오류를 방지해야한다. | 컴포지션 설계 - 재정의가 필요하면, 기존 클래스를 확장하는 대신, 새로운 클래스를 만들고 private필드로 기존 클래스의 인스턴스를 참조하게끔 한다. | 상속은 상위 클래스와 하위 클래스가 순수한 is-a 관계일 때만 써야한다. | . | 인터페이스는 구현하는 쪽을 생각해 설계하라 | . | 디폴트 메서드를 선언하면, 그 인터페이스를 구현한 후 디폴트 메서드를 재정의하지 않은 모든 클래스에서 디폴트 구현이 쓰이게 된다. | 모든 상황에서 불변식을 해치지 않는 디폴트 메서드를 작성하기란 어려운 법이다. | . | . | 태그 달린 클래스보다는 클래스 계층구조를 활용하라 . | 태그 달린 클래스란? | . | 클래스 중에 두가지 이상의 의미를 표현할 수 있으며, 그 중 표현하는 의미를 태그 값으로 알려주는 클래스 | 열거 타입 선언, 태그 필드, switch문 등 코드가 섞여있는 클래스 | 여러 구현이 혼합돼 있어서 가독성이 나쁘다. | 그 클래스에 새로운 의미를 추가할 때마다 모든 switch문에 코드를 추가해야하고 | 인스턴스의 타입만으로는 나타내는 의미를 알 수 없다. | . | . // ex) 태그달린 클래스 class Figure { enum Shape { RECTANGLE, CIRCLE }; final Shape shape; double radius; Figure(double radius) { shape = Shape.CIRCLE: this.radius = radius; } double area() { switch(shape) { case RECTANGLE; return length * width; default: throw new AssertionError(shape); } } } . | 태그달린 클래스 → 클래스 계층 구조로 변경한다. | 계층구조의 root가 되는 추상 클래스를 정의 | 태그값에 따라 동작이 달라지는 메서드들을 루트 클래스의 추상 메서드로 선언한다. | 태그에 상관없이 동작이 동일한 메서드들을 일반 메서드로 선언한다. | . abstract class Figure { abstract double area(); } class Circle extends Figure { final double radius; Circle(double radius) { this.radius = radius; } @Override double area() { return Math.PI * (radius * radius); } } class Rectangle extends Figure { final double length; final double width; @Override double area() { return length * width; } } . | . | raw 타입은 사용하지 마라 . | 로 타입을 쓰게되면 타입 안정성을 잃게 된다. | 비한정적 와일드 카드 타입을 사용하라 - 로타입 컬렉션은 아무 원소나 넣을 수 있으니 타입불변식을 훼손할 수 있는데, Collection&lt;?&gt;은 null외에는 어떤 원소도 넣을 수 없다. | 예외) class리터럴에는 raw타입을 써야한다. - 예를 들어, List.class, String[].class. int.class는 허용하고 List.class 와 List&lt;?&gt;.class는 허용하지 않는다. | . | 배열보다는 리스트를 사용하라 . | 배열은 공변이다. 상위 타입과 하위 타입이 같이 변한다는 것. 반면 제네릭은 불공변이다. | . | 한정적 와일드카드를 사용해 API유연성을 높이라 . | 펙스(PECS) 공식: producer-extends, consumer-super | . | 매개변수화 타입 T가 생산자(producer)라면 &lt;? extends T&gt;를 사용하고 | 소비자(consumer)라면 &lt;? super T&gt;를 사용하라 | . | 제네릭과 가변인수를 함께 쓸 때는 신중하라 . | 제네릭과 varargs를 혼용하면 타입 안전성이 깨진다. | . | . static void dangerous(List&lt;String&gt;... stringLists) { List&lt;Integer&gt; intList = List.of(42); Object[] object = stringLists; objects[0] = intList; String s = stringLists[0].get(0); // ClassCastException발생 } . | 제네릭 varargs배열 매개변수에 값을 저장하는 것은 안전하지 않다. | . | 타입 안전 이종 컨테이너를 고려하라 . | int 상수 대신 열거 타입을 사용하라 . | 열거 타입이 근본적으로 불변이지만, 모든 필드는 final이어야 한다. | 필드를 public으로 선언해도 되지만, private으로 두고 별도의 public접근자 메소드를 두는게 낫다 | . | . public enum Planet { EARTH(3.302e+23, 2.439e6); private final double mass; Planet(double mass) { this.mass = mass; } public double mass() { return mass; } } . | 열거타입 클래스에 상수별로 다르게 동작해야 하는 경우, switch문 대신 상수별 메서드 구현을 사용하자 | 열거타입 상수 일부가 같은 동작을 공유한다면 전락 열거 타입 패턴을 사용하자. | . | 비트 필드 대신 EnumSet을 사용하라. | ordinal 인덱싱 대신 EnumMap을 사용하라. | . Map&lt;Plant.LifeCycle, Set&lt;Planet&gt;&gt; plantsByLifeCycle = new EnumMap&lt;&gt;(Plant.LifeCycle.class); for (Plant.LifeCycle lc : Plant.LifeCycle.values()) { plantsByLifeCycle.put(lc, new HashSet&lt;&gt;()); } for (Plant p :garden) { plantsByLifeCycle.get(p.lifeCycle).add(p); } . | EnumMap은 내부에서 배열을 사용하기 떄문에, ordinal 성능과 비등하다. | 아니면 스트림을 사용하면, 코드를 더 간략하게 할 수 있다 | . Arrays.stream(garden).collect(groupingBy(p -&gt; p.lifeCycle)); Arrays.stream(garden).collect(groupingBy(p -&gt; p.lifeCycle, () -&gt; new EnumMap&lt;&gt;(LifeCycle.class), toSet())); . | 확장할 수 있는 열거 타입이 필요하면 인터페이스를 사용하라. | 열거 타입 자체는 확장할 수 없지만, 인터페이스와 그 인터페이스를 구현하는 기본 열거 타입을 함께 사용해 같은 효과를 낼 수 있다. (예: java.nio.file.LinkOption열거타입은 CopyOption, OpenOption인터페이스를 구현했다) | . | . // Operation.class public interface Operation { double apply(double x, double y); } // BasicOperation.class public enum BasicOperation implements Operation { PLUS(\"+\") { public double apply(double x, double y) {return x + y;} }; private final String symbol; BasicOperation(String symbol) { this.symbol = symbol; } @Override public String toString() { return symbol; } } // 확장가능 열거 타입 ExtendedOperation.class public enum ExtendedOperation implements Operation { EXP(\"^\") { public double apply(double x, double y) { return Math.pow(x, y); } }; private final String symbol; ExtendedOperation(String symbol) { this.symbol = symbol; } @Override public String toString() { return symbol; } } . | 정의하려는 것이 타입이라면 마커 인터페이스를 사용하라 . | 아무 메서드도 담고 있지 않고, 자신을 구현하는 클래스가 특정 속성을 가짐을 표시해주는 인터페이스를 마커 인터페이스라고 한다. (예: Serializable) | 마커 인터페이스가 마커 애너테이션 보다 나은 점 | . | 마커 인터페이스는 이를 구현한 클래스의 인스턴스를 구분하는 타입으로 쓸 수 있다. | 적용 대상을 더 정밀하게 지정할 수 있다. | 애너테이션으로 하면 Element.Type에 한정되는 반면, 인터페이스는 확장하면 그 하위 타입으로 보장된다. | . | . | . ",
    "url": "http://localhost:4000/docs/clipping/java/effective_java/#effective-java-%EC%A0%95%EB%A6%AC",
    "relUrl": "/docs/clipping/java/effective_java/#effective-java-정리"
  },"94": {
    "doc": "Effective Java",
    "title": ":: 람다와 스트림",
    "content": ". | 익명 클래스보다는 람다를 사용하라 | . [as-is] Collections.sort(words, new Comparator&lt;String&gt;() { public int compare(String s1, String s2) { return Integer.compare(s1.length(), s2.length()); } }); [to-be] Collectoins.sort(words, (s1, s2) -&gt; Integer.compare(s1.length(), s2.length())); --&gt; Collection.sort(words, comparingInt(String::length)); --&gt; words.sort(comparingInt(String::length)); . | 전략패턴처럼, 함수 객체를 사용하는 과거 객체 지향 디자인 패턴에는 익명 클래스명 충분했다. | 자바8에서는 추상 메서드 하나짜리 인터페이스를 람다식으로 만들어 간략하게 사용할 수 있다. | 타입을 명시헤야 하는 경우를 제외하고는 람다의 모든 매개변수 타입은 생략하자 | . | 람다는 이름이 없고 문서화도 못한다. | 코드 자체로 동작이 명확히 설명되지 않거나 코드 줄 수가 많아지면 람다를 쓰지 말아야한다. (최대 3줄 안에 끝내는 것이 좋다) | . | 람다 함수 객체가 자신을 참조해야할 때는 this 키워드가 바깥 인스턴스를 가리키기 때문에 쓸수 없다. 이 경우는 익명 클래스를 써야한다. | 람다도 익명 클래스처럼 직렬화 형태가 구현별로 다를 수 있다. 따라서 람다를 직렬화하는 일은 극히 삼가야한다(익명 클래스의 인스턴스도 마찬가지). Comparator처럼 직렬화를 해야만한다면 private정적 중첩 클래스의 인스턴스를 사용하자 | . | 람다보다는 메서드 참조를 사용하라 . | 매개변수가 늘어날수록 메서드 참조로 제거할 수 있는 코드양도 늘어난다. | . | . [as-is] map.merge(key, 1, (count, incr) -&gt; count + incr); [to-be] map.merge(key, 1, Ingeger::sum); . | 람다로 할 수 없는 일이라면 메서드 참조로도 할 수 없다. | 때로는 메서드 참조보다 람다가 더 간결할 때가 있다. | 제네릭 함수 타입의 경우 람다로는 불가능하나 메서드 참조로 가능하다. | . interface G1 { &lt;E extends Exception&gt; Object m() throws E; } interface G2 { &lt;F extends Exception&gt; String m() throws Exception; } interface G extends G1, G2 {} &lt;F extends Exception&gt; () -&gt; String throws F . | 표준 함수형 인터페이스를 사용하라 . | 기본 함수형 인터페이스에 박싱된 기본 타입을 넣어 사용하지는 말자 - 계산이 많을 때 성능이 느려진다. | . | 스트림은 주의해서 사용하라 . | 스트림 파이프라인은 지연 평가된다. 평가는 종단 연산이 호출될 때 이뤄지며 무한 스트림을 다룰 수 있게 해주는 열쇠이다. | 람다에서는 타입 이름을 자주 생략하므로 매개변수 이름을 잘 지어야 스트림 파이프라인의 가독성이 유지된다. | char용 스트림을 지원하지 않기 때문에, char값을 처리할 때는 스트림을 삼가는 편이 낫다. | . | 스트림에서는 부작용 없는 함수를 사용하라 . | 스트림 패러다임의 핵심은 계산을 일련의 변환으로 재구성하는 부분이다. 다른 가변 상태를 참조하지 않고, 함수 스스로도 다른 상태를 변경하지 않는다. | . | . // 잘못된 스트림 사용 Map&lt;String, Long&gt; freq = new HashMap&lt;&gt;(); try (Stream&lt;String&gt; words = new Scanner(file).tokens()) { words.forEach(word -&gt; { // forEach는 그저 스트림이 수행한 연산 결과를 보여주는 일만 해야한다. freq.merge(word.toLowerCase(), 1L, Long::sum); // freq라는 외부 상태를 수정하는 람다를 실행하는 문제 }); } // 올바른 스트림 사용 Map&lt;String, Long&gt; freq = try (Stream&lt;String&gt; words = new Scanner(file).tokens()) { freq = words.collect(groupingBy(String::toLowerCase, counting())); } . | forEach연산은 스트림 계산 결과를 보고할 때만 사용하고, 계산하는데 쓰지 말자. | 스트림의 각 원소가 고유한 키에 매핑되어 있을 때 toMap을 사용할 수 있다 | . // 문자열을 열거타입 상수에 맵핑한다. private static final Map&lt;String, Operation&gt; stringtoEnum = Stream.of(values()).collect( toMap(Object::toString, e -&gt; e)); . // 각 키와 해당 키의 특정 원소를 연관 짓는 맵을 생성하는 수집기 Map&lt;ARtist, Album&gt; topHits = albums.collect( toMap(Album::artist, a -&gt; a, maxBy(comparing(Album::sales)))); . // 마지막에 쓴 값을 취하는 수집기 toMap(keyMapper, valueMapper, (oldVal, newVal) -&gt; newVal) . | 반환 타입으로는 스트림보다 컬렉션이 낫다 . | for-each로 스트림을 반복할 수 없는 이유는 Stream이 Iterable을 extand하지 않아서이다. | 원소 시퀀스를 반환하는 공개API의 반환 타입에는 Collection이나 그 하위 타입을 쓰는게 일반적으로 최선이다 | . | Collection인터페이스는 Iterable의 하위 타입이고 stream메서드도 제공하니 반복과 스트림을 동시에 지원한다. | Array도 Array.asList와 Stream.of메서드로 반복과 스트림을 지원할 수 있다. | . | . public static &lt;E&gt; Stream&lt;List&lt;E&gt;&gt; of(List&lt;E&gt; list) { return IntStream.range(0, list.size()) .mapToObj(start -&gt; IntStream.rangeClosed(Start + 1, list.size()) .mapToObj(end -&gt; list.subList(start, end))) .flatMap(x -&gt; x); } . | 스트림 병렬화는 주의해서 적용하라 . | 환경이 아무디 좋아도 데이터 소스가 Stream.iterate거나 중간 연산으로 limit을 쓰면 파이프라인 병렬화로는 성능 개선을 기대할 수 없다. | 대체로 스트림의 소스가 ArrayList, HashMap, HashSet, ConcurrentHashMap의 인스턴스거나 배열, int 범위, long 범위일 때 병렬화의 효과가 가장 좋다 | . | 데이터를 원하는 크기로 정확하고 손쉽게 나눌 수 있어서 일을 다수의 스레드에 분배하기 좋다는 특징이 있다 | 원소들을 순차적으로 실행할 때의 참조 지역성이 뛰어나다. 참조 지역성은 다량의 데이터를 처리하는 벌크 연산을 병렬화할 때 아주 중요한 요소로 작용한다. | . | . ",
    "url": "http://localhost:4000/docs/clipping/java/effective_java/#-%EB%9E%8C%EB%8B%A4%EC%99%80-%EC%8A%A4%ED%8A%B8%EB%A6%BC",
    "relUrl": "/docs/clipping/java/effective_java/#-람다와-스트림"
  },"95": {
    "doc": "Effective Java",
    "title": ":: 메소드",
    "content": ". | 매개변수가 유효한지 검사하라. | requireNonNull : null검사를 수동으로 하지 않아도 된다. 원하는 예외 메시지를 지정할 수 있다. 입력값을 그대로 반환도 된다. | . | . this.strategy = Objects.requireNonNull(strage, \"전략\"); . | 자바9에서는 Object의 범위 검사 기능을 추가했다. : checkFromIndexSize, checkFromToIndex, checkIndex | . | 적시에 방어적 복사본을 만들라 . | 외부 공격으로부터 인스턴스의 내부를 보호하려면 생서자에서 받은 가변 매개변수 각각을 방어적으로 복사해야 한다. | . | . public Period(Date start, Date end) { this.start = new Date(start.getTime()); // 생성자를 수정해서 매개변수의 방어적 복사본을 만든다. this.end = new Date(end.getTime()); if (this.start.compareTo(this.end) &gt; 0) { throw new IllegalArgumentException(); } } . | 매개변수가 제3자에 의해 확장될 수 있는 타입이라면 방어적 복사본을 만들 때 clone을 사용해서는 안된다. 단 성생저와 달리 접근자 메서드에서는 방어적 복사에 clone을 사용해도 된다. | 방어적 복사에는 성능 저하가 따르고 또 항상 쓸 수 있는 것도 아니다. 복사 비용이 너무 크거나 클라이언트가 그 요소를 잘못 수정할 일이 없음이 신뢰된다면 방어적 복사를 수행하는 대신 해당 구성요소를 수정했을 때의 책임을 클라이언트에 있음을 문서에 명시하도록 하자 | . | 메서드 시그니처를 신중히 설계하라 . | 메서드 이름을 신중히 짓자. 표준 명명 규칙을 따른다 | 편의 메서드를 너무 많이 만들지 말자 | 매개변수 목록은 4개 이하가 좋다 | . | 매개변수를 짧게 줄여주는 기술 . | 여러 메서드로 쪼갠다. List인터페이스가 그렇다 | 잘못하면 메서드가 너무 많아질 수 있지만, 직교성을 높혀서 메서드 수를 줄여줄 수도 있다(직교성이 높다는 것은 공통점이 없는 기능들이 잘 분리되어있다는 뜻) | . | 매개변수 여러개를 묶어주는 도우미 클래스를 만드는 것으로 정적 멤버 클래스를 말한다. | 앞의 두개를 혼합한 것 - 매개변수 타입으로는 클래스보다는 인터페이스가 낫다. | 인터페이스가 있다면 직접 사용하자. 예를들어 HashMap을 넘기지 말고 Map을 사용하자. 그러면 TreeMap, ConcurrentHashMap, TreeMap등도 인수로 건낼 수 있다. - boolean보다는 원소 2개짜리 열거 타입이 낫다. | 메서드 이름상 boolean을 받아야 의미가 더 명확할 때는 예외다) | . | . 52.다중정의는 신중히 사용하라 . | 재정의한 메서드는 동적으로 선택되고, 다중정의한 메서드는 정적으로 선택된다. | 안전하고 보수적으로 가려면 매개변수 수가 같은 다중정의는 만들지 말자. | 가변인수를 사용하는 메서드라면 다중정의를 아예 하지 말아야 한다. | . | 메서드를 다중정의할 때, 서로 다른 함수형 인터페이스라도 같은 위치의 인수로 받아서는 안된다. | -XLint:overloads를 지정하면 이런 종류의 다중정의를 경고해준다. | . | 인수를 포워드하여 두 메서드가 동일한 일을 하도록 보장할 필요가 있다. | String클래스의 contentEquals메서드는 CharBuffer, String, StringBuilder, StringBuffer 등등 비슷한 부류의 타입을 가지고 있고 이들의 공통 인터페이스로 CharSequence가 등장했다. | . public boolean contentEquals(StringBuffer sb) { return contentEquals((CharSequence) sb); } . | String클래스의 valueOf(char[])과 valueOf(Object)는 같은 객체를 건네더라도 전혀 다른 일을 수행한다. | . | . | 가변인수는 신중히 사용하라 . | 가변인수는 인수 개수가 정해지지 않았을 때 유용하다. | 가변인수 메서드는 호출될 때마다 배열을 새로 하나 할당하고 초기화하는 비용이 발생한다. | . | 인수 3개까지는 다중정의 메서드를 만들고 4개부터 가변 인수로 처리하는 방법으로 성능을 개선해볼 수 있다. | . | null이 아닌 빈 컬렉션이나 배열을 반환하라 . | null을 반환하는 API는 사용하기 어렵고 오류 처리 코드도 늘어나기 때문에 빈 컬렉션이나 빈 배열로 반환하도록 한다. | Collections.emptyList, Collections.emptySet, Collections.emptyMap : 빈 컬렉션 할당이 성능을 떨어뜨릴 수 있기 때문에, 불변 컬렉션으로 반환하도록 한다 | 배열도 null을 반환하지 말고 길이가 0인 배열을 반환하라 | . | 그렇다고 미리 할당하지 말자. 성능이 나빠진다. | . | 옵셔널 반환은 신중히 하라 . | 옵셔널을 반환하는 메서드는 예외를 던지는 메서드보다 유연하고 사용하기 쉬우며, null을 반환하는 경우보다 오류 가능성이 작다. | 옵셔널을 반환하는 메서드에서는 절대 null을 반환하지 말자 | . | Optional.of(value)에 null을 넣으면 npe가 발생하니 Optional.ofNullable(value)를 사용하면 된다. - 옵셔널은 검사 예외와 취지가 비슷하다. 즉 반환값이 없을 수도 있음을 API사용자에게 명확히 알려준다. - 옵셔널 활용 | 기본값을 정해둘 수 있다 | . String lastWordInLexicon = max(words).orElse(\"단어 없음...\"); . | 원하는 예외를 던질 수 있다 | . Toy myToy = max(toys).orElseThrow(TemperTantrumException::new); . | 항상 값이 채워져 있다고 가정한다. | . Element lastNobleGas = max(Elements.NOBLE_GASES).get(); . | . | 적합한 메서드를 찾지 못했다면 isPresent를 활용하자. | 자바9에서는 Optional에 stream()메서드가 추가되었다. | 컬렉션, 스트림, 배열, 옵셔널 같은 컨테이너 타입은 옵셔널로 감싸면 안된다. | Optional&lt;List&gt;를 반환하기보다는 빈 List를 반환하는게 좋다. | . | 박싱된 기본 타입을 담는 옵셔널은 기본타입보다 무겁다. OptionalInt, OptionalLong, OptionalDouble이 있다. 박싱된 기본타입을 담은 옵셔널을 반환하는 일은 없도록 하자. 단 Boolean, Byte, Character, Short, Float은 예외일 수 있다. | 옵셔널을 맵의 값으로 사용하면 안된다. | . | 공개된 API요소에는 항상 문서화 주석을 작성하라 . | 문서화 주석 작성법(How to Write Doc Comments)가 업계 표준 API | 메서드가 어떻게 동작하는지가 아닌, 무엇을 하는지를 기술해야한다. (how가 아닌 what을 기술해야 한다) | 포함해야하는 내용 | . | 메서드를 호출하기 위한 전제조건 | 메서드가 성공적으로 수행된 후에 만족해야하는 사후조건 | 부작용에 대한 내용 - 규칙 | ‘@param, ‘@return, ‘@throws태그의 설명에는 마침표를 붙이지 않는다. | 제네릭 타입이나 제네릭 메서드를 문서화할 때는 모든 타입 매개변수에 주석을 달아야 한다. | 열거타입을 문서화할 때는 상수들에도 주석을 달아야 한다. | 애너테이션 타입을 문서화할 때는 멤버들에도 모두 주석을 달아야 한다. | 클래스 혹은 정적 메서드가 스레드 안전하든 그렇지 않든, 스레드 안전 수준을 반드시 API설명에 포함해야 한다. | . | . ",
    "url": "http://localhost:4000/docs/clipping/java/effective_java/#-%EB%A9%94%EC%86%8C%EB%93%9C",
    "relUrl": "/docs/clipping/java/effective_java/#-메소드"
  },"96": {
    "doc": "Effective Java",
    "title": ":: 일반적인 프로그래밍 원칙",
    "content": ". | 지연변수의 범위를 최소화하라 . | 메서드를 작게 유지하고 한 가지 기능에 집중한다 | . | . for (int i = 0, n = expensiveComputation(); i &lt; n; i++) { // 반복 변수 i,n에서, 반복여부를 결정짓는 i의 한계값을 n에 저장해서 반복 때마다 다시 계산해야하는 비용을 없앤다. } . | 라이브러리를 익히고 사용하라 . | Random을 사용하지 말고 ThreadLocalRandom으로 대체한다.(성능 좋음) | 포트 조인 풀이나 병렬 스트림에서는 SplittableRandom을 사용한다. | . | 박싱된 기본 타입보다는 기본 타입을 사용하라. | 기본 타입은 값만 가지고 있지만, 박싱된 기본타입은 값 + 식별성(identity)를 갖고 있다. | . | new Integer(42), new Integer(42) 로 연산하면, 두개가 다른 값으로 식별된다. 즉 같은 객체를 비교하는 것이 아니면 박싱된 기본 타입에 == 연산자를 사용할 시 오류가 빌생한다. - 박싱된 기본타입은 null을 가질 수 있다 - 기본타입이 박싱된 기본 타입보다 시간과 메모리 사용면에서 더 효율적이다. | 박싱과 언박싱을 반복해서 일어나게 연산되는 경우를 만들면 안된다. - 기본타입과 박싱된 기본 타입을 혼용한 연산에서는 박싱된 기본타입의 박싱이 자동으로 풀린다. - 박싱된 기본 타입을 사용하는 경우 | 컬렉션의 원소, 키, 값으로 쓴다. 컬렉션은 기본타입을 담을 수 없으므로… . | 예) ThreadLocal는 안되고 ThreadLocal를 써야한다. | . | 리플렉션을 통해 메서드를 호출할 때도 박싱된 기본 타입을 사용한다. | . | 다른 타입이 적절하다면 문자열 사용을 피하라 . | 문자열은 다른 타입, 열거타입, 혼합타입을 대신하기에 적합하지 않다. | . | 오류가능성도 꺼지고, 파싱해야해서 느리고 | string에서 제공하는 기능에만 의존해야한다. - 권한을 표현하기에 적합하지 않다. | 예를 들어 쓰레드 지역변수를 선언할 때, 클라이언트에서 호출된 문자열로 쓰레드별 지역변수를 식별하게 되면, . | 각 클라이언트별로 고유한 키가 있어야하고 (공유되면 안되니까) | 결국 보안도 취약해진다. | . | 그래서 문자열 대신 Object클래스로 선언해본다. | . public final class ThreadLocal&lt;T&gt; { public ThreadLocal(); public void set(T value); public T get(); } . | 문자열 연결은 느리니 주의하라 . | 문자열 n개를 잇는 시간은 n제곱승에 비례한다. 문자열은 불변이라서 두 문자열을 연결한다치면 양쪽의 내용을 모두 복사해야 하므로 성능 저하가 발생한다. | String대신 StringBuilder를 사용하자 | . | 객체는 인터페이스를 사용해 참조하라 . | 적합한 인터페이스만 있다면 매개변수뿐 아니라 반환값, 변수, 필드를 전부 인터페이스 타입으로 선언하라 | . | 객체체의 실제 클래스를 사용해야 할 상황은 오직 생성자로 생성할 뿐이다. | . | . Set&lt;Son&gt; sonSet = new LinkedHashSet&lt;&gt;(); . | 예외. | String이나 Integer같은 값 클래스의 경우 인터페이스로 설계할일이 거의 없으므로 클래스로 참조해야한다. | 클래스 기반으로 작성된 프레임워크의 객체들의 경우 인터페이스가 없다. OutputStream등 java.io패키지의 클래스들이 여기에 해당 | PriorityQueue클래스는 Queue인터페이스에는 없는 comparator메서드를 제공하는데 이 메소드를 꼭 사용해야하는 경우는 예외로 사용가능하다. | . | . | 리플렉션보다는 인터페이스를 사용하라 . | 리플렉션 단점 | . | 컴파일타임 타입검사가 주는 이점을 하나도 누릴 수 없다. | 리플렉션을 이용하면 코드가 지저분하고 장황해진다. | 성능이 떨어진다. | . | 네이티브 메서드는 신중히 사용하라 . | 네이티브 언어는 자바보다 플랫폼을 많이 타서 이식성도 낮고 디버깅도 어려우며 성능에도 안좋다. | . | 최적화는 신중히 하라 . | 최적화 규칙 | . | 하지마라 | 완전히 명백하고 최적화되지 않은 해법을 찾을 때까지는 하지마라 | 각각의 최적화 시도 전후로 성능을 측정하라 - 성능을 제한하는 설계를 피하라 | 완성 후 변경하기 어려운 컴포넌트끼리 또는 외부 시스템과의 통신하는 경우(API, 네트워크 프로토콜, 영구 저장용 데이터 포맷 등) - 프로파일링 도구를 활용한다 | jmh | . | 일반적으로 통용되는 명명 규칙을 따르라 . | 자바언어명세 jls, 6.1 | 패키지명 | . | 8자 이하의 짧은 단어로 한다. | utilities보다는 util | . | 여러 단어로 구성된 이름이면 약어로 해도 된다. - 타입 매개변수 | 보통 한 문자로 표현한다 . | T : 임의의 타입 | E : 컬렉션 원소 타입 | K, V : 맵의 키와 값 | X : 예외 | R : 메서드 반환 타입 | T, U, V : 그 외에 임의 타입 시퀀스 . | 문법 규칙 | . | . | 패키지 : 따로 규칙 없다. | 클래스 . | 객체를 생성할 수 있는 클래스(열거타입 포함) 의 이름은 보통 단수 명사나 명사구를 사용 . ex) Thread, PriorityQueue, ChessPiece 등 . | 객체를 생성할 수 없는 클래스의 이름은 . | 복수형 명사 : Collectors, Collections 등 | 인터페이스 이름은 . | 클래스와 똑같이 짓는다 : Collection, Comparator | 형용사로 짓는다 : -able, -ible . ex) Runnable, Iterable, Accessible 등 . | . | . | . | 메서드 . | 동사나 목적어를 포함한 동사구로 짓는다 | boolean을 반환하는 메서드면 . | is, has + 명사/명사구/형용사로 기능하는 단어나 구로 구성한다 . ex) isDigit, isEmpty, isEnabled, hasSiblings . | . | 해당 인스턴스의 속성을 반환하는 메서드 . | 명사, 명사구, get으로 시작하는 동사구로 짓는다. | . | 객체의 타입을 바꿔서 반환하는 메서드 . | to + Type형태로 한다. ex) toString, toArray등 . | . | 객체의 내용을 다른 뷰로 보여주는 메서드 . | as + Type 형태로 한다. ex) asList . | . | 객체의 값을 기본 타입 값으로 반환하는 메서드 . | type + Value형태로 한다 . ex) intValue . | . | 정적 팩터리의 경우 . ex) valueOf, instance, getInstance, newInstance, getType, newType . | . | . | . ",
    "url": "http://localhost:4000/docs/clipping/java/effective_java/#-%EC%9D%BC%EB%B0%98%EC%A0%81%EC%9D%B8-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D-%EC%9B%90%EC%B9%99",
    "relUrl": "/docs/clipping/java/effective_java/#-일반적인-프로그래밍-원칙"
  },"97": {
    "doc": "Effective Java",
    "title": ":: 예외",
    "content": ". | 복구할 수 있는 상황에는 검사 예외를, 프로그래밍 오류에는 런타임 예외를 사용하라 . | 런타임 예외의 대부분은 전제조건을 만족하지 못했을 때 발생한다. API명세에 맞는 제약을 지키지 못했다는 뜻이다. 이 경우 복구할 수 있는 상황인지를 구분할 수 없다. 복구가 가능하다면 검사 예외를 그 외에는 런타임 예외를 사용하자 | . | 필요없는 검사 예외 사용은 피하라 . | API를 제대로 사용해도 발생할 수 있는 예외이거나, 프로그래머가 의미 있는 조치를 취할 수 있는 경우 외에는 비검사 예외를 사용하는 것이 좋다. | . | 표준 예외를 사용하라 . | 표준 예외를 재사용하라 - 예외 클래스 수가 적을수록 메모리 사용량도 줄고 클래스 적재하는 시간도 적게 걸린다. | 대표되는 재사용 표준 예외 | . | IllegalStateException . | 인수값이 무엇이었든 어차피 실패했을 것라면 IllegaStateException | 그렇지 않으면 IllegalArgumentException | . | ConcurrentModificatonException : 단일 스레드에서 사용하려고 설계한 객체를 여러 스레드가 동시에 수정하려고 할 때 | UnsupportedOperationException - 예외 | Exception, RuntimeException, THrowable, Error는 직접 재사용하지 말자. 이 예외들은 추상 클래스라고 생각하자 | . | 메서드가 던지는 모든 예외를 문서화하라 . | 검사 예외는 항상 따로따로 선언하고, 각 예외가 발생하는 상황을 자바독의 ‘@throws태그를 사용하여 정확히 문서화 하자 | . | 메서드가 Exception이나 Throwable을 던진다고 선언해서는 안된다. 메서드는 사용자에게 각 예외를 대처할 수 있는 힌트를 줘야한다. 같은 맥락에서 발생할 여지가 있는 다른 예외들까지 삼켜버릴 수 있어 API 사용성을 크게 떨어뜨린다. - 메서드가 던질 수 있는 예외를 각각 ‘@throws태그로 문서화하되, 비검사 예외는 메서드 선언의 throws목록에 넣지말자. 그 이유는 검사냐 비검사냐에 따라 API 사용자가 해야 할 일이 달라지므로 두개를 확실히 구분해주는 것이 좋기 때문이다. | . | 가능한 한 실패 원자적으로 만들라 . | 호출된 메서드가 실패하더라도 해당 객체는 메서드 호출 전 상태를 유지해야 한다. | 실패 원자적으로 만드는 방법 | . | 불변 객체로 설계하는 것 : 실패하더라도 변하지 않으므로 객체가 불안정한 상태에 빠지지 않는다. | 작업 수행에 앞서 매개변수의 유효성을 검사하는 것 | 객체의 임시 복사본에서 작업을 수행한 다음, 작업이 성공적으로 완료되면 원래 객체와 교체하는 것 | 작업도중 발생하는 실패를 가로채는 복구 코드를 작성하여 작업 전 상태로 되돌리는 방법 | . | 예외를 무시하지 말라. | 예외를 무시하기로 했다면 catch 블록 안에 그렇게 결정한 이유를 주석으로 남기고 예외 변수의 이름도 ignored로 바꿔놓도록 하자. | . | . try { } catch (TimeoutException | ExecutionException ignored) { // 기본값을 사용한다 } . ",
    "url": "http://localhost:4000/docs/clipping/java/effective_java/#-%EC%98%88%EC%99%B8",
    "relUrl": "/docs/clipping/java/effective_java/#-예외"
  },"98": {
    "doc": "Effective Java",
    "title": ":: 동시성",
    "content": ". | 공유중인 가변 데이터는 동기화해 사용하라 . | 언어 명세상 long과 double 외의 변수를 읽고 쓰는 동작은 원자적(atomic)이다. 즉, 여러 스레드가 같은 변수를 동기화 없이 수정하는 중이라도, 항상 어떤 스레드가 정상적으로 저장한 값을 온전히 읽어옴을 보장한다는 뜻이다. | 동기화는 배타적 실행뿐 아니라 스레드 사이의 안정적인 통신에 꼭 필요하다. | 여러 스레드가 가변 데이터를 공유한다면 그 데이터는 읽고 쓰는 동작은 반드시 동기화해야한다. 아니면 불변 데이터만 공유하거나 아무것도 공유하지 말자. 가변 데이터는 단일 스레드에서만 쓰도록 하자 | . | 과도한 동기화는 피하라 . | 동기화된 영역 안에서는 재정의할 수 있는 메서드는 호출하면 안된다 | 클라이언트가 넘겨준 함수 객체를 호출해서도 안된다 | 동기화 영역에서는 가능한 한 일을 적게 하는 것 | . | 쓰레드보다는 실행자, 태스크, 스트림을 애용하라 . | 실행자 | . | 가벼운 서버라면 Executors.newCachedThreadPool이 일반적으로 좋다 . | CachedThreadPool은 요청받은 태스크들이 큐에 쌓이지 않고 즉시 스레드에 위임돼 실행된다. 그래서 무거운 어플리케이션엔 맞지 않다 | . | 무거운 서버라면 Executors.newFixedThreadPool을 사용하거나 ThreadPoolExecutor를 직접 선언하도록 한다. | 자바7에서부터 실행자 프레임워크는 fork-join태스크를 지원한다. - 태스크 | 태스크는 실행자 프레임워크에서 작업단위를 나타내는 추상 개념으로 Runnable, Callable이 있다. | 포크 조인 태스크 . | 포크 조인풀이라는 특별한 실행자 서비스를 실행한다. | ForkJoinTask의 인스턴스는 작은 하위 태스크로 나뉠 수 있고일을 먼저 끝넨 태스크는 다른 스레드의 남은 태스크를 가져와 대신 처리할 수 있다. | . | . | wait와 notify보다는 동시성 유틸리티를 애용하라 . | 동시성 유틸리티의 범주 | . | 실행자 프레임워크 | 동시성 컬렉션(concurrent collection) . | List, Queue, Map 과 같은 표준 컬렉션 인터페이스에 동시성을 가미해 구현한 고성능 컬렉션이다. | 높은 동시성을 수행하기 위해 각자 내부에서 동기화를 수행한다. | 따라서 동시성 컬렉션에서 동기화를 사용안하게 하는 것은 불가능하고 외부에서 락을 걸면 오히려 성능이 떨어진다. | Collections.synchronizedMap보다 ConcurrentHashMap을 사용하는 것이 훨씬 좋다. 동기화된 맵을 동시성 맵으로 교체하는 것만해도 성능이 극적으로 개선된다. | . | 동기화 장치(synchronizer) . | 스레드가 다른 스레드를 기다릴 수 있게 해서, 서로 작업을 조율할 수 있게 해준다. (CountDownLatch, Semaphore) . | wait와 notify를 써야한다고 하면, wait는 항상 표준 관용구에 따라 while문안에서 호출하도록하자 | 일반적으로 notify보다는 notifyAll을 사용해야 한다. | . | . | . | 쓰레드 안전성 수준을 문서화하라 . | 스레드 안전성이 높은 순서 | . | 불변 (‘@Immutable): 이 클래스의 인스턴스는 상수처럼 외부 동기화가 필요없다(String, Long, BigInteger..등) | 무조건적 스레드 안전 (‘@ThreadSafe): 인스턴스는 수정될 수 있으나, 내부에서 동기화하여 별도의 외부 동기화 없이 동시에 사용해도 안전하다(AtomicLong, ConcurrentHashMap) | 조건부 스레드 안전 : 일부 메서드는 동시에 사용하려면 외부 동기화가 필요하다.(Collections.synchronized 래퍼 메서드가 반환한 컬렉션들) | 스레드 안전하지 않음(‘@NotThreadSafe) : 동시에 사용하려면 각각의 메서드 호출을 클라이언트가 선택한 외부 동기화 매커니즘으로 감싸야한다 (ArrayList, HashMap 같은 기본 컬렉션) | 스레드 적대적 : 이 클래스는 모든 메서드 호출이 멀티 스레드에 안전하지 않다. 이 경우 deprecated API로 지정하거나 한다. (generateSerialNumber메서드가 없으면 해당) - 반환 타입만으로 명확히 할 수 없는 정적 팩터리라면 객체의 스레드 안전성을 문서화해야한다 - 열거 타입은 굳이 불변으로 안써도 된다 | . | 지연 초기화는 신중히 사용하라 . | 지연 초기화란? | . | 필드이 초기화 시점을 그 값이 처음 필요할 때까지 늦추는 기법 - 지연 초기화는 양날의 검이다. 클래스 또는 인스턴스 생성 시의 초기화 비용은 줄지만 지연 초기화하는 필드에 접근하는 비용은 커진다. - 멀티 스레드 환경에서는 지연 초기화해야하는 필드를 둘 이상의 스레드가 공유한다면 반드시 동기화해야 한다. - 대부분의 상황에서 일반적인 초기화가 지연 초기화보다 낫다. - 지연 초기화가 초기화 순환성을 깨뜨릴 것 같으면 synchronized를 단 접근자를 사용하자 | . | . private FieldType field; private synchronized FieldType getField() { if (field == null) rield = computeFieldValue(); return field; } . | 성능 때문에 정적 필드를 지연 초기화해야한다면 지연 초기화 홀더 클래스 관용구를 사용하자 | . private static class FieldHolder { static final FieldType field = computeFieldValue(); } private static FieldType getField() { return FieldHolder.field; } // getField가 호출되는 순간 Fieldholder.field가 처음 읽히면서, FieldHolder클래스 초기화가 이뤄진다. // 이 관용구는 getField메서드가 필드에 접근하면서 동기화를 전혀하지 않으니 성능이 느려질게 없다. | 성능 때문에 인스턴스 필드를 지연 초기화해야 한다면 이중검사 관용구를 사용하라. | 한번은 동기화 없이 검사하고, 한번은 동기화해서 검사한다. 두번 째 검사에서도 필드가 초기화되지 않았을 때만 초기화하도록 한다. | 필드가 초기화된 후로는 동기화하지 않으므로 해당 필드는 반드시 volatile로 선언해야한다. | . | . private volatile FieldType field; private FieldType getField() { FieldType result = field; if (result != null) { // 초기화된 상황에서는 필드를 한번만 읽도록 보장. 첫번째 검사 return result; } synchronized(this) { if (field == null) { // 두 번째 검사 field = computeFieldValue(); } return field; } } . | 대부분의 필드는 지연 초기화가 필요없다. 꼭 지연 초기화를 써야한다면 인스턴스 필드에는 이중검사 관용구를, 정적 필드에는 지연 초기화 홀더 클래스 관용구를 사용하자. | . | 프로그램의 동작을 스레드 스케쥴러에 기대지 말라 . | 여러 스레드가 실행중이면 운영체제의 스레드 스케쥴러가 어떤 스레드를 얼마나 오래 실행할지 결정한다. 정확성이나 성능이 스레드 스케쥴러에 따라 달라지는 프로그램이라면 다른 플랫폼에 이식하기 어렵다 | 실행 가능한 스레드 수를 프로세서 수보다 지나치게 많아지지 않게 하는 것이 중요하다. | 스레드가 작업이 완료되면, 다음 작업이 있을 때까지 대기하게 하는 것이 좋다. 즉 스레드 풀을 적절하게 설정하고 작업은 짧게 유지한다. | 스레드는 busy waiting 상태가 되면 안된다. 이 상태는 스레드 스케쥴러에 취약하고 프로세스에 큰 부담을 준다. | 스레드 우선순위나 Thread.yield로 해결하려고 하면 안된다. 이식성도 떨어지고 합리적인 조치가 아니다. | . | . ",
    "url": "http://localhost:4000/docs/clipping/java/effective_java/#-%EB%8F%99%EC%8B%9C%EC%84%B1",
    "relUrl": "/docs/clipping/java/effective_java/#-동시성"
  },"99": {
    "doc": "Effective Java",
    "title": "::직렬화",
    "content": ". | 자바 직렬화의 대안을 찾아라 . | 직렬화 위험을 회피하는 가장 좋은 방법은 아무것도 역직렬화하지 않는 것이다. | . | 크로스-플랫폼 구조화된 데이터 표현 . | json : 텍스트 기반 표현에는 효과적 | 프로토콜 버퍼 . | 자바 직렬화를 피할 수 없다면, 신뢰할 수 없는 데이터는 절대 역직렬화하지 않는 것이다. | . | . | 객체 역직렬화 필터링(java.io.ObjectInputFilter)을 사용하자 | . | Serializable을 구현할지는 신중히 결정하라 . | Serializable을 구현하면 릴리스한 뒤에는 수정하기 어렵다. 직렬화 형태도 하나의 공개 API가 된다. | 직렬화가 클래스 개선을 방해하는 예 | . | 스트림 고유 식별자, 즉 직렬 버전 UID가 없으면 시스템이 런타임에 암호해시 함수를 적용해 자동으로 클래스 안에 생성해 넣는다. 그런데 자동으로 생성되면 나중에 클래스가 수정되면 uid값도 변경되기 때문에 호환성이 꺠져버려 런타임에 InvalidClassException이 발생한다. | 버그와 보안 구멍이 생길 위험이 높아진다. | 직렬화는 언어의 기본 매커니즘을 우회하는 객체 생성 기법인 것이다. 역직렬화는 일반 생성자의 문제가 그대로 적용되는 ‘숨은 생성자’다. 기본 역직렬화를 사용하면 불변식 깨짐과 허가되지 않은 접근에 쉽게 노출된다는 뜻이다. | . | 해당 클래스의 신 버전을 릴리스할 때 테스트할 것이 늘어난다는 것이다. | 상속용으로 설계된 클래스는 대부분 Serializable을 구현하면 안되며, 인터페이스도 대부분 Serializable을 확장해서는 안된다. | 내부클래스는 직렬화를 구현하지 말아야 한다. | . | 커스텀 직렬화 형태를 고려해보라 . | 자바의 기본 직렬화 형태는 객체를 직렬화한 결과가 해당 객체의 논리적 표현에 부합할 때만 사용하고, 그렇지 않으면 객체를 적절히 설명하는 커스텀 직렬화 형태를 고안하라 | 구버전으로 직렬화된 인스턴스들과의 호환성을 끊으려는 경우를 제외하고는 직렬 버전 uid를 절대 수정하지말자. | . | readObject 메서드는 방어적으로 작성하라 . | readObject메서드를 작성할 때는 항상 public생성자를 작성하는 자세로 해야한다. | readObject는 어떤 바이트 스트림이 넘어오더라도 유효한 인스턴스를 만들어내야한다. 바이트 스트림이 진짜 직렬화된 인스턴스라고 가정해서는 안된다. | . | 인스턴스 수를 통제해야 한다면 readResolve보다는 열거 타입을 사용하라. | 불변식을 지키기 위해 인스턴스를 통제해야 한다면 가능한 한 열거 타입을 사용하자 | . | . public enum Elvis { INSTANCE; private String[] favoriteSongs = { \"Hound Dog\", \"Heartbreak Hotel\"}; public void printFavorites() { System.out.println(Arrays.toString(favoriteSongs)); } } . | implement Serializable을 추가하면 싱글턴이 아니게 되는데, readResolve기능을 이용하면 readObject가 만들어낸 인스턴스를 다른 것으로 대체할 수 있다. 그리고 그 클래스에서 모든 참조 타입 인스턴스 필드를 transient로 선언해야한다. | . | 직렬화된 인스턴스 대신 직렬화 프록시 사용을 검토하라 . | 직렬화를 구현하게 되면 버그와 보안 문제가 일어나게 되는데 그 위험을 줄여줄 기법으로 직렬화 프록시 패턴(serialization proxy pattern)이 있다. | . | . private Object writeReplace() { // 직렬화 프록시 패턴용 writeReplace 메서드 return new SerializationProxy(this); } . | 직렬화 프록시 패턴 단점 . | 클라이언트가 확장할 수 있는 클래스에는 적용할 수 없다 | 객체 그래프에 순환이 있는 클래스에도 적용할 수 없다. | 방어적 복사보다 성능이 안좋다. | . | . ",
    "url": "http://localhost:4000/docs/clipping/java/effective_java/#%EC%A7%81%EB%A0%AC%ED%99%94",
    "relUrl": "/docs/clipping/java/effective_java/#직렬화"
  },"100": {
    "doc": "Effective Java",
    "title": "Effective Java",
    "content": " ",
    "url": "http://localhost:4000/docs/clipping/java/effective_java/",
    "relUrl": "/docs/clipping/java/effective_java/"
  },"101": {
    "doc": "Elastic Search",
    "title": "Elastic Search",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/elastic-search/elasticsearch/",
    "relUrl": "/docs/msa/elastic-search/elasticsearch/"
  },"102": {
    "doc": "elasticsearch field add(1)",
    "title": "[기존 데이터에 추가하는 방식]",
    "content": "💡 *데이터가 적고, 서버에 문제가 없을 경우에만 사용합니다. (로컬의 경우에만 진행하도록 합니다.)* 1. 현재 적용된 맵핑 정보를 조회한다. GET attic_ticket/_mapping . 2. 위에서 조회한 맵핑 정보를 참고해서, depth에 맞게 컬럼을 추가한다. PUT attic_ticket/_mappings { \"properties\": { \"customer\" : { \"type\":\"nested\", \"properties\": { \"messengerId\": { // customer에 messengerId 컬럼 추가 \"type\": \"text\" } } } } } . 3. 잘 추가되었는지 확인한다 . GET attic_ticket/_mapping . 4. 기존 데이터에 추가한 필드를 업데이트 한다.( multiple update ) . POST attic_ticket/_update_by_query { \"script\": \"ctx._source.customer.messengerId = ''\" } . ",
    "url": "http://localhost:4000/docs/msa/elastic-search/elasticsearch_add_field_1/#%EA%B8%B0%EC%A1%B4-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%97%90-%EC%B6%94%EA%B0%80%ED%95%98%EB%8A%94-%EB%B0%A9%EC%8B%9D",
    "relUrl": "/docs/msa/elastic-search/elasticsearch_add_field_1/#기존-데이터에-추가하는-방식"
  },"103": {
    "doc": "elasticsearch field add(1)",
    "title": "** (필드가 배열인 경우) **",
    "content": "5-1. 기존 배열 삭제 . POST attic_message/_update_by_query { \"script\": { \"source\": \"ctx._source.remove('metaarray')\" }, \"query\":{ \"bool\": { \"should\": [ { \"terms\": { \"channelUrl\": [ \"92095428-d647-466c-a054-e1e984dd48b1\" ] } } ] } } } . 5-2. 배열 초기화 . POST attic_message/_update_by_query { \"script\": \"ctx._source.metaarray = []\", \"query\":{ \"bool\": { \"should\": [ { \"terms\": { \"channelUrl\": [ \"92095428-d647-466c-a054-e1e984dd48b1\" ] } } ] } } } . 5-3. 배열에 값 추가 . POST attic_message/_update_by_query { \"script\": { \"source\":\"ctx._source.metaarray.add(params)\", \"params\": { \"key\": \"templateMessage\", \"value\":[ \"{~~~~~~~~~~}\" ] } }, \"query\":{ \"bool\": { \"should\": [ { \"terms\": { \"channelUrl\": [ \"92095428-d647-466c-a054-e1e984dd48b1\" ] } } ] } } } . 5. 검증 . | 일부 티켓에만 추가한 필드에 값을 업데이트해본다. | . POST attic_ticket/_update_by_query { \"script\": { \"source\":\"ctx._source.customer.messengerId = 'honggildong'\" }, \"query\":{ // 일부 ticket에만 값을 업데이트하고 \"term\":{ \"ticketId\":\"63af9a77-845b-4ca5-b692-0d3e5cc7d398\" } } } . | 추가한 값으로 검색해본다. | . GET attic_ticket/_search { \"query\" : { \"bool\": { \"should\":[{ \"terms\":{ \"ticketId\":[\"63af9a77-845b-4ca5-b692-0d3e5cc7d398\"],\"boost\":1.0 } }] } } } . 참고) https://esbook.kimjmin.net/04-data/4.3-_bulk . ",
    "url": "http://localhost:4000/docs/msa/elastic-search/elasticsearch_add_field_1/#-%ED%95%84%EB%93%9C%EA%B0%80-%EB%B0%B0%EC%97%B4%EC%9D%B8-%EA%B2%BD%EC%9A%B0-",
    "relUrl": "/docs/msa/elastic-search/elasticsearch_add_field_1/#-필드가-배열인-경우-"
  },"104": {
    "doc": "elasticsearch field add(1)",
    "title": "elasticsearch field add(1)",
    "content": "💡 지금까지 찾아본 방식 중 2가지를 정리 [공통] . 기존 데이터 백업을 진행합니다. 스냅샷 백업 방식은 “여기” 참고하세요. ",
    "url": "http://localhost:4000/docs/msa/elastic-search/elasticsearch_add_field_1/",
    "relUrl": "/docs/msa/elastic-search/elasticsearch_add_field_1/"
  },"105": {
    "doc": "elasticsearch field add(2)",
    "title": "[Alias를 활용하는 방식]",
    "content": "💡 무중단 방식인 만큼, 데이터가 많은 경우 size를 나눠서 진행하고, 백업은 필수로 합니다. ",
    "url": "http://localhost:4000/docs/msa/elastic-search/elasticsearch_add_field_2/#alias%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%98%EB%8A%94-%EB%B0%A9%EC%8B%9D",
    "relUrl": "/docs/msa/elastic-search/elasticsearch_add_field_2/#alias를-활용하는-방식"
  },"106": {
    "doc": "elasticsearch field add(2)",
    "title": "1. 현재 적용된 맵핑 정보를 조회한다.",
    "content": "GET attic_ticket/_mapping . ",
    "url": "http://localhost:4000/docs/msa/elastic-search/elasticsearch_add_field_2/#1-%ED%98%84%EC%9E%AC-%EC%A0%81%EC%9A%A9%EB%90%9C-%EB%A7%B5%ED%95%91-%EC%A0%95%EB%B3%B4%EB%A5%BC-%EC%A1%B0%ED%9A%8C%ED%95%9C%EB%8B%A4",
    "relUrl": "/docs/msa/elastic-search/elasticsearch_add_field_2/#1-현재-적용된-맵핑-정보를-조회한다"
  },"107": {
    "doc": "elasticsearch field add(2)",
    "title": "2. 위에서 조회한 맵핑 정보를 복사해서, 새로운 필드을 추가하고 새로운 맵핑정보를 가진 인덱스를 생성한다.",
    "content": "PUT attic_ticket_new // attic_ticket_new 인덱스를 생성 { \"mappings\":{ \"properties\" : { \"_class\" : { \"type\" : \"text\", \"fields\" : { \"keyword\" : { \"type\" : \"keyword\", \"ignore_above\" : 256 } } }, \"customer\" : { \"type\" : \"nested\", \"properties\" : { \"messengerId\" : { // messengerId 필드 추가 \"type\" : \"text\", \"fields\" : { \"keyword\" : { \"type\" : \"keyword\", \"ignore_above\" : 256 } } }, ......(중략)....... } } } . ",
    "url": "http://localhost:4000/docs/msa/elastic-search/elasticsearch_add_field_2/#2-%EC%9C%84%EC%97%90%EC%84%9C-%EC%A1%B0%ED%9A%8C%ED%95%9C-%EB%A7%B5%ED%95%91-%EC%A0%95%EB%B3%B4%EB%A5%BC-%EB%B3%B5%EC%82%AC%ED%95%B4%EC%84%9C-%EC%83%88%EB%A1%9C%EC%9A%B4-%ED%95%84%EB%93%9C%EC%9D%84-%EC%B6%94%EA%B0%80%ED%95%98%EA%B3%A0-%EC%83%88%EB%A1%9C%EC%9A%B4-%EB%A7%B5%ED%95%91%EC%A0%95%EB%B3%B4%EB%A5%BC-%EA%B0%80%EC%A7%84-%EC%9D%B8%EB%8D%B1%EC%8A%A4%EB%A5%BC-%EC%83%9D%EC%84%B1%ED%95%9C%EB%8B%A4",
    "relUrl": "/docs/msa/elastic-search/elasticsearch_add_field_2/#2-위에서-조회한-맵핑-정보를-복사해서-새로운-필드을-추가하고-새로운-맵핑정보를-가진-인덱스를-생성한다"
  },"108": {
    "doc": "elasticsearch field add(2)",
    "title": "3. 잘 추가되었는지 확인한다",
    "content": "GET attic_ticket_new/_mapping . ",
    "url": "http://localhost:4000/docs/msa/elastic-search/elasticsearch_add_field_2/#3-%EC%9E%98-%EC%B6%94%EA%B0%80%EB%90%98%EC%97%88%EB%8A%94%EC%A7%80-%ED%99%95%EC%9D%B8%ED%95%9C%EB%8B%A4",
    "relUrl": "/docs/msa/elastic-search/elasticsearch_add_field_2/#3-잘-추가되었는지-확인한다"
  },"109": {
    "doc": "elasticsearch field add(2)",
    "title": "4. 새로 생성한 인덱스로 기존 데이터 복사",
    "content": "💡 document양이 10만이 넘어가면 Kibana로 했을때 504 Gateway timeout발생하게 되므로 비동기로 실행되도록 옵션 wait_for_completion=false를 준다. POST _reindex?wait_for_completion=false // false로 하면 비동기로 실행하겠다는 뜻 { \"source\": { \"index\": \"attic_ticket\" // 원본 인덱스 }, \"dest\": { \"index\": \"attic_ticket_new\" // 필드 추가해서 새로 생성한 인덱스 } } . | _reindex api는 _source가 enable일때만 가능하다(_search하면 enable인지 확인가능) | _reindex는 mapping정보는 복사하지 않고 데이터만 복사하기 때문에 새로운 index쪽에 따로 mapping정보를 맞춰줘야 하는 것. | . 4-1. 데이터 양이 많은 경우, 여러번 나눠서 수행한다. 💡 reindex는 scroll batch이기 때문에, 사이즈를 나눠서 수행한다. (default size는 1000) POST _reindex?wait_for_completion=false { \"source\": { \"index\": \"attic_ticket\" \"size\" : 999 // 나눠서 수행할 크기를 지정한다. }, \"dest\": { \"index\": \"attic_ticket_new\" } } . 4-2. 원본이 원격지에 있는 경우, 원본 데이터 중 일부만 대상으로 하는 경우 . POST _reindex?wait_for_completion=false { \"source\": { \"remote\": { // 원본데이터가 있는 원격지 정보 \"host\": \"https://remotehost:9200\", \"username\": \"user\", \"password\": \"pass\" }, \"index\": \"attic_ticket\", // 원본 인덱스 \"query\": { // 일부 데이터만 복사할 경우 조건 쿼리를 추가한다. \"match\": { \"field_name\": \"field_value\" } } }, \"dest\": { \"index\": \"attic_ticket_new\" // 필드 추가해서 새로 생성한 인덱스 } } . 4-3. 비동기 수행 후, 수행 결과 조회 . GET _tasks . | task번호로 조회한다. | cancellable이 true이면, 수행 중 취소가 가능하다. | . ",
    "url": "http://localhost:4000/docs/msa/elastic-search/elasticsearch_add_field_2/#4-%EC%83%88%EB%A1%9C-%EC%83%9D%EC%84%B1%ED%95%9C-%EC%9D%B8%EB%8D%B1%EC%8A%A4%EB%A1%9C-%EA%B8%B0%EC%A1%B4-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B3%B5%EC%82%AC",
    "relUrl": "/docs/msa/elastic-search/elasticsearch_add_field_2/#4-새로-생성한-인덱스로-기존-데이터-복사"
  },"110": {
    "doc": "elasticsearch field add(2)",
    "title": "5.  원본데이터와 복사데이터 count를 비교해본다.",
    "content": "GET attic_ticket/_count GET attic_ticket_new/_count . ",
    "url": "http://localhost:4000/docs/msa/elastic-search/elasticsearch_add_field_2/#5--%EC%9B%90%EB%B3%B8%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%99%80-%EB%B3%B5%EC%82%AC%EB%8D%B0%EC%9D%B4%ED%84%B0-count%EB%A5%BC-%EB%B9%84%EA%B5%90%ED%95%B4%EB%B3%B8%EB%8B%A4",
    "relUrl": "/docs/msa/elastic-search/elasticsearch_add_field_2/#5--원본데이터와-복사데이터-count를-비교해본다"
  },"111": {
    "doc": "elasticsearch field add(2)",
    "title": "6. 새로 추가한 인덱스에 기존 인덱스의 alias로 교체해야한다.",
    "content": "6-1. attic_ticket에 alias를 추가한다. (삭제되게 되지만, alias를 교체해야하므로 원본에 alias가 있어야한다.) . 💡 alias 이름은 index이름과 동일한 이름으로 지정할 수 없습니다. alias 이름으로도 인덱스 검색이 되어야하므로... POST /_aliases { \"actions\" : [ { \"add\" : { \"index\" : \"attic_ticket\", \"alias\" : \"attic_ticket_alias\" } } ] } . 6-2. 새로 추가한 인덱스에 기존 원본 alias로 교체해준다. (alias add를 먼저 실행하면 동일한 alias를 가진 색인이 2개가 되므로 (거의) 동일한 검색결과가 2건씩 나오게 된다. 반대로 기존 alias를 먼저 지우면 클라이언트에서 검색 요청이 들어왔을 때 해당 alias내지 인덱스가 없으므로 오류가 발생하기 때문에 add와 remove를 동시에 진행) . POST /_aliases { \"actions\" : [ { \"add\": { \"index\": \"attic_ticket_new\", \"alias\": \"attic_ticket\" }, \"remove\" : { \"index\" : \"attic_ticket\", \"alias\" : \"attic_ticket_alias\" } } ] } . 6-3. 새로운 인덱스에 alias가 잘 맵핑되어있는지 확인한다. GET /_alias . ",
    "url": "http://localhost:4000/docs/msa/elastic-search/elasticsearch_add_field_2/#6-%EC%83%88%EB%A1%9C-%EC%B6%94%EA%B0%80%ED%95%9C-%EC%9D%B8%EB%8D%B1%EC%8A%A4%EC%97%90-%EA%B8%B0%EC%A1%B4-%EC%9D%B8%EB%8D%B1%EC%8A%A4%EC%9D%98-alias%EB%A1%9C-%EA%B5%90%EC%B2%B4%ED%95%B4%EC%95%BC%ED%95%9C%EB%8B%A4",
    "relUrl": "/docs/msa/elastic-search/elasticsearch_add_field_2/#6-새로-추가한-인덱스에-기존-인덱스의-alias로-교체해야한다"
  },"112": {
    "doc": "elasticsearch field add(2)",
    "title": "7. 검증",
    "content": "7-1. 새로운 티켓을 인입 또는 종료시켜본다. 7-2. 새로운 인덱스로 검색해본다. GET attic_ticket/_search // 교체한 alias명으로 검색 { \"query\" : { \"bool\": { \"should\":[{ \"terms\":{ \"ticketId\":[\"f6872447-be1a-4152-8325-7620a6ee084f\"],\"boost\":1.0 } }] } } } . | 검색 결과의 _index가 새로 생성한 인덱스명인지 확인 | . ",
    "url": "http://localhost:4000/docs/msa/elastic-search/elasticsearch_add_field_2/#7-%EA%B2%80%EC%A6%9D",
    "relUrl": "/docs/msa/elastic-search/elasticsearch_add_field_2/#7-검증"
  },"113": {
    "doc": "elasticsearch field add(2)",
    "title": "참고",
    "content": "https://www.elastic.co/kr/blog/changing-mapping-with-zero-downtime . ",
    "url": "http://localhost:4000/docs/msa/elastic-search/elasticsearch_add_field_2/#%EC%B0%B8%EA%B3%A0",
    "relUrl": "/docs/msa/elastic-search/elasticsearch_add_field_2/#참고"
  },"114": {
    "doc": "elasticsearch field add(2)",
    "title": "elasticsearch field add(2)",
    "content": "[공통] . 기존 데이터 백업을 진행합니다. 스냅샷 백업 방식은 여기 참고하세요. ",
    "url": "http://localhost:4000/docs/msa/elastic-search/elasticsearch_add_field_2/",
    "relUrl": "/docs/msa/elastic-search/elasticsearch_add_field_2/"
  },"115": {
    "doc": "elasticsearch snapshot create/restore/delete",
    "title": "참고 사이트",
    "content": "https://lovekmg.github.io/2018/12/06/elasticsearch-backup-and-restore/ . https://kay0426.tistory.com/46 . ",
    "url": "http://localhost:4000/docs/msa/elastic-search/elasticsearch_backup/#%EC%B0%B8%EA%B3%A0-%EC%82%AC%EC%9D%B4%ED%8A%B8",
    "relUrl": "/docs/msa/elastic-search/elasticsearch_backup/#참고-사이트"
  },"116": {
    "doc": "elasticsearch snapshot create/restore/delete",
    "title": "elasticsearch snapshot create/restore/delete",
    "content": ". | elasticsearch snapshot 기능을 사용 | . (1) snapshot을 했을 경우, 저장할 repository가 필요하다. (2) GET _nodes를 실행시켰을 때 path.repo 값이 있는지 확인한다. (3) (2)가 없는 경우, . 1) elasticsearch.yml에 아래 설정을 추가한다. path.repo: [\"/usr/share/elasticsearch/backup\"] . 2) docker에서 elasticsearch reload한다. 3) 다시 kibana에서 GET _nodes 호출 . (4) repository의 path를 지정했으면, snapshot 리파지토리를 생성한다. PUT _snapshot/ticket_backup { \"type\": \"fs\", \"settings\": { \"location\": \"/usr/share/elasticsearch/backup\", --&gt; path.repo의 경로를 지정해준다. \"compress\": true --&gt; 압축할지 여부로, mapping데이터만 압축되고 data가 압축되는 것은 아님. 디폴트(true) } } . 참고) elasticsearch를 재구동해도 snapshot repository가 영속되도록 하려면, volume에 path.repo를 추가해줘야한다. (5) snapshot 생성 . PUT _snapshot/ticket_backup/ticket_snapshot_210513?wait_for_completion=true // 비동기로 실행 { \"indices\": \"attic_ticket\", // snapshop할 doc으로 , 콤마로 여러개 지정가능. alias명으로 불가 \"ignore_unavailable\": true, // true 값일 경우, missing되거나 closed 된 indices는 snapshot되지 않는다.(기본 값 false) \"include_global_state\": false, \"metadata\": { \"backup_executor\": \"jhsim\" // 추가 정보 } } . (6) snapshot 조회 . GET _snapshot/ticket_backup/_all . (7) snapshot으로 복원 . POST _snapshot/ticket_backup/ticket_snapshot_210513/_restore { \"indices\": \"attic_ticket\", // alias명으로 불가. 지정하지 않으면 전체를 복구한다. \"ignore_unavailable\": true, \"include_global_state\": true, \"rename_pattern\": \"(.+)\", \"rename_replacement\": \"restored_$1\" // indices 이름과 중첩불가. 다른 이름으로 해야한다. } . ** 변경된 indices로 서비스하려면, alias를 활용해서 한다. (8) 복원 조회 . GET /_cat/indices?v . (9) snapshot 삭제 . DELETE _snapshot/ticket_backup/ticket_snapshot_210513 . ",
    "url": "http://localhost:4000/docs/msa/elastic-search/elasticsearch_backup/",
    "relUrl": "/docs/msa/elastic-search/elasticsearch_backup/"
  },"117": {
    "doc": "aws elb waf 403 error",
    "title": "problem",
    "content": "상담톡 연동 서비스를 구축해서 오픈까지 한 상태에서 특정 메시지만 상담 어플리케이션에 표시되지 않고 에러 메시지가 온다는 문의가 왔었습니다. 에러메시지 유형을 보니 카카오쪽에서 저희쪽 서드파티 서버로 전송에 실패한 경우, 카카오에서 고객에게 내보내는 메시지였는데요 . ",
    "url": "http://localhost:4000/docs/errors/elb_waf_rule_403/#problem",
    "relUrl": "/docs/errors/elb_waf_rule_403/#problem"
  },"118": {
    "doc": "aws elb waf 403 error",
    "title": "cause",
    "content": "원인파악까지 이틀 정도 넘게 걸렸던 것 같습니다. aws로 구축한 사이트였는데, waf와 elb를 걸쳐서 메시지가 도달하고 있기 때문에 . 어느 구간에서 에러가 났는지 확인이 필요했습니다. try1. 어느 구간까지 도달하는지 로그 체크 . 제가 확인이 가능한 부분은 서드파티 서버 뿐이여서 체크해보니 전혀 해당 시점에 메시지가 로깅되는 로그는 없었습니다. try2. elb 및 waf 체크 . 솔루션 업체에 연락해서 당일 에러로그만 필터링해서 전달 요청했습니다. https 2021-07-22T03:26:08.923663Z app/e64c01e680374 - -1 -1 -1 403 - 472 271 \"POST https://~~:443/message HTTP/1.1\" \"AHC/2.0\" ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2 \"~~\" -1 2021-07-22T03:26:08.915000Z \"waf\" \"-\" \"-\" \"-\" \"-\" \"-\" \"-\" . 유일한 에러가 403이였는데요.. 403이여서 첨에는 무시했었습니다. ㅠㅜ… . ",
    "url": "http://localhost:4000/docs/errors/elb_waf_rule_403/#cause",
    "relUrl": "/docs/errors/elb_waf_rule_403/#cause"
  },"119": {
    "doc": "aws elb waf 403 error",
    "title": "try3",
    "content": "원인을 알아낼 수 있었던 것은 사실 때려맞춰보는 심정으로 해보다가 파악할 수 있었습니다. 현업의 말과 다르게 일부 메시지만 실패가 나고 있었고 . 특히 카카오톡으로 첨부파일을 첨부한 경우만 발생하는 것으로 특정할 수 있었습니다. 일반 메시지와 첨부파일 차이라고 한다면.. POST API Body 부분에 https:// ~ 와 같은 첨부파일 url이 들어가는 것이였는데요. 역시나 ://로 일반 메시지에 넣어보니 403 에러로 waf로그에 찍혀있었습니다. ",
    "url": "http://localhost:4000/docs/errors/elb_waf_rule_403/#try3",
    "relUrl": "/docs/errors/elb_waf_rule_403/#try3"
  },"120": {
    "doc": "aws elb waf 403 error",
    "title": "solution",
    "content": "솔루션 업체쪽에 문의해보니 waf에 있는 rule에 의해 필터가 되고 있고 . 필터될 경우 카카오서버쪽으로 403으로 리턴시키고 있었습니다. 그래서 룰 변경 요청으로 해결했습니다. ",
    "url": "http://localhost:4000/docs/errors/elb_waf_rule_403/#solution",
    "relUrl": "/docs/errors/elb_waf_rule_403/#solution"
  },"121": {
    "doc": "aws elb waf 403 error",
    "title": "waf rule",
    "content": "waf에서 block . | GenericRFI_BODY | 요청 본문의 값을 검사하고 웹 애플리케이션에서 원격 파일 포함 (RFI, Remote File Inclusion)을 도용하는 경우 제어 ex) :// | — | — | . | 필드 | 설명 | 값 | . | type | 　 | https  | . | 시간 | 　 | 2021-07-22T03:26:08.923663Z | . | elb | 　 | app/ | . | client:port | 　 |   | . | target:port | AWS  WAF에서 요청을 차단한 경우, 이 값은 -로 설정되고  elb_status_code 값은 403으로 설정됩니다. | - | . | request_processing_time | 로드 밸런서가 대상으로 요청을  디스패치할 수 없는 경우 이 값은 -1로 설정됩니다. | -1 | . | target_processing_time | 로드 밸런서가 대상으로 요청을  디스패치할 수 없는 경우 이 값은 -1로 설정됩니다. | -1 | . | response_processing_time | 로드 밸런서가 대상으로 요청을  전송할 수 없는 경우 이 값은 -1로 설정됩니다. | -1 | . | elb_status_code | 로드 밸런서의 응답 상태  코드입니다. | 403 | . | target_status_code | 대상의 응답 상태 코드입니다. 대상으로 연결이 설정되고 대상이 응답을 전송한 경우에만 이 값이 기록됩니다. 그렇지 않으면 -에 설정됩니다. | - | . | received_bytes | 　 | 472 | . | sent_bytes | 　 | 271 | . | “요청” | 　 | POST  https://~/message  HTTP/1.1 | . | “user_agent” | 　 | AHC/2.0 | . | ssl_cipher | 　 | ECDHE-RSA-AES128-GCM-SHA256 | . | ssl_protocol | 　 | TLSv1.2 | . | target_group_arn | 　 | arn:aws:elasticloadbalancing: | . | “trace_id” | 　 |   | . | “domain_name” | 　 |   | . | “chosen_cert_arn” | 　 |   | . | matched_rule_priority | 　 | -1 | . | request_creation_time | 　 | 2021-07-22T03:26:08.915000Z | . | “실행된 작업” | waf — 로드 밸런서는 요청을 대상으로 전달해야 하는지 여부를 결정하기 위해 AWS WAF로 요청을 전달했습니다. 이것이 최종 조치인 경우 AWS WAF에서는 요청을 거부해야 한다고 결정했습니다. | waf | . | “redirect_url” | 　 | - | . | “error_reason” | 　 | - | . | “target:port_list” | 　 | - | . | “target_status_code_list” | 　 | - | . | “classification” | 　 | - | . | “classification_reason” | 　 | - | . ",
    "url": "http://localhost:4000/docs/errors/elb_waf_rule_403/#waf-rule",
    "relUrl": "/docs/errors/elb_waf_rule_403/#waf-rule"
  },"122": {
    "doc": "aws elb waf 403 error",
    "title": "aws elb waf 403 error",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/elb_waf_rule_403/",
    "relUrl": "/docs/errors/elb_waf_rule_403/"
  },"123": {
    "doc": "전락 열거 타입 패턴",
    "title": "전락 열거 타입 패턴",
    "content": ". | 열거형 클래스에 새로운 값을 열거타입에 추가하려면 그 값을 처리하는 case문을 쌍으로 넣어줘야하는 문제가 있다. | 새로운 상수를 추가할 때마다 ‘전략’을 선택하도록 하면 switch문이나 상수별 메서드 구현이 필요없게 된다. | . enum PayrollDay { MONDAY(WEEKDAY), SUNDAY(WEEKEND); private final PayType payType; PayrollDay(PayType payType) { this.payType = payType; } int pay(int minutesWorked, int payRate) { return payType.pay(minutesWorked, payRate); } enum PayType { WEEKDAY { int overtimePay(int minsWorked, int payRate) { return minsWorked &lt;= MIN_PER_SHIFT ? 0 : (minsWorked - MINS_PER_SHIFT) * payRate / 2; } }, WEEKEND { }; abstract int overtimePay(int mins, int payRate); private static final int MINS_PER_SHIFT = 8 * 60; int pay(int minsWorked, int payRate) { int basePay = minsWorked * payRate; return basePay + overtimePay(minsWorked, payRate); } } } . ",
    "url": "http://localhost:4000/docs/patterns/enums_pattern/",
    "relUrl": "/docs/patterns/enums_pattern/"
  },"124": {
    "doc": "Errors",
    "title": "Note",
    "content": "About some errors that I know. It might be duplicated. Cause to figure out, I read another blog or stackoverflow.com searching for them. I will go on adding the post. ",
    "url": "http://localhost:4000/docs/errors#note",
    "relUrl": "/docs/errors#note"
  },"125": {
    "doc": "Errors",
    "title": "Errors",
    "content": " ",
    "url": "http://localhost:4000/docs/errors",
    "relUrl": "/docs/errors"
  },"126": {
    "doc": "Etc",
    "title": "Etc",
    "content": " ",
    "url": "http://localhost:4000/docs/mooc/etc/etc/",
    "relUrl": "/docs/mooc/etc/etc/"
  },"127": {
    "doc": "Etc",
    "title": "Etc,.",
    "content": "Things that I summarize to record about development. ",
    "url": "http://localhost:4000/docs/etc#etc",
    "relUrl": "/docs/etc#etc"
  },"128": {
    "doc": "Etc",
    "title": "Etc",
    "content": " ",
    "url": "http://localhost:4000/docs/etc",
    "relUrl": "/docs/etc"
  },"129": {
    "doc": "Factory Method pattern",
    "title": "Factory Method pattern",
    "content": "예 ) java8 의 Supplier 인터페이스 . ",
    "url": "http://localhost:4000/docs/patterns/factory_method_pattern/",
    "relUrl": "/docs/patterns/factory_method_pattern/"
  },"130": {
    "doc": "Feign",
    "title": "Feign",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/feign/feign/",
    "relUrl": "/docs/msa/feign/feign/"
  },"131": {
    "doc": "com.netflix.client.ClientException",
    "title": "com.netflix.client.ClientException",
    "content": "com.netflix.client.ClientException: Load balancer does not have available server for client: aaa . cause . feignclient로 다른 모듈 호출하려고 하는데 못찾을 때 . error log . 11:46:24.265 010-exec-3 ERROR e.r.BaseExceptionHandler: 57 handleThrowable [status] 500 INTERNAL_SERVER_ERROR, [code]: 500100, [message] Hystrix command fails and does not a fallback., [detail message] SchemaTranslateClient#translate(StandardMessageCdo) failed and no fallback available. com.netflix.hystrix.exception.HystrixRuntimeException: SchemaTranslateClient#translate(StandardMessageCdo) failed and no fallback available. at com.netflix.hystrix.AbstractCommand$22.call(AbstractCommand.java:822) at com.netflix.hystrix.AbstractCommand$22.call(AbstractCommand.java:807) at rx.internal.operators.OperatorOnErrorResumeNextViaFunction$4.onError(OperatorOnErrorResumeNextViaFunction.java:140) at rx.internal.operators.OnSubscribeDoOnEach$DoOnEachSubscriber.onError(OnSubscribeDoOnEach.java:87) at rx.internal.operators.OnSubscribeDoOnEach$DoOnEachSubscriber.onError(OnSubscribeDoOnEach.java:87) at com.netflix.hystrix.AbstractCommand$DeprecatedOnFallbackHookApplication$1.onError(AbstractCommand.java:1472) at com.netflix.hystrix.AbstractCommand$FallbackHookApplication$1.onError(AbstractCommand.java:1397) at rx.internal.operators.OnSubscribeDoOnEach$DoOnEachSubscriber.onError(OnSubscribeDoOnEach.java:87) at rx.observers.Subscribers$5.onError(Subscribers.java:230) at rx.internal.operators.OnSubscribeThrow.call(OnSubscribeThrow.java:44) at rx.internal.operators.OnSubscribeThrow.call(OnSubscribeThrow.java:28) at rx.Observable.unsafeSubscribe(Observable.java:10327) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:51) ... at rx.internal.operators.OperatorOnErrorResumeNextViaFunction$4.onError(OperatorOnErrorResumeNextViaFunction.java:142) at rx.internal.operators.OnSubscribeDoOnEach$DoOnEachSubscriber.onError(OnSubscribeDoOnEach.java:87) at rx.internal.operators.OnSubscribeDoOnEach$DoOnEachSubscriber.onError(OnSubscribeDoOnEach.java:87) at com.netflix.hystrix.AbstractCommand$HystrixObservableTimeoutOperator$3.onError(AbstractCommand.java:1194) at rx.internal.operators.OperatorSubscribeOn$SubscribeOnSubscriber.onError(OperatorSubscribeOn.java:80) at rx.observers.Subscribers$5.onError(Subscribers.java:230) Caused by: java.lang.RuntimeException: com.netflix.client.ClientException: Load balancer does not have available server for client: aaa at org.springframework.cloud.openfeign.ribbon.LoadBalancerFeignClient.execute(LoadBalancerFeignClient.java:90) at org.springframework.cloud.sleuth.instrument.web.client.feign.TraceLoadBalancerFeignClient.execute(TraceLoadBalancerFeignClient.java:71) at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:108) at feign.SynchronousMethodHandler.invoke(SynchronousMethodHandler.java:78) at feign.hystrix.HystrixInvocationHandler$1.run(HystrixInvocationHandler.java:109) at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:302) at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:298) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:46) ... 28 common frames omitted . solution . springboot로 올릴때 해당 모듈이 pom에 있는지랑. springboot application에 feignclient어노테이션이 있는지를 확인한다. ",
    "url": "http://localhost:4000/docs/errors/feign1/",
    "relUrl": "/docs/errors/feign1/"
  },"132": {
    "doc": "java.lang.IllegalStateException...",
    "title": "java.lang.IllegalStateException: RequestParam.value() was empty on parameter 0",
    "content": "원인 : FeignClient로 선언한 adapter에 @RequestParam으로 값을 받아오는 부분에 맵핑을 잘못함. 기존&gt; . @RequestParam(defaultValue =”0”, required = false) int offset, . @RequestParam(defaultValue = “10”, required = false) int limit . 변경&gt; . @RequestParam(“offset”) int offset, . @RequestParam(“limit”) int limit . ",
    "url": "http://localhost:4000/docs/errors/feign2/#javalangillegalstateexception-requestparamvalue-was-empty-on-parameter-0",
    "relUrl": "/docs/errors/feign2/#javalangillegalstateexception-requestparamvalue-was-empty-on-parameter-0"
  },"133": {
    "doc": "java.lang.IllegalStateException...",
    "title": "java.lang.IllegalStateException...",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/feign2/",
    "relUrl": "/docs/errors/feign2/"
  },"134": {
    "doc": "Feign log level",
    "title": "basic",
    "content": "07:44:21.783   [ReceptionClient#register] ---&gt; POST [http://test/register](http://test/register) HTTP/1.1 07:44:23.872   [ReceptionClient#register] &lt;--- HTTP/1.1 200  (2084ms) . ",
    "url": "http://localhost:4000/docs/msa/feign/feign_log_level/#basic",
    "relUrl": "/docs/msa/feign/feign_log_level/#basic"
  },"135": {
    "doc": "Feign log level",
    "title": "headers",
    "content": "07:46:45.695  [ReceptionClient#register] ---&gt; POST [http://test/register](http://test/register) HTTP/1.1 07:46:45.695  [ReceptionClient#register] Accept: application/json 07:46:45.696  [ReceptionClient#register] Content-Length: 336 07:46:45.696  [ReceptionClient#register] Content-Type: application/json 07:46:45.696  [ReceptionClient#register] Content-Type: charset=utf8 07:46:45.696  [ReceptionClient#register] ---&gt; END HTTP (336-byte body) 07:46:45.845  [ReceptionClient#register] &lt;--- HTTP/1.1 200  (148ms) 07:46:45.845  [ReceptionClient#register] connection: keep-alive 07:46:45.845 [ReceptionClient#register] content-type: application/json 07:46:45.845  [ReceptionClient#register] date: Thu, 29 Apr 2021 22:46:45 GMT 07:46:45.845  [ReceptionClient#register] keep-alive: timeout=60 07:46:45.845  [ReceptionClient#register] transfer-encoding: chunked 07:46:45.845  [ReceptionClient#register] &lt;--- END HTTP (130-byte body) . ",
    "url": "http://localhost:4000/docs/msa/feign/feign_log_level/#headers",
    "relUrl": "/docs/msa/feign/feign_log_level/#headers"
  },"136": {
    "doc": "Feign log level",
    "title": "full",
    "content": "07:49:09.457 [ReceptionClient#register] ---&gt; POST [http://test/register](http://test/register) HTTP/1.1 07:49:09.458 [ReceptionClient#register] Accept: application/json 07:49:09.458 [ReceptionClient#register] Content-Length: 336 07:49:09.458 [ReceptionClient#register] Content-Type: application/json 07:49:09.458 [ReceptionClient#register] Content-Type: charset=utf8 07:49:09.458 [ReceptionClient#register] 07:49:09.458 [ReceptionClient#register] {\"id\":\"96d7abbd-1c20-46c3-8931-56649759f17e\",\"customer\":{\"id\":\"aaaaaaaa\",\"loginId\":\"bbbbb\",\"loggedIn\":false,\"metadata\":{\"externalId\":\"bbbbbbbb\"}},\"appChannelId\":\"ccccccccc\",\"firstMessage\":\"네\",\"customType\":\"customer\",\"topicId\":\"default-topic\",\"fileMetaIds\":[]} 07:49:09.459 [ReceptionClient#register] ---&gt; END HTTP (336-byte body) 07:49:09.640 [ReceptionClient#register] &lt;--- HTTP/1.1 200  (181ms) 07:49:09.641 [ReceptionClient#register] connection: keep-alive 07:49:09.641 [ReceptionClient#register] content-type: application/json 07:49:09.641 [ReceptionClient#register] date: Thu, 29 Apr 2021 22:49:09 GMT 07:49:09.641 [ReceptionClient#register] keep-alive: timeout=60 07:49:09.642 [ReceptionClient#register] transfer-encoding: chunked 07:49:09.642 [ReceptionClient#register] 07:49:09.642 [ReceptionClient#register] {\"id\":\"96d7abbd-1c20-46c3-8931-56649759f17e\",\"customerId\":\"aaaaaaa\",\"messageId\":391668525187072} 07:49:09.642 [ReceptionClient#register] &lt;--- END HTTP (130-byte body) . ",
    "url": "http://localhost:4000/docs/msa/feign/feign_log_level/#full",
    "relUrl": "/docs/msa/feign/feign_log_level/#full"
  },"137": {
    "doc": "Feign log level",
    "title": "Feign log level",
    "content": "level로 full, basic, none, headers가 있음 . ",
    "url": "http://localhost:4000/docs/msa/feign/feign_log_level/",
    "relUrl": "/docs/msa/feign/feign_log_level/"
  },"138": {
    "doc": "Feign LB using nginx (without Eureka)",
    "title": "시스템 구성도",
    "content": ". subject: how to dynamically specify feign call service name according to the environment . ",
    "url": "http://localhost:4000/docs/msa/feign/feignandribbon/#%EC%8B%9C%EC%8A%A4%ED%85%9C-%EA%B5%AC%EC%84%B1%EB%8F%84",
    "relUrl": "/docs/msa/feign/feignandribbon/#시스템-구성도"
  },"139": {
    "doc": "Feign LB using nginx (without Eureka)",
    "title": "구성 환경 설명",
    "content": ". | 다중화 구성 AP서버에서 Nginx G/W를 통해 ThirdParty Server의 API를 호출하는 구성 | Nginx 앞에 L4 존재 | Nginx는 Failover 구성 | . ",
    "url": "http://localhost:4000/docs/msa/feign/feignandribbon/#%EA%B5%AC%EC%84%B1-%ED%99%98%EA%B2%BD-%EC%84%A4%EB%AA%85",
    "relUrl": "/docs/msa/feign/feignandribbon/#구성-환경-설명"
  },"140": {
    "doc": "Feign LB using nginx (without Eureka)",
    "title": "요구사항",
    "content": ". | Eureka에 등록되지 않은 서비스를 Ribbin통해 LB되게 해야한다. | . ",
    "url": "http://localhost:4000/docs/msa/feign/feignandribbon/#%EC%9A%94%EA%B5%AC%EC%82%AC%ED%95%AD",
    "relUrl": "/docs/msa/feign/feignandribbon/#요구사항"
  },"141": {
    "doc": "Feign LB using nginx (without Eureka)",
    "title": "개발 항목",
    "content": ". | AS-IS . | direct로 외부 API를 feign#httpclient로 호출 | . | TO-BE . | Nginx G/W를 통해서 호출하도록 변경 필요 | . | . ",
    "url": "http://localhost:4000/docs/msa/feign/feignandribbon/#%EA%B0%9C%EB%B0%9C-%ED%95%AD%EB%AA%A9",
    "relUrl": "/docs/msa/feign/feignandribbon/#개발-항목"
  },"142": {
    "doc": "Feign LB using nginx (without Eureka)",
    "title": "테스트 환경 구성",
    "content": ". | Window에 두개 서비스 올려도 됨 (1.19.9 버전) | Nginx 설정 . | proxy_pass설정 | . server { listen 8050; server_name localhost; charset utf-8; location ~* ^/(chat|image|file) { resolver 8.8.8.8; proxy_pass https://test.com$uri; } # Health Check location /ping { access_log on; add_header 'Content-Type' 'application/json'; return 200 '{\"status\":\"UP\"}'; } } . | 동일 서버에서 여러개 띄우려면, 포트만 다르게 해서 띄우도록 한다. | server목록에 http url이나 서블릿path가 붙으면 안됨, 딱 c클래스까지 | . | . problem 1 . https://niiiii.tistory.com/entry/Eureka-없이-ribbon으로-load-balancing-처리하기 에서처럼 yml설정만으로 했을때, npe발생 . c.n.l.RoundRobinRule : 66 choose No up servers available from load balancer: DynamicServerListLoadBalancer:{NFLoadBalancer:name=kakao-service,current list of Servers=[],Load balancer stats=Zone stats: {},Server stats: []}ServerList:org.springframework.cloud.netflix.ribbon.eureka.DomainExtractingServerList@4be00017 07:44:29.490 -service-2 WARN c.n.l.BaseLoadBalancer :757 chooseServer LoadBalancer [kakao-service]: Error choosing server for key null java.lang.NullPointerException: null at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:878) at com.google.common.cache.LocalCache.get(LocalCache.java:3950) at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3974) at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4935) . cause 1 . 기본 healthcheck uri는 / 루트로 되고 있는데, . nginx.conf에 / 루트로 선언된게 없다보니 . ribbon으로 LB하려는 서버가 없어서 NPE가 발생한 것 . solved 1 . healthcheck url을 변경하고 싶다면, . 별도의 configuration파일을 생성해서 bean으로 올리고 ribbonClients 설정으로 지정해주면 된다. path를 yml로 빼서 주는 방법도 있겠다. 그게 아니라면 디폴트 / 루트로 check된다. /ping을 healthcheck uri로 뺐다. [yml] . thirdparty-gateway: health-check-location: /ping ribbon: eureka: enabled: false NIWSServerListClassName: com.netflix.loadbalancer.ConfigurationBasedServerList listOfServers: localhost:19011,localhost:19013 NFLoadBalancerRuleClassName: com.netflix.loadbalancer.AvailabilityFilteringRule NFLoadBalancerPingClassName: com.ext.FeignRibbonPing . [java] . import com.netflix.loadbalancer.PingUrl; public class FeignRibbonPing extends PingUrl { @Value(\"${thirdparty-gateway.health-check-location:}\") private String healthCheckLocation; @Override public String getPingAppendString() { return healthCheckLocation; } } . [nginx.conf] . location /ping { access_log off; # on으로 하면 너무 많이 쌓인다. add_header 'Content-Type' 'application/json'; return 200 '{\"status\":\"UP\"}'; } . ** 참고로, nginx plus인 상용버전엔 별도로 health check용 location을 선언하지 않아도, health check 모듈?이 있는 것 같다. Nginx, Nginx Plus 차이 - GRIP.News . | 테스트 . | ping잘 올라온다. | 번갈아가며 outgoing하고 있다. | 가용성 검증 | . | 만약에 서버 정보가 잘못된 경우 . | 400, 500에 대해서 LB가 되는지 | . | 한쪽서버가 가용하지 않은 경우 ping이 안된다는 에러가 주기적으로 찍힌다 | . java.net.ConnectException: Connection refused: connect at java.net.TwoStacksPlainSocketImpl.socketConnect(Native Method) at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172) at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) at java.net.Socket.connect(Socket.java:607) at org.apache.http.conn.scheme.PlainSocketFactory.connectSocket(PlainSocketFactory.java:121) at org.apache.http.impl.conn.DefaultClientConnectionOperator.openConnection(DefaultClientConnectionOperator.java:180) at org.apache.http.impl.conn.ManagedClientConnectionImpl.open(ManagedClientConnectionImpl.java:326) at org.apache.http.impl.client.DefaultRequestDirector.tryConnect(DefaultRequestDirector.java:605) at org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:440) at org.apache.http.impl.client.AbstractHttpClient.doExecute(AbstractHttpClient.java:835) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56) at com.netflix.loadbalancer.PingUrl.isAlive(PingUrl.java:126) at com.netflix.loadbalancer.BaseLoadBalancer$SerialPingStrategy.pingServers(BaseLoadBalancer.java:921) at com.netflix.loadbalancer.BaseLoadBalancer$Pinger.runPinger(BaseLoadBalancer.java:691) . FeignClient - name or url . url을 쓰는 경우도 있고 name을 통해 nginx의 gateway를 통해서 호출하는 경우도 모두 지원해야한다고 하면 . | 두개다 모두 정의할 경우에 대한 우선순위를 테스트를 통해서 정리해봤다. | name은 필수값이 되어버렷다. 단, url은 null이어도 된다. (이전 feign은 필수가 아니였음) | name, url 두개다 설정했을 때, url로 나간다.. 중복해서 name으로 나가진 않았다. | . | . @FeignClient( contextId = \"com.TestClient\", name = \"${test.subapi.name}\", url = \"NO_URL\", configuration = {FeignConfiguration.class, FeignRetryConfiguration.class}, primary = false ) public interface TestClient{ . | 제품에는 . | url을 쓰고자 하면 yml에 url을 정의하고, ribbon설정을 주석하도록 가이드했고, name을 쓰려고 하면 url을 공란으로 하는 것으로 했다. | (다시 변경) feign call 하기 전에 nginx로 연결한 listOfServers의 서버의 상태가 Alive한지 체크하는 것을 추가해서 정상일 경우 name으로 호출하고 그게 아니면 url값을 참조해서 API호출하도록 했다. | . import com.netflix.loadbalancer.Server; import lombok.RequiredArgsConstructor; import lombok.extern.slf4j.Slf4j; import org.springframework.cloud.client.ServiceInstance; import org.springframework.cloud.client.loadbalancer.LoadBalancerClient; import org.springframework.cloud.netflix.ribbon.RibbonLoadBalancerClient; import org.springframework.stereotype.Service; @Slf4j @Service @RequiredArgsConstructor public class FeignRibbonService { private final LoadBalancerClient loadBalancerClient; public boolean isAlive() { try { final ServiceInstance instance = loadBalancerClient.choose(\"thirdparty.thirdparty-gateway\"); Server server; if (instance instanceof RibbonLoadBalancerClient.RibbonServer) { RibbonLoadBalancerClient.RibbonServer ribbonServer = (RibbonLoadBalancerClient.RibbonServer) instance; server = ribbonServer.getServer(); return server.isAlive(); } else { server = new Server(instance.getScheme(), instance.getHost(), instance.getPort()); return server.isAlive(); } } catch (Exception e) { log.error(e.getMessage()); return false; } } } . | . reference . Ribbon으로 Load Balancing처리(without Eureka) . LoadBalancer: Error choosing server for key null 에러 · Issue #11 · yanghun0070/dayco . Simple healthcheck endpoint in nginx server container . more detail.. 좀더 디테일하게 하려면, config생성해서 주입 . 6. Client Side Load Balancer: Ribbon . 꼭 주입안해도 클래스로 주입하는 방법 . https://github.com/spring-cloud/spring-cloud-netflix/issues/92 . 설정디테일 . Ribbon . ",
    "url": "http://localhost:4000/docs/msa/feign/feignandribbon/#%ED%85%8C%EC%8A%A4%ED%8A%B8-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%84%B1",
    "relUrl": "/docs/msa/feign/feignandribbon/#테스트-환경-구성"
  },"143": {
    "doc": "Feign LB using nginx (without Eureka)",
    "title": "Feign LB using nginx (without Eureka)",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/feign/feignandribbon/",
    "relUrl": "/docs/msa/feign/feignandribbon/"
  },"144": {
    "doc": "Feign client Async call",
    "title": "try1. AsyncFeign 사용하기",
    "content": "How to build REST API client using Feign in Spring Boot . AsyncFeign&lt;Object&gt; asyncFeign = AsyncFeign.asyncBuilder() .requestInterceptor(new FeignConfiguration().requestInterceptor()) .build(); asyncFeign.newInstance(new Target.HardCodedTarget(BotHistoryClient.class, \"mocha\", \"\")); . 구현을 하고 보니, AsyncFeign에 @Experimental가 있었다. 제품에는 못 넣을꺼 같아서 직접 구현했다. ",
    "url": "http://localhost:4000/docs/msa/feign/feignclient_async/#try1-asyncfeign-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0",
    "relUrl": "/docs/msa/feign/feignclient_async/#try1-asyncfeign-사용하기"
  },"145": {
    "doc": "Feign client Async call",
    "title": "try2. CompletableFuture.runAsync 호출",
    "content": "private final Executor taskExecutor; public void register(ConversationMessage conversationMessage) { CompletableFuture.runAsync(() -&gt; botHistoryClient.register(BotMessageBulkCdo.toDomain(conversationMessage)), taskExecutor) .exceptionally(throwable -&gt; { log.error(throwable.getMessage()); return null; }); } . 일단 서비스 안에서 직접 completableFuture를 선언해서 비동기로 호출해봄 . 저는 executor를 bean으로 등록해둔 것이 있어서, commonPool을 사용하지 않음 . ",
    "url": "http://localhost:4000/docs/msa/feign/feignclient_async/#try2-completablefuturerunasync-%ED%98%B8%EC%B6%9C",
    "relUrl": "/docs/msa/feign/feignclient_async/#try2-completablefuturerunasync-호출"
  },"146": {
    "doc": "Feign client Async call",
    "title": "try3. 인터페이스 구현",
    "content": "요청이 많을 경우 병목이 예상되는 구간이 몇 군데 있어서 공통 인터페이스를 구현했다. feign client async interface 생성 . public interface FeignAsyncClient { void execute(Object o); } . 비동기로 feign 호출하기 위한 feignclient 인터페이스의 공통함수 선언 . feign client 구현체 . @FeignClient( contextId = \"BotHistoryClient\", name = \"mocha\", configuration = {FeignConfiguration.class, FeignRetryConfiguration.class}, primary = false ) public interface BotHistoryClient extends FeignAsyncClient { @Override @PostMapping(\"bothistory/messages/bulk\") void execute(@RequestBody Object o); } . 비동기 호출을 해야하는 feign은 FeignAsyncClient를 상속받아서 FeignClient API를 선언하고 . 비동기 메소드 인터페이스 . public interface FeignAsyncHandler { CompletableFuture&lt;Void&gt; send(Object o); } . 서비스단에서 feignclient를 비동기 호출하기 위한 메소드를 인터페이스로 생성 . 비동기 메소드 인터페이스 구현체 . public class BotHistoryClientAsyncHandler implements FeignAsyncHandler { private final FeignAsyncClientService feignAsyncClientService; @Override public CompletableFuture&lt;Void&gt; send(Object o) { return feignAsyncClientService.apiFuture(botHistoryClient, o); } } . send메소드를 상세구현 . FeignClient 비동기 호출 . public class FeignAsyncClientService { private final Executor taskExecutor; public CompletableFuture&lt;Void&gt; apiFuture(FeignAsyncClient feignAsyncClient, Object o) { return CompletableFuture.runAsync(() -&gt; feignAsyncClient.execute(o), taskExecutor) .exceptionally(throwable -&gt; { log.error(throwable.getMessage()); return null; }); } public &lt;T&gt; T apiFutureSupplier(FeignAsyncSupplierClient feignAsyncClient, Object o, Class&lt;T&gt; rt) { try { return CompletableFuture.supplyAsync(() -&gt; feignAsyncClient.execute(o), taskExecutor) .thenApply(reponse -&gt; JsonUtil.fromJson(reponse, rt)).get(); } catch (Exception e) { throw new RuntimeException(e); } } } . FeignAsyncClientService에서 runAsync 또는 리턴용 supplyAsync로 비동기 호출하도록 한다. ",
    "url": "http://localhost:4000/docs/msa/feign/feignclient_async/#try3-%EC%9D%B8%ED%84%B0%ED%8E%98%EC%9D%B4%EC%8A%A4-%EA%B5%AC%ED%98%84",
    "relUrl": "/docs/msa/feign/feignclient_async/#try3-인터페이스-구현"
  },"147": {
    "doc": "Feign client Async call",
    "title": "Feign client Async call",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/feign/feignclient_async/",
    "relUrl": "/docs/msa/feign/feignclient_async/"
  },"148": {
    "doc": "Flyweight pattern",
    "title": "Flyweight pattern",
    "content": " ",
    "url": "http://localhost:4000/docs/patterns/flyweight_pattern/",
    "relUrl": "/docs/patterns/flyweight_pattern/"
  },"149": {
    "doc": "git pull > exit code 128 error",
    "title": "error log",
    "content": "git.exe clone --progress --branch develop -v \"[https://--/qm/loadtest/tree/develop](https://--/qm/loadtest/tree/develop)\" \"D:\\_GIT\\attic-project\\qm\\develop\" Cloning into 'D:\\_GIT\\attic-project\\qm\\develop'... fatal: unable to update url base from redirection: asked for: [https://--/qm/loadtest/tree/develop/info/refs?service=git-upload-pack](https://--/qm/loadtest/tree/develop/info/refs?service=git-upload-pack) redirect: [https://--/users/sign_in](https://gitlab.spectra.co.kr/users/sign_in) git did not exit cleanly (exit code 128) (391 ms @ 2022-08-01 오전 8:41:19) . ",
    "url": "http://localhost:4000/docs/errors/git_pull_128_error/#error-log",
    "relUrl": "/docs/errors/git_pull_128_error/#error-log"
  },"150": {
    "doc": "git pull > exit code 128 error",
    "title": "solution",
    "content": "Gitlabでpushしようとしたら、fatal: unable to update url base from redirection: と出てpushできない . 에 댓글을 보면 기존 브랜치를 삭제하고 새로 받으라 되어있는데 . 그걸로도 잘 안되어서 . 그냥 새로운 폴더에서 pull하니 잘되었다~ . ",
    "url": "http://localhost:4000/docs/errors/git_pull_128_error/#solution",
    "relUrl": "/docs/errors/git_pull_128_error/#solution"
  },"151": {
    "doc": "git pull > exit code 128 error",
    "title": "git pull > exit code 128 error",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/git_pull_128_error/",
    "relUrl": "/docs/errors/git_pull_128_error/"
  },"152": {
    "doc": "notion에서 gitblog로 이사",
    "title": ":: github에서 블로그를 사용하기 위한 사전 준비",
    "content": "** 이대로 하기만 하면 됨 . 왕초보를 위한 Github 블로그 만들기 (1) . ** 오류 1 . remote: Support for password authentication was removed on August 13, 2021. Please use a personal access token instead. push할 때 위의 에러가 나면, . 깃 토큰 인증(Git personal access token) . ** 오류 2 . unable to access ‘/Users/${userName}/.config/git/attributes’: Permission denied . Unable to access ‘git/attributes’ . ** 오류 3 . jekyll을 설치하려고 하다보니 ruby로 되어있어서… 온갖 오류를 다 만났습니다… . ruby는 모르기도 하고…포기할 뻔 . jekyll: command not found . Jekyll - command not found . ** 오류 4 . You don’t have write permissions for the /Library/Ruby/Gems/2.6.0 directory . Mac에서 Gem::FilePermissionError 에러 발생시 해결 방법 . ** 오류 5 . 겨우겨우 ruby버전 업하고 jekyll도 설치해서, 서비스 구동하려고 하니까 또 다른 오류 발생 . jekyll/commands/serve/servlet.rb:3:in `require’: cannot load such file – webrick (LoadError) . 하필 ruby를 3.0.2로 업그레이드 했더니,,, 3.x부터 webrick이 빠졌다고 하네요 ㅠㅜ . 별도로 webrick을 설치해줘야합니다. jekyll 실행 시킬 때 `require’: cannot load such file – webrick (LoadError) 오류가 난다면 bundle add webrick . ",
    "url": "http://localhost:4000/docs/etc/gitblog_move/#-github%EC%97%90%EC%84%9C-%EB%B8%94%EB%A1%9C%EA%B7%B8%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0-%EC%9C%84%ED%95%9C-%EC%82%AC%EC%A0%84-%EC%A4%80%EB%B9%84",
    "relUrl": "/docs/etc/gitblog_move/#-github에서-블로그를-사용하기-위한-사전-준비"
  },"153": {
    "doc": "notion에서 gitblog로 이사",
    "title": ":: 축!",
    "content": "드디어 기본 준비가 끝이 났습니다…… . ",
    "url": "http://localhost:4000/docs/etc/gitblog_move/#-%EC%B6%95",
    "relUrl": "/docs/etc/gitblog_move/#-축"
  },"154": {
    "doc": "notion에서 gitblog로 이사",
    "title": ":: 블로그에 Jekyll 테마 적용하기",
    "content": "이제는 jekyll을 잘 꾸며볼 차례입니다.. 아래 블로그에서 가이드대로 따라하면 됩니다. 왕초보를 위한 Github 블로그 만들기 (2) - 테마 적용(with Jekyll) . 무료버전으로 찾아봤습니다 ㅋㅋ . 저는 이것으로 선택(jekyll-theme-prologue) . GitHub - chrisbobbe/jekyll-theme-prologue: A Jekyll version of the “Prologue” theme by HTML5 UP . :: 오류 1 . 다운받은 테마 파일을 bundle install 하려고 하니까, 다운받은 gemfil과 버전이 안맞았네요 . Fetching gem metadata from https://rubygems.org/......... Resolving dependencies... Bundler could not find compatible versions for gem \"bundler\": In Gemfile: bundler (~&gt; 1.12) Current Bundler version: bundler (2.2.29) Your bundle requires a different version of Bundler than the one you're running. Install the necessary version with `gem install bundler:1.17.3` and rerun bundler using `bundle _1.17.3_ install` . —&gt; gemfile만 원래 파일로 돌려놓고, 덮지 않음 . :: 오류 ?? . Bundler could not find compatible versions for gem \"bundler\": In Gemfile: bundler (~&gt; 1.12) Current Bundler version: bundler (2.2.29) Your bundle requires a different version of Bundler than the one you're running. Install the necessary version with `gem install bundler:1.17.3` and rerun bundler using `bundle _1.17.3_ install` . 이건 gem 을 ‘~&gt;1.12’ 까지 설치하고, gemfile.lock파일 삭제하고 bundle 1.17.3 install 해주고 해서 해결하긴 했는데요… . 삽질을 많이하고 오류를 너무 많이 봐서 다 정리를 못하겠습니다. ㅠㅜ ruby도 삭제하고 다시 설치하고 . 하..포기할 뻔.. 겨우 테마 설치 완료 ^__^ . ",
    "url": "http://localhost:4000/docs/etc/gitblog_move/#-%EB%B8%94%EB%A1%9C%EA%B7%B8%EC%97%90-jekyll-%ED%85%8C%EB%A7%88-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0",
    "relUrl": "/docs/etc/gitblog_move/#-블로그에-jekyll-테마-적용하기"
  },"155": {
    "doc": "notion에서 gitblog로 이사",
    "title": ":: gitblog에 광고 적용하기",
    "content": "기존에 사용하던 애드센스가 있었기 때문에, 어렵지 않게 광고를 재개할 수 있었습니다. 관리페이지에서 새로운 주소로 사이트를 추가하고 스크립트를 include\\head_custom.html하위에 추가하면 끝. 참고) . 블로그 수익 애드 센스 광고 달기 . ",
    "url": "http://localhost:4000/docs/etc/gitblog_move/#-gitblog%EC%97%90-%EA%B4%91%EA%B3%A0-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0",
    "relUrl": "/docs/etc/gitblog_move/#-gitblog에-광고-적용하기"
  },"156": {
    "doc": "notion에서 gitblog로 이사",
    "title": ":: DNS 적용하기",
    "content": "gitblog를 생성하면, username으로 기본 주소가 되기 때문에 도메인네임을 추가해서 포워딩서비스를 하는 것이 좋습니다. | 저는 freenom을 사용하고 있어서 freenom에 무료 도메인 하나 더 추가생성했습니다. | freenom에 github와의 nameserver를 설정해야하는데요. 아래 블로그 참고하면 간단합니다. | . | [도메인 무료로 SSL/TLS(HTTPS) 얻는 법 | Freenom &amp; GitHub Pages](https://m.blog.naver.com/desbey7/222092439777) | . dns와 sitemap관계 . 아무리 sitemap을 수정해도 가져올 수 없다고만 나와서 수동 등록까지 했는데요. https://itgall.com/programming/236207 글 읽고, 다시 cf도메인 연결을 삭제하고 github.io로 돌려놨습니다. ",
    "url": "http://localhost:4000/docs/etc/gitblog_move/#-dns-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0",
    "relUrl": "/docs/etc/gitblog_move/#-dns-적용하기"
  },"157": {
    "doc": "notion에서 gitblog로 이사",
    "title": ":: 구글 검색엔진에 노출시키기",
    "content": "step-9-구글-검색-가능하게-하기 . ",
    "url": "http://localhost:4000/docs/etc/gitblog_move/#-%EA%B5%AC%EA%B8%80-%EA%B2%80%EC%83%89%EC%97%94%EC%A7%84%EC%97%90-%EB%85%B8%EC%B6%9C%EC%8B%9C%ED%82%A4%EA%B8%B0",
    "relUrl": "/docs/etc/gitblog_move/#-구글-검색엔진에-노출시키기"
  },"158": {
    "doc": "notion에서 gitblog로 이사",
    "title": ":: 파비콘 적용",
    "content": "저는 니아 언더 세븐의 니아 이미지를 추출해서 적용했습니다. [Github Blog] 파비콘(Favicon) 세팅하기 . header코드에 이미 선언되어 있어서, 생성한 파비콘 파일을 기존과 동일한 이름으로 교체만 해주었습니다!! . ",
    "url": "http://localhost:4000/docs/etc/gitblog_move/#-%ED%8C%8C%EB%B9%84%EC%BD%98-%EC%A0%81%EC%9A%A9",
    "relUrl": "/docs/etc/gitblog_move/#-파비콘-적용"
  },"159": {
    "doc": "notion에서 gitblog로 이사",
    "title": ":: 댓글 추가",
    "content": "에드고시에 거듭 실패해서 이런 저런 이유를 찾던 중, 댓글기능이 없어서 그럴 수도 있단 글을 읽고 jekyll에 댓글 기능을 추가했습니다. 자세한 내용은 아래 블로그를 참고해주세요. 되게 간단하네요! utterance 댓글 설치 . ",
    "url": "http://localhost:4000/docs/etc/gitblog_move/#-%EB%8C%93%EA%B8%80-%EC%B6%94%EA%B0%80",
    "relUrl": "/docs/etc/gitblog_move/#-댓글-추가"
  },"160": {
    "doc": "notion에서 gitblog로 이사",
    "title": ":: 태그 추가",
    "content": "아직도 할 것이 많네요 ㅋㅋㅋㅋ 태그가 등록된다면 검색될 확률이 높아질 것 같아서 태그도 추가했습니다. 태그 추가 . ",
    "url": "http://localhost:4000/docs/etc/gitblog_move/#-%ED%83%9C%EA%B7%B8-%EC%B6%94%EA%B0%80",
    "relUrl": "/docs/etc/gitblog_move/#-태그-추가"
  },"161": {
    "doc": "notion에서 gitblog로 이사",
    "title": ":: 검색엔진 등록",
    "content": "구글 서치엔진 . | 저는 jekyll-sitemap 플러그인을 사용해서 sitemap.xml을 만들었는데요. 아무리해도 “사이트맵을 읽을 수 없음”만 표시되어서 잘못 만들어졌다 했는데요. | 처음엔 last_modified_at가 없어서 그런듯 싶어서, layout도 post로 변경하고 추가해줬습니다. | 사이트맵 validation 체크 사이트에서도 체크했는데요. 정상으로 표시됩니다. | . | . ",
    "url": "http://localhost:4000/docs/etc/gitblog_move/#-%EA%B2%80%EC%83%89%EC%97%94%EC%A7%84-%EB%93%B1%EB%A1%9D",
    "relUrl": "/docs/etc/gitblog_move/#-검색엔진-등록"
  },"162": {
    "doc": "notion에서 gitblog로 이사",
    "title": ":: 마무리",
    "content": "조금씩 notion이나 에버노트 내용을 옮기고 있습니다. ",
    "url": "http://localhost:4000/docs/etc/gitblog_move/#-%EB%A7%88%EB%AC%B4%EB%A6%AC",
    "relUrl": "/docs/etc/gitblog_move/#-마무리"
  },"163": {
    "doc": "notion에서 gitblog로 이사",
    "title": "notion에서 gitblog로 이사",
    "content": " ",
    "url": "http://localhost:4000/docs/etc/gitblog_move/",
    "relUrl": "/docs/etc/gitblog_move/"
  },"164": {
    "doc": "The write format 1 is smaller than the supported format 2",
    "title": "The write format 1 is smaller than the supported format 2 [2.0.206/5]",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/h2_error/#the-write-format-1-is-smaller-than-the-supported-format-2-202065",
    "relUrl": "/docs/errors/h2_error/#the-write-format-1-is-smaller-than-the-supported-format-2-202065"
  },"165": {
    "doc": "The write format 1 is smaller than the supported format 2",
    "title": "error",
    "content": "org.h2.jdbc.JdbcSQLNonTransientException: General error: \"The write format 1 is smaller than the supported format 2 [2.0.206/5]\" [50000-206] at org.h2.message.DbException.getJdbcSQLException(DbException.java:573) ~[h2-2.0.206.jar:2.0.206] at org.h2.message.DbException.getJdbcSQLException(DbException.java:496) ~[h2-2.0.206.jar:2.0.206] at org.h2.message.DbException.get(DbException.java:216) ~[h2-2.0.206.jar:2.0.206] at org.h2.mvstore.db.Store.convertMVStoreException(Store.java:166) ~[h2-2.0.206.jar:2.0.206] at org.h2.mvstore.db.Store.&lt;init&gt;(Store.java:140) ~[h2-2.0.206.jar:2.0.206] at org.h2.engine.Database.&lt;init&gt;(Database.java:324) ~[h2-2.0.206.jar:2.0.206] at org.h2.engine.Engine.openSession(Engine.java:92) ~[h2-2.0.206.jar:2.0.206] at org.h2.engine.Engine.openSession(Engine.java:222) ~[h2-2.0.206.jar:2.0.206] at org.h2.engine.Engine.createSession(Engine.java:201) ~[h2-2.0.206.jar:2.0.206] at org.h2.engine.SessionRemote.connectEmbeddedOrServer(SessionRemote.java:338) ~[h2-2.0.206.jar:2.0.206] at org.h2.jdbc.JdbcConnection.&lt;init&gt;(JdbcConnection.java:117) ~[h2-2.0.206.jar:2.0.206] at org.h2.Driver.connect(Driver.java:59) ~[h2-2.0.206.jar:2.0.206] at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:138) ~[HikariCP-3.4.5.jar:na] at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:358) ~[HikariCP-3.4.5.jar:na] at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:206) ~[HikariCP-3.4.5.jar:na] at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:477) [HikariCP-3.4.5.jar:na] at com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:560) [HikariCP-3.4.5.jar:na] at com.zaxxer.hikari.pool.HikariPool.&lt;init&gt;(HikariPool.java:115) [HikariCP-3.4.5.jar:na] at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:112) [HikariCP-3.4.5.jar:na] at org.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration.lambda$h2Console$0(H2ConsoleAutoConfiguration.java:72) [spring-boot-autoconfigure-2.3.12.RELEASE.jar:2.3.12.RELEASE] at org.springframework.beans.factory.ObjectProvider.ifAvailable(ObjectProvider.java:93) ~[spring-beans-5.2.15.RELEASE.jar:5.2.15.RELEASE] at org.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration.h2Console(H2ConsoleAutoConfiguration.java:71) [spring-boot-autoconfigure-2.3.12.RELEASE.jar:2.3.12.RELEASE] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_282] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_282] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_282] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_282] at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ~[spring-beans-5.2.15.RELEASE.jar:5.2.15.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:652) ~[spring-beans-5.2.15.RELEASE.jar:5.2.15.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:637) ~[spring-beans-5.2.15.RELEASE.jar:5.2.15.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1341) ~[spring-beans-5.2.15.RELEASE.jar:5.2.15.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1181) ~[spring-beans-5.2.15.RELEASE.jar:5.2.15.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:556) ~[spring-beans-5.2.15.RELEASE.jar:5.2.15.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) ~[spring-beans-5.2.15.RELEASE.jar:5.2.15.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) ~[spring-beans-5.2.15.RELEASE.jar:5.2.15.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) ~[spring-beans-5.2.15.RELEASE.jar:5.2.15.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) ~[spring-beans-5.2.15.RELEASE.jar:5.2.15.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:207) ~[spring-beans-5.2.15.RELEASE.jar:5.2.15.RELEASE] at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:211) ~[spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE] at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:202) ~[spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE] at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addServletContextInitializerBeans(ServletContextInitializerBeans.java:96) ~[spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE] at org.springframework.boot.web.servlet.ServletContextInitializerBeans.&lt;init&gt;(ServletContextInitializerBeans.java:85) ~[spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.getServletContextInitializerBeans(ServletWebServerApplicationContext.java:255) ~[spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.selfInitialize(ServletWebServerApplicationContext.java:229) ~[spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE] at org.springframework.boot.web.embedded.tomcat.TomcatStarter.onStartup(TomcatStarter.java:53) ~[spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE] at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5161) ~[tomcat-embed-core-9.0.46.jar:9.0.46] at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) ~[tomcat-embed-core-9.0.46.jar:9.0.46] at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1384) ~[tomcat-embed-core-9.0.46.jar:9.0.46] at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1374) ~[tomcat-embed-core-9.0.46.jar:9.0.46] at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_282] at org.apache.tomcat.util.threads.InlineExecutorService.execute(InlineExecutorService.java:75) ~[tomcat-embed-core-9.0.46.jar:9.0.46] at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:134) ~[na:1.8.0_282] at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:909) ~[tomcat-embed-core-9.0.46.jar:9.0.46] at org.apache.catalina.core.StandardHost.startInternal(StandardHost.java:829) ~[tomcat-embed-core-9.0.46.jar:9.0.46] at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) ~[tomcat-embed-core-9.0.46.jar:9.0.46] at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1384) ~[tomcat-embed-core-9.0.46.jar:9.0.46] at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1374) ~[tomcat-embed-core-9.0.46.jar:9.0.46] at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_282] at org.apache.tomcat.util.threads.InlineExecutorService.execute(InlineExecutorService.java:75) ~[tomcat-embed-core-9.0.46.jar:9.0.46] at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:134) ~[na:1.8.0_282] at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:909) ~[tomcat-embed-core-9.0.46.jar:9.0.46] at org.apache.catalina.core.StandardEngine.startInternal(StandardEngine.java:262) ~[tomcat-embed-core-9.0.46.jar:9.0.46] at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) ~[tomcat-embed-core-9.0.46.jar:9.0.46] at org.apache.catalina.core.StandardService.startInternal(StandardService.java:433) ~[tomcat-embed-core-9.0.46.jar:9.0.46] at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) ~[tomcat-embed-core-9.0.46.jar:9.0.46] at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:930) ~[tomcat-embed-core-9.0.46.jar:9.0.46] at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) ~[tomcat-embed-core-9.0.46.jar:9.0.46] at org.apache.catalina.startup.Tomcat.start(Tomcat.java:486) ~[tomcat-embed-core-9.0.46.jar:9.0.46] at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize(TomcatWebServer.java:123) ~[spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE] at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.&lt;init&gt;(TomcatWebServer.java:104) ~[spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE] at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getTomcatWebServer(TomcatServletWebServerFactory.java:440) ~[spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE] at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getWebServer(TomcatServletWebServerFactory.java:193) ~[spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.createWebServer(ServletWebServerApplicationContext.java:178) ~[spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:158) ~[spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:545) ~[spring-context-5.2.15.RELEASE.jar:5.2.15.RELEASE] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:143) ~[spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:755) ~[spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:747) ~[spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:402) ~[spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:312) ~[spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1247) ~[spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1236) ~[spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE] at spectra.attic.coreasset.ecosystem.registry.RegistryApplication.main(RegistryApplication.java:16) ~[classes/:na] Caused by: org.h2.mvstore.MVStoreException: The write format 1 is smaller than the supported format 2 [2.0.206/5] at org.h2.mvstore.DataUtils.newMVStoreException(DataUtils.java:1004) ~[h2-2.0.206.jar:2.0.206] at org.h2.mvstore.MVStore.getUnsupportedWriteFormatException(MVStore.java:1059) ~[h2-2.0.206.jar:2.0.206] at org.h2.mvstore.MVStore.readStoreHeader(MVStore.java:878) ~[h2-2.0.206.jar:2.0.206] at org.h2.mvstore.MVStore.&lt;init&gt;(MVStore.java:455) ~[h2-2.0.206.jar:2.0.206] at org.h2.mvstore.MVStore$Builder.open(MVStore.java:4052) ~[h2-2.0.206.jar:2.0.206] at org.h2.mvstore.db.Store.&lt;init&gt;(Store.java:129) ~[h2-2.0.206.jar:2.0.206] ... 77 common frames omitted . ",
    "url": "http://localhost:4000/docs/errors/h2_error/#error",
    "relUrl": "/docs/errors/h2_error/#error"
  },"166": {
    "doc": "The write format 1 is smaller than the supported format 2",
    "title": "solve",
    "content": "h2버전 업 전에 생성했던 h2파일이 이전 버전이어서 생긴 문제로 보여서 . 이전 h2파일 삭제하고 다시 재기동! . ",
    "url": "http://localhost:4000/docs/errors/h2_error/#solve",
    "relUrl": "/docs/errors/h2_error/#solve"
  },"167": {
    "doc": "The write format 1 is smaller than the supported format 2",
    "title": "The write format 1 is smaller than the supported format 2",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/h2_error/",
    "relUrl": "/docs/errors/h2_error/"
  },"168": {
    "doc": "HazelcastSerializationException",
    "title": "HazelcastSerializationException",
    "content": "error . nested exception is com.hazelcast.nio.serialization.HazelcastSerializationException: com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field \"btalkId\", not marked as ignorable (one known property: \"customerId\"]) at [Source: (String)\"{ \"customerId\" : \"DS3l1Bl_RGz2\", \"btalkId\" : \"0edc1246-cb45-4f87-bdc0-9768890c6614\" }\"; line: 3, column: 16] (through reference chain: BTalk[\"btalkId\"]); . cause . public class BtalkKey implements JsonSerializable { private String bTalkId; } . 변수를 bTalkId; 로 선언했더니, getter에서 getBTalkId로 되었지만, Hazelcast에서 json으로 찾으려고 할때, btalkId로 찾아서 발생한 오류 . resolve . 자바표준은 getter로 썼을때, 대문자가 연속으로 두번이 오는 것은 표준에 어긋난다고 함. 그래서 bTalkId 에서 btalkId;로 변수 선언 . reference . why-does-jackson-2-not-recognize-the-first-capital-letter-if-the-leading-camel-c . java-tip-6-dont-capitalize-first-two . ",
    "url": "http://localhost:4000/docs/errors/hazelcastSerializationException/",
    "relUrl": "/docs/errors/hazelcastSerializationException/"
  },"169": {
    "doc": "Home",
    "title": "recently update",
    "content": ":: toy project . | webpage 스크랩핑 후 갱신여부 체크하는 어플리케이션 개발 | 다른 msa서비스 API 변경 체크 - tdd작성 | springboot admin - custom 메뉴 추가(quartz 설정 화면 추가) | . :: post . 2022-10-01 change Feign And Loadbalancer Retry 2022-10-01 change Hystrix to Resilience4j 2022-10-01 change netflix-ribbon to spring-cloud-loadbalancer 2022-09-23 kafka inconsistentClusterIdException 2022-09-21 docker elasticsearch shutdown cause 2022-09-19 upsource ReviewNotFoundException 2022-09-08 A “NullPointerException” could be thrown; “getListenerContainer()” can return null. 2022-09-07 BeanInstantiationException Failed to instantiate 2022-09-06 intellij gc overhead limit exceeded maven 2022-09-03 우아한 CRUD - Spring Data JDBC Advanced . ",
    "url": "http://localhost:4000/#recently-update",
    "relUrl": "/#recently-update"
  },"170": {
    "doc": "Home",
    "title": "Home",
    "content": " ",
    "url": "http://localhost:4000/",
    "relUrl": "/"
  },"171": {
    "doc": "cannot be opened because it does not exist",
    "title": "cannot be opened because it does not exist",
    "content": "problems . 인텔리제이에서 spring boot run하면 아래와 같은 오류발생 . 09:06:19.237 main ERROR o.s.b.SpringApplication :834 reportFailure Application run failed org.springframework.beans.factory.BeanDefinitionStoreException: Failed to parse configuration class [Application]; nested exception is java.io.FileNotFoundException: class path resource [ExpireTokenAdapter.class] cannot be opened because it does not exist Process finished with exit code 1 . try 1 . 절케해도 안되서 . 전체 maven reload했는데 . java.lang.OutOfMemoryError: GC overhead limit exceeded 이렇게 오류발생 . try 2 . 메모리 옵션 -xms1024m -xmx2048m으로 늘리고 다시 시도 . 그래도 에러나는 모듈있어서 . 에러나는 모듈은 폴더자체 rebuild해주고 다시 재시작하니까 된다 . 그래도 다음날 계속 소스를 pull받다보니 이미 존재하는 class파일인데 cannot find오류가 나서 . springboot 시작전에 before build하는 옵션을 제거하고 . solution . 수동 build하는 것으로 바꾸니 잘된다. 에러도 없고 오히려 이게 빠른것 같다. 수동 build는 인텔리제이 [Build &gt; Build Project] 실행 . ",
    "url": "http://localhost:4000/docs/errors/intellij1/",
    "relUrl": "/docs/errors/intellij1/"
  },"172": {
    "doc": "intellij gc overhead limit exceeded maven",
    "title": "problem",
    "content": ". | 이유는 여러가지인 것 같은데, 이번에 발생한 이유는 종합적이였다. 주로 pull 받고나서 발생한다. | pom.xml의 version이 잘못되어서 전체 build 실패가 발생하거나 | 패키지 경로가 변경된 파일을 pull받았을 때 | . | 원인을 그냥 수정했으면 해결되었을 것 같다. 근데 이것저것 clear하고 하다보니 점점 더 꼬이게 된 것 같다. | 그래서 rebuild 및 build를 돌리면 이미 컴파일이 되어있음에도 intellij는 package not found에러를 전체 모듈개수만큼 발생시킨다. 전체적으로 고장난 느낌 ㅜㅠ | . ",
    "url": "http://localhost:4000/docs/errors/intellij_gc/#problem",
    "relUrl": "/docs/errors/intellij_gc/#problem"
  },"173": {
    "doc": "intellij gc overhead limit exceeded maven",
    "title": "try 1",
    "content": ". | 이런 유형의 직접적인 원인은 gc가 아닌 경우가 많았다. | compiler 버전이 맞지 않았다거나 . | intellij &gt; settings &gt; build, execution, deployment → Compiler → Java Compiler | . | . ",
    "url": "http://localhost:4000/docs/errors/intellij_gc/#try-1",
    "relUrl": "/docs/errors/intellij_gc/#try-1"
  },"174": {
    "doc": "intellij gc overhead limit exceeded maven",
    "title": "try 2",
    "content": ". | 최근에 push된 git history를 보는 것도 좋다. | 아까처럼 pom.xml 오류가 발생했다거나 | 새로운 module이 추가되었거나 | 기존 module이 삭제되었는데 dependency 오류가 있다거나 | mudule name이 변경되었다거나 | . | . ",
    "url": "http://localhost:4000/docs/errors/intellij_gc/#try-2",
    "relUrl": "/docs/errors/intellij_gc/#try-2"
  },"175": {
    "doc": "intellij gc overhead limit exceeded maven",
    "title": "try 3. do not use “clear output directory on rebuild” option",
    "content": ". | 이번엔 이 옵션 해제로 해결! 어차피 수동으로 빌드할 때마다 clear하고 하기 때문에 해제해도 되었다. | 추가로 “Rebuild module on dependency change” 옵션도 해제했다. pc 성능이 안좋다보니 자동으로 되는 것들이 오히려 문제 일으키는 것 같아서.. | . ",
    "url": "http://localhost:4000/docs/errors/intellij_gc/#try-3-do-not-use-clear-output-directory-on-rebuild-option",
    "relUrl": "/docs/errors/intellij_gc/#try-3-do-not-use-clear-output-directory-on-rebuild-option"
  },"176": {
    "doc": "intellij gc overhead limit exceeded maven",
    "title": "try 3",
    "content": "다 안된다고 하면, 다른 경로에 파일을 새로 받아서 신규 프로젝트로 다시 생성하는 것도 방법이다. ",
    "url": "http://localhost:4000/docs/errors/intellij_gc/#try-3",
    "relUrl": "/docs/errors/intellij_gc/#try-3"
  },"177": {
    "doc": "intellij gc overhead limit exceeded maven",
    "title": "intellij gc overhead limit exceeded maven",
    "content": ". ",
    "url": "http://localhost:4000/docs/errors/intellij_gc/",
    "relUrl": "/docs/errors/intellij_gc/"
  },"178": {
    "doc": "Intercepting Filter Pattern",
    "title": "Intercepting Filter Pattern",
    "content": "Interception Filter Pattern . | 체인으로 묶인 필터를 통과하면서 최종적으로 Target 클래스에 도달하도록 한다. | 전처리/후처리를 수행하려고 하는 경우 사용 | . ",
    "url": "http://localhost:4000/docs/patterns/intercepting_filter_pattern/",
    "relUrl": "/docs/patterns/intercepting_filter_pattern/"
  },"179": {
    "doc": "Intercepting Filter Pattern",
    "title": "Entity.",
    "content": "Filter:: . 실제로 필터작업을 구현하고, 실행 . public class AppChannelFilter implements BusinessMessageFilter { // 특정 App채널만 유효하도록 필터링 private final AppChannelTypeValidator appChannelTypeValidator; @Override public void execute(ConversationMessage conversationMessage) { appChannelTypeValidator.validate(); } } . Filter Chain:: . 여러 필터들을 순서대로 실행하기 위해 체인으로 묶음 . Target:: . 모든 필터가 통과되면 최종적으로 실행될 엔티티 . Filter Manager:: . 여러 필터들과 필터 체인을 연결 . public class BusinessMessageFilterManager { private final List&lt;BusinessMessageFilter&gt; businessMessageFilters; public void execute(ConversationMessage conversationMessage){ for (BusinessMessageFilter businessMessageFilter : businessMessageFilters) { businessMessageFilter.execute(conversationMessage); } } } . Client:: . 필터요청하는 엔티티 . public class BtalkMessageFilterExecutor { private final BusinessMessageFilterManager businessMessageFilterManager; public void filter(ConversationMessage conversationMessage) { businessMessageFilterManager.execute(conversationMessage); } } . 참고. https://www.tutorialspoint.com/design_pattern/intercepting_filter_pattern.htm . ",
    "url": "http://localhost:4000/docs/patterns/intercepting_filter_pattern/#entity",
    "relUrl": "/docs/patterns/intercepting_filter_pattern/#entity"
  },"180": {
    "doc": "ios 웹앱 만들기",
    "title": "목표",
    "content": "firebase로 푸시받는 것 까지 하고 앱으로 배포 . ",
    "url": "http://localhost:4000/docs/etc/ios_webapp/#%EB%AA%A9%ED%91%9C",
    "relUrl": "/docs/etc/ios_webapp/#목표"
  },"181": {
    "doc": "ios 웹앱 만들기",
    "title": "기본 웹앱 작성",
    "content": "웹앱 코드(https://www.youtube.com/watch?v=JafGypqFvs4) . ",
    "url": "http://localhost:4000/docs/etc/ios_webapp/#%EA%B8%B0%EB%B3%B8-%EC%9B%B9%EC%95%B1-%EC%9E%91%EC%84%B1",
    "relUrl": "/docs/etc/ios_webapp/#기본-웹앱-작성"
  },"182": {
    "doc": "ios 웹앱 만들기",
    "title": "인증서 작업",
    "content": ". | testflight으로 푸시테스트가 가능하려면, AdHoc Provisioning Profile which will use the production push certificate을 발급받아야 한다. (개발용이면 안됨) | 일단 fcm을 통한 발송준비용 인증서 . | fcm을 통해서 발송하는 것은 apns를 통해서 하는 인증서 절차보다 간단합니다. apns를 통해 발송할 경우, fcm에서 한 절차보다 몇 가지 더 하면 됩니다.(두개를 공통으로 사용가능) | mac의 키체인에서 인증서 만들고 | Identifiers app등록 . | App ID Prefix는 아무거나 (teamid가 없는것도 됨) | push notification 선택 | . | 다 등록하고 다시 상세내용에서 push notification의 edit 화면에서 배포용 인증서 생성 . | 로컬 키체인에서 csr파일 생성 (앱이 다르면, 각각 만들어주는 것이 좋다) - https://ios-development.tistory.com/247 | 그러면 Certificates, Identifiers &amp; Profiles &gt; Certificate에서 푸시용 배포용 2개만들어지게 됨 | 그러면 총 개인용, 푸시용(Apple Push Services로 등록한), 배포용 3개가 됨 | 앱을 동일 계정으로 여러개 만들 경우는 identifiers app등록하고 csr인증서 연결해주고 key등록해주면 됨 | . | Profile은 fcm일땐 생성안해도 됨 | Keys 생성 (중요!) . | 나중에 fcm 콘솔에 등록해야 하므로, 다운로드 파일(p8), Key Id 적어야함 | . | . | firebase 설정 . | firebase 프로젝트 생성하고 → plist파일을 xcode에 넣고 → xcode 프로젝트에 firebase 라이브러리 추가하고(라이브러리는 firebase messaging 만 선택) → firebase 코드 추가한다. | 클라우드 메시지 → APN 인증 키 추가 . | apple developer의 Key 등록했을 때 받은, Keys의 Key Id, AuthKey~~.p8 | team Id는 계정의 팀 아이디를 적는다(인증서랑 무관) | . | . | 이제는 xcode 작업 . | Sigining &amp; Capabilities에 push notification 과 background modes 추가 . | background modes에는 background fetch와 remote notifications 선택 | . | info.plist에 속성 추가 . | FirebaseAppDelegateProxyEnabled를 boolean으로 추가하고 NO로 설정 | . | . | . ",
    "url": "http://localhost:4000/docs/etc/ios_webapp/#%EC%9D%B8%EC%A6%9D%EC%84%9C-%EC%9E%91%EC%97%85",
    "relUrl": "/docs/etc/ios_webapp/#인증서-작업"
  },"183": {
    "doc": "ios 웹앱 만들기",
    "title": "푸시 메시지 발송",
    "content": ". | 테스트 . | node의 apn모듈로 발송 . | 준비물 : 위에서 인증서 생성시 다운받은 p8파일과 p8파일의 KeyID, 팀ID, 번들ID | . iOS APNs 인증 키 p8 (iOS Key로 푸시 보내기) . | firebase를 통해서 발송하는 방법도 있음 . | token을 에스프레소로 앱에서 호출하도록 해야함 | 발송시간을 지금으로 해도 폰으로 오기까지 2~3분정도 걸리는 것 같다 | . | . | token들을 서버 API를 통해 등록시키기 . Alamofire라이브러리를 pod로 설치해서 post api . iOS : Alamofire 를 이용한 API 호출 . | . ",
    "url": "http://localhost:4000/docs/etc/ios_webapp/#%ED%91%B8%EC%8B%9C-%EB%A9%94%EC%8B%9C%EC%A7%80-%EB%B0%9C%EC%86%A1",
    "relUrl": "/docs/etc/ios_webapp/#푸시-메시지-발송"
  },"184": {
    "doc": "ios 웹앱 만들기",
    "title": "기타",
    "content": ". | 앱아이콘 적용(https://appicon.co/) | 뱃지 : ios는 서버에서 숫자를 발송시켜줘야한다고 함. 앱에선 왔을때 0으로 초기화하는 코드만 두고 | . ",
    "url": "http://localhost:4000/docs/etc/ios_webapp/#%EA%B8%B0%ED%83%80",
    "relUrl": "/docs/etc/ios_webapp/#기타"
  },"185": {
    "doc": "ios 웹앱 만들기",
    "title": "배포",
    "content": ". | 방식 결정 : 배포방식 중 testflight을 사용해보도록 함 | . 알면 알수록 헷갈리는 IOS 환경 #2 - 앱 배포방식에 대해서 알아보자. | 순서 . | https://dev-yakuza.posstree.com/ko/react-native/ios-testflight/ 에 따라 xcode에서 앱 배포 | xcode의 archive로 여러 앱을 했더니 자꾸 codesign이 다른 키체인껄로 되어서 아래와 같은 에러가 난다. | . App Store Connect Operation Error No suitable application records were found. Verify your bundle identifier ‘~~~’ is correct. —&gt; 여러 가지 방법을 다 해봤지만, 결국 안되어서 Transporter앱을 통해서 업로드했다(https://red-cherry-ring.tistory.com/16) —&gt; 성공!! . | 배포전 info.plist파일에 수출규정준수 설정 제외시켜야 함 (https://jh3786.tistory.com/11) | . | 참고 . | https://testflight.apple.com/ | . | . ",
    "url": "http://localhost:4000/docs/etc/ios_webapp/#%EB%B0%B0%ED%8F%AC",
    "relUrl": "/docs/etc/ios_webapp/#배포"
  },"186": {
    "doc": "ios 웹앱 만들기",
    "title": "reference",
    "content": "https://dev200ok.blogspot.com/2020/04/ios-notification-push.html . https://www.raywenderlich.com/11395893-push-notifications-tutorial-getting-started . ",
    "url": "http://localhost:4000/docs/etc/ios_webapp/#reference",
    "relUrl": "/docs/etc/ios_webapp/#reference"
  },"187": {
    "doc": "ios 웹앱 만들기",
    "title": "기타",
    "content": "[iOS] 푸시알림 클라우드 메세지 보내기[2] (APNS, 파이어베이스) . | 내 계정이 회사 계정의 팀멤버로 연결되어서, 인증서를 생성할 수 없는 문제가 생겼는데.(팀관리자 계정이 갱신이 안되어서..) - 일단 푸시하려면 구독이 필요해보인다. | 내 맥은 카탈리나 10.15.7이고 xcode는 12.5로 ios15이상은 시뮬레이터나 폰에도 설치가 안되는 문제가 있다. | xcode13버전의 파일을 일부 옮겨와서 폰에 설치하려고 하니, 빌드는 성공했지만 아래오류 발생 | . The code signature version is no longer supported. Domain: com.apple.dt.MobileDeviceErrorDomain . | 해결은 https://stackoverflow.com/a/68467307 이렇게 -generate-entitlement-der를 추가해줬다. | 저걸해주고 나서 fcm연동하니 발생했는데, TARGETS -&gt; select[your project name] -&gt; General -&gt; Frameworks,Libraries,and EmbeddedContent 에 가서 Firebase Analystic인가 하는 라이브러리를 제거해줬더니 해결 | . | p12파일을 생성하기까지 | . iOS) APNs :: 인증서 발급받는 방법 (p.12, pem) . [ios] 자바 스프링 서버에서 iOS앱에 푸시 알림 보내기(APNs 개발용, 배포용) . [iOS] Spring 서버에서 사용할 APNS 인증서 준비 . ",
    "url": "http://localhost:4000/docs/etc/ios_webapp/#%EA%B8%B0%ED%83%80-1",
    "relUrl": "/docs/etc/ios_webapp/#기타-1"
  },"188": {
    "doc": "ios 웹앱 만들기",
    "title": "ios 웹앱 만들기",
    "content": " ",
    "url": "http://localhost:4000/docs/etc/ios_webapp/",
    "relUrl": "/docs/etc/ios_webapp/"
  },"189": {
    "doc": "Java",
    "title": "Java",
    "content": " ",
    "url": "http://localhost:4000/docs/clipping/java/java/",
    "relUrl": "/docs/clipping/java/java/"
  },"190": {
    "doc": "header contains multiple values...",
    "title": "header contains multiple values ‘*, *’, but only one is allowed",
    "content": "header contains multiple values ‘*, *’, but only one is allowed . 라고 크롬콘솔에 찍힐때 . response.addheader를 똑같은 값으로 두번한건 아닌지 체크필요. 중복선언시 저런 에러난다. ",
    "url": "http://localhost:4000/docs/errors/java1/#header-contains-multiple-values---but-only-one-is-allowed",
    "relUrl": "/docs/errors/java1/#header-contains-multiple-values---but-only-one-is-allowed"
  },"191": {
    "doc": "header contains multiple values...",
    "title": "header contains multiple values...",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/java1/",
    "relUrl": "/docs/errors/java1/"
  },"192": {
    "doc": "Unsatisfied dependency expressed through constructor parameter 8; nested exception...",
    "title": "Unsatisfied dependency expressed through constructor parameter 8; nested exception…",
    "content": "오류 : Unsatisfied dependency expressed through constructor parameter 8; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name ‘TestAdapter’: FactoryBean threw exception on object creation; nested exception is java.lang.IllegalStateException: Method find not annotated with HTTP method type (ex. GET, POST) . 원인:TestAdapter에 부모가 선언하지 않은 이름의 메소드로 선언되어있어서 그러함. 즉 부모에 있는데TestAdapter에 구현체가 없어서 나오는 에러 . ",
    "url": "http://localhost:4000/docs/errors/java2/#unsatisfied-dependency-expressed-through-constructor-parameter-8-nested-exception",
    "relUrl": "/docs/errors/java2/#unsatisfied-dependency-expressed-through-constructor-parameter-8-nested-exception"
  },"193": {
    "doc": "Unsatisfied dependency expressed through constructor parameter 8; nested exception...",
    "title": "Unsatisfied dependency expressed through constructor parameter 8; nested exception...",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/java2/",
    "relUrl": "/docs/errors/java2/"
  },"194": {
    "doc": "Can't generate resourceBase as part of webapp tmp dir name",
    "title": "Can’t generate resourceBase as part of webapp tmp dir name: java.lang.NullPointerException",
    "content": "현상) 인텔리제이에서 application으로 jetty올리는데 에러가 나면서 안올라갈때 . 오류) [09-29 09:01:17.454] WARN [main] [o.e.j.w.WebInfConfiguration.getCanonicalNameForWebAppTmpDir] 627 - Can’t generate resourceBase as part of webapp tmp dir name: java.lang.NullPointerException . [09-29 09:01:17.665] WARN [main] [o.e.j.w.WebAppContext.doStart] 514 - Failed startup of context o.e.j.w.WebAppContext@17695df3{/router,[],null} . java.lang.NullPointerException: null . at org.eclipse.jetty.webapp.WebAppContext.getWebInf(WebAppContext.java:844) . at org.eclipse.jetty.webapp.WebInfConfiguration.findWebInfLibJars(WebInfConfiguration.java:708) . at org.eclipse.jetty.webapp.WebInfConfiguration.findJars(WebInfConfiguration.java:689) . at org.eclipse.jetty.webapp.WebInfConfiguration.preConfigure(WebInfConfiguration.java:128) . at org.eclipse.jetty.webapp.WebAppContext.preConfigure(WebAppContext.java:468) . at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:504) . at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68) . at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:132) . at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:114) . at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:61) . at org.eclipse.jetty.server.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:163) . at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68) . at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:132) . at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:114) . at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:61) . at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68) . at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:132) . at org.eclipse.jetty.server.Server.start(Server.java:387) . at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:114) . at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:61) . at org.eclipse.jetty.server.Server.doStart(Server.java:354) . at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68) . 원인) . 첫번째로, 이 프로젝트랑 상관없는 path의 디렉토리를 옮겼었는데, 그걸 못찾는다고 나온당…그래서 그건 그냥 .idea폴더 날리고 , 프로젝트 재생성 . 두번째로, 어플리케이션 올릴때 Working directory에 %MODULE_WORKING_DIR%이렇게 줘야하는데 없어서,,,, 참고로 $MODULE_DIR$ 에서 %MODULE_WORKING_DIR% 이렇게 바뀜 . ",
    "url": "http://localhost:4000/docs/errors/jetty1/#cant-generate-resourcebase-as-part-of-webapp-tmp-dir-name-javalangnullpointerexception",
    "relUrl": "/docs/errors/jetty1/#cant-generate-resourcebase-as-part-of-webapp-tmp-dir-name-javalangnullpointerexception"
  },"195": {
    "doc": "Can't generate resourceBase as part of webapp tmp dir name",
    "title": "Can't generate resourceBase as part of webapp tmp dir name",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/jetty1/",
    "relUrl": "/docs/errors/jetty1/"
  },"196": {
    "doc": "Jpa",
    "title": "Jpa",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/jpa/jpa/",
    "relUrl": "/docs/msa/jpa/jpa/"
  },"197": {
    "doc": "store-jpa 모듈을 만들고 나니 Not a managed type 에러 날때",
    "title": "store-jpa 모듈을 만들고 나니 Not a managed type 에러 날때",
    "content": "error log . 11:30:46.596 main WARN stractApplicationContext:557 refresh Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'aaaService' defined in file []: Unsatisfied dependency expressed through constructor parameter 0; nested exception is at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:769) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:218) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1341) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1187) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:845) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:742) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:389) at org.springframework.boot.SpringApplication.run(SpringApplication.java:311) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1213) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1202) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:769) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:218) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1341) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1187) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:277) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1251) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1171) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:857) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:760) ... 19 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'internalGatewayRepository': Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class AAAJpo at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1778) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:277) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1251) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1171) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:857) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:760)... 33 common frames omitted Caused by: java.lang.IllegalArgumentException: Not a managed type: class AAAGatewayJpo at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:552) at org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.&lt;init&gt;(JpaMetamodelEntityInformation.java:74) at org.springframework.data.jpa.repository.support.JpaEntityInformationSupport.getEntityInformation(JpaEntityInformationSupport.java:66) at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getEntityInformation(JpaRepositoryFactory.java:201) at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:151) at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:134) at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:65) at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:305) at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.lambda$afterPropertiesSet$5(RepositoryFactoryBeanSupport.java:297) at org.springframework.data.util.Lazy.getNullable(Lazy.java:211) at org.springframework.data.util.Lazy.get(Lazy.java:94) at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.afterPropertiesSet(RepositoryFactoryBeanSupport.java:300) at org.springframework.data.jpa.repository.support.JpaRepositoryFactoryBean.afterPropertiesSet(JpaRepositoryFactoryBean.java:121) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1837) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1774) ... 44 common frames omitted Process finished with exit code 1 . cause . SpringApplication으로 서비스 올릴 때, scan하는 패키지는 test.www인데 springboot로 올리는 application 파일은 test.www.aaa.boot아래에 있었다. 이걸 test.www.aaa 하위로 옮기고 나니 해결됨 . ",
    "url": "http://localhost:4000/docs/errors/jpa1/",
    "relUrl": "/docs/errors/jpa1/"
  },"198": {
    "doc": "jpa 프로그래밍",
    "title": "3. 영속성 관리",
    "content": "@DynamicUpdate . 컬럼이 30개 이상이 되면, @DynamicUpdate를 사용한 동적 수정 쿼리가 정적 수정 쿼리보다 빠르다. 하지만 한 테이블에 컬럼이 30개 이상 된다는 것은 테이블 설계상 분리가 적절하게 되지 않았을 가능성이 높다. @SequenceGenerator . SequenceGenterator.allocationSize의 기본값은 50이다. 이는 최적화 때문인데, 만약 하나씩 증가해야한다면 1로 설정하면 된다. @SeqyebceGeberator는 @GeneratedValue 옆에 사용해도 된다. ",
    "url": "http://localhost:4000/docs/clipping/msa/jpa_programming/#3-%EC%98%81%EC%86%8D%EC%84%B1-%EA%B4%80%EB%A6%AC",
    "relUrl": "/docs/clipping/msa/jpa_programming/#3-영속성-관리"
  },"199": {
    "doc": "jpa 프로그래밍",
    "title": "4. 엔티티 맵핑",
    "content": "@Column 생략 . int data1; // @Column생략, 자바 기본타입으로 not null로 생성된다. Integer data2; // @Column 생략하면 nullable속성으로 생성된다. 따라서 자바 기본타입에 @Column을 사용하면 nullable = false로 지정하는 것이 안전하다. ",
    "url": "http://localhost:4000/docs/clipping/msa/jpa_programming/#4-%EC%97%94%ED%8B%B0%ED%8B%B0-%EB%A7%B5%ED%95%91",
    "relUrl": "/docs/clipping/msa/jpa_programming/#4-엔티티-맵핑"
  },"200": {
    "doc": "jpa 프로그래밍",
    "title": "5. 연관관계 매핑 기초",
    "content": "양방향 매핑 . 양방향 매핑시에는 무한 루프에 빠지지 않게 조심해야한다. 예를 들어 Member.toString()에서 getTeam()을 호출하고 Team.toString()에서 getMember()를 호출하면 무한 루프에 빠질 수 있다. 이런 문제는 엔티티를 JSON으로 변환할 때 자주 발생한다. ",
    "url": "http://localhost:4000/docs/clipping/msa/jpa_programming/#5-%EC%97%B0%EA%B4%80%EA%B4%80%EA%B3%84-%EB%A7%A4%ED%95%91-%EA%B8%B0%EC%B4%88",
    "relUrl": "/docs/clipping/msa/jpa_programming/#5-연관관계-매핑-기초"
  },"201": {
    "doc": "jpa 프로그래밍",
    "title": "6. 다양한 연관관계 매핑",
    "content": "일대다 . | 일대다 단방향 매핑보다는 다대일 양방향 매핑을 사용하자. | 관계형 데이터베이스 특성상 외래키는 항상 다 쪽에 있다. 그러므로 양방향 매핑에서 @OneToMany는 연관관계의 주인이 될 수 없다. 이런 이유로 @ManyToOne에는 mappedBy속성이 없다. | . ",
    "url": "http://localhost:4000/docs/clipping/msa/jpa_programming/#6-%EB%8B%A4%EC%96%91%ED%95%9C-%EC%97%B0%EA%B4%80%EA%B4%80%EA%B3%84-%EB%A7%A4%ED%95%91",
    "relUrl": "/docs/clipping/msa/jpa_programming/#6-다양한-연관관계-매핑"
  },"202": {
    "doc": "jpa 프로그래밍",
    "title": "7. 고급 매핑",
    "content": "복합키와 식별 관계 매핑 . | 복합 키에는 @GenerateValue를 사용할 수 없다. 복합 키를 구성하는 여러 컬럼 중 하나에도 사용할 수 없다. | . ",
    "url": "http://localhost:4000/docs/clipping/msa/jpa_programming/#7-%EA%B3%A0%EA%B8%89-%EB%A7%A4%ED%95%91",
    "relUrl": "/docs/clipping/msa/jpa_programming/#7-고급-매핑"
  },"203": {
    "doc": "jpa 프로그래밍",
    "title": "9. 값 타입",
    "content": "임베디드 타입(복합 값 타입) . | 임베디드 타입은 기본 생성자가 필수다. | 임베디드 타입을 포함한 모든 값 타입은 엔티티의 생명주기에 의존하므로 엔티티와 임베디드 타입의 관계를 UML로 표현하면 컴포지션 관계가 된다 | 하이버네이트는 임베디드 타입을 컴포넌트라고 한다. | . ",
    "url": "http://localhost:4000/docs/clipping/msa/jpa_programming/#9-%EA%B0%92-%ED%83%80%EC%9E%85",
    "relUrl": "/docs/clipping/msa/jpa_programming/#9-값-타입"
  },"204": {
    "doc": "jpa 프로그래밍",
    "title": "12. 스프링 데데이이터 JPA",
    "content": "쿼리 메소드 기능 . | 스프링 데이터 JPA 쿼리 생성 기능 | . ",
    "url": "http://localhost:4000/docs/clipping/msa/jpa_programming/#12-%EC%8A%A4%ED%94%84%EB%A7%81-%EB%8D%B0%EB%8D%B0%EC%9D%B4%EC%9D%B4%ED%84%B0-jpa",
    "relUrl": "/docs/clipping/msa/jpa_programming/#12-스프링-데데이이터-jpa"
  },"205": {
    "doc": "jpa 프로그래밍",
    "title": "14. 컬렉션과 부가  기능",
    "content": "리스너 . | 엔티티의 생명주기에 따른 이벤트를 처리할 수 있다. | 방법 . | 엔티티에 직접 이벤트를 적용하는 방법(@PostPersist, @PostLoad…) | 별도의 리스너 등록 @EntityListener(DuckListener.class) Public class Duck { ... } public class DuckListener { @PrePersist private void prePersist(Object obj) { } @PostPersist private void postPersist(Object obj) { } } . | 기본 리스너 사용 . | 모든 엔티티에 적용하는 경우라면 기본 리스너로 등록하면 된다. | . | . | . ",
    "url": "http://localhost:4000/docs/clipping/msa/jpa_programming/#14-%EC%BB%AC%EB%A0%89%EC%85%98%EA%B3%BC-%EB%B6%80%EA%B0%80--%EA%B8%B0%EB%8A%A5",
    "relUrl": "/docs/clipping/msa/jpa_programming/#14-컬렉션과-부가--기능"
  },"206": {
    "doc": "jpa 프로그래밍",
    "title": "jpa 프로그래밍",
    "content": ". ",
    "url": "http://localhost:4000/docs/clipping/msa/jpa_programming/",
    "relUrl": "/docs/clipping/msa/jpa_programming/"
  },"207": {
    "doc": "Jpa saveAll Stress Test Result",
    "title": "부하 scenario",
    "content": ". | tps20으로, 챗봇이력을 400개씩 전송한다. | 서버 정보 . | 4코어 하이퍼쓰레딩 → 8thread | . | . ",
    "url": "http://localhost:4000/docs/msa/jpa/jpa_saveAll/#%EB%B6%80%ED%95%98-scenario",
    "relUrl": "/docs/msa/jpa/jpa_saveAll/#부하-scenario"
  },"208": {
    "doc": "Jpa saveAll Stress Test Result",
    "title": "problem",
    "content": "save → saveAll 로 변경해서 transaction을 하나로 줄였지만 오히려 오래 걸리는 케이스가 다수 발생 . | elapsed = 174,283 ms | sqlCount=1200, sqlTime=125,509 ms | . • API서버에 지연이 발생함에 따라 호출했던 클라이언트 서버에도 지연이 발생되어, 새로운 메시지가 들어와도 wait 상태 발생 . | 쿼리 로깅해보면 ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61)를 타고 여러 row가 한개씩 insert되고 있다. —&gt; batch가 적용된 것이 아니란 뜻 | . hu Aug 11 10:48:24 KST 2022 INFO: [FETCH] [Created on: Thu Aug 11 10:48:24 KST 2022, duration: 0, connection-id: 245, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61)] Thu Aug 11 10:48:24 KST 2022 INFO: [QUERY] insert into mocha_bot_message (C_APP_CHANNEL_ID, C_CREATED_AT, C_CUSTOMER_ID, C_MESSAGE, C_TALK_ID, C_UTTERANCE, C_BOT_MESSAGE_ID, C_TENANT_ID) values ('e3158759b0449439fe59b2edb32b4de91bce13fa', 1660 ... (truncated) [Created on: Thu Aug 11 10:48:24 KST 2022, duration: 1, connection-id: 246, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61)] Thu Aug 11 10:48:24 KST 2022 INFO: [FETCH] [Created on: Thu Aug 11 10:48:24 KST 2022, duration: 0, connection-id: 246, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61)] Thu Aug 11 10:48:24 KST 2022 INFO: [QUERY] insert into mocha_bot_message (C_APP_CHANNEL_ID, C_CREATED_AT, C_CUSTOMER_ID, C_MESSAGE, C_TALK_ID, C_UTTERANCE, C_BOT_MESSAGE_ID, C_TENANT_ID) values ('e3158759b0449439fe59b2edb32b4de91bce13fa', 1660 ... (truncated) [Created on: Thu Aug 11 10:48:24 KST 2022, duration: 1, connection-id: 248, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61)] Thu Aug 11 10:48:24 KST 2022 INFO: [FETCH] [Created on: Thu Aug 11 10:48:24 KST 2022, duration: 0, connection-id: 248, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61)] Thu Aug 11 10:48:24 KST 2022 INFO: [QUERY] insert into mocha_bot_message (C_APP_CHANNEL_ID, C_CREATED_AT, C_CUSTOMER_ID, C_MESSAGE, C_TALK_ID, C_UTTERANCE, C_BOT_MESSAGE_ID, C_TENANT_ID) values ('e3158759b0449439fe59b2edb32b4de91bce13fa', 1660 ... (truncated) [Created on: Thu Aug 11 10:48:24 KST 2022, duration: 0, connection-id: 245, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61)] Thu Aug 11 10:48:24 KST 2022 INFO: [FETCH] [Created on: Thu Aug 11 10:48:24 KST 2022, duration: 0, connection-id: 245, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61)] Thu Aug 11 10:48:24 KST 2022 INFO: [QUERY] insert into mocha_bot_message (C_APP_CHANNEL_ID, C_CREATED_AT, C_CUSTOMER_ID, C_MESSAGE, C_TALK_ID, C_UTTERANCE, C_BOT_MESSAGE_ID, C_TENANT_ID) values ('e3158759b0449439fe59b2edb32b4de91bce13fa', 1660 ... (truncated) [Created on: Thu Aug 11 10:48:24 KST 2022, duration: 2, connection-id: 246, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61)] Thu Aug 11 10:48:24 KST 2022 INFO: [QUERY] insert into mocha_bot_message (C_APP_CHANNEL_ID, C_CREATED_AT, C_CUSTOMER_ID, C_MESSAGE, C_TALK_ID, C_UTTERANCE, C_BOT_MESSAGE_ID, C_TENANT_ID) values ('e3158759b0449439fe59b2edb32b4de91bce13fa', 1660 ... (truncated) [Created on: Thu Aug 11 10:48:24 KST 2022, duration: 2, connection-id: 248, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61)] Thu Aug 11 10:48:24 KST 2022 INFO: [QUERY] insert into mocha_bot_message (C_APP_CHANNEL_ID, C_CREATED_AT, C_CUSTOMER_ID, C_MESSAGE, C_TALK_ID, C_UTTERANCE, C_BOT_MESSAGE_ID, C_TENANT_ID) values ('e3158759b0449439fe59b2edb32b4de91bce13fa', 1660 ... (truncated) [Created on: Thu Aug 11 10:48:24 KST 2022, duration: 1, connection-id: 245, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61)] Thu Aug 11 10:48:24 KST 2022 INFO: [FETCH] [Created on: Thu Aug 11 10:48:24 KST 2022, duration: 0, connection-id: 246, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61)] Thu Aug 11 10:48:24 KST 2022 INFO: [FETCH] [Created on: Thu Aug 11 10:48:24 KST 2022, duration: 0, connection-id: 248, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61)] Thu Aug 11 10:48:24 KST 2022 INFO: [FETCH] [Created on: Thu Aug 11 10:48:24 KST 2022, duration: 0, connection-id: 245, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61)] Thu Aug 11 10:48:24 KST 2022 INFO: [QUERY] insert into mocha_bot_message (C_APP_CHANNEL_ID, C_CREATED_AT, C_CUSTOMER_ID, C_MESSAGE, C_TALK_ID, C_UTTERANCE, C_BOT_MESSAGE_ID, C_TENANT_ID) values ('e3158759b0449439fe59b2edb32b4de91bce13fa', 1660 ... (truncated) [Created on: Thu Aug 11 10:48:24 KST 2022, duration: 0, connection-id: 246, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61)] Thu Aug 11 10:48:24 KST 2022 INFO: [QUERY] insert into mocha_bot_message (C_APP_CHANNEL_ID, C_CREATED_AT, C_CUSTOMER_ID, C_MESSAGE, C_TALK_ID, C_UTTERANCE, C_BOT_MESSAGE_ID, C_TENANT_ID) values ('e3158759b0449439fe59b2edb32b4de91bce13fa', 1660 ... (truncated) [Created on: Thu Aug 11 10:48:24 KST 2022, duration: 0, connection-id: 248, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61)] Thu Aug 11 10:48:24 KST 2022 INFO: [QUERY] insert into mocha_bot_message (C_APP_CHANNEL_ID, C_CREATED_AT, C_CUSTOMER_ID, C_MESSAGE, C_TALK_ID, C_UTTERANCE, C_BOT_MESSAGE_ID, C_TENANT_ID) values ('e3158759b0449439fe59b2edb32b4de91bce13fa', 1660 ... (truncated) [Created on: Thu Aug 11 10:48:24 KST 2022, duration: 0, connection-id: 245, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61)] . 결과적으로 pool max 발생 . ",
    "url": "http://localhost:4000/docs/msa/jpa/jpa_saveAll/#problem",
    "relUrl": "/docs/msa/jpa/jpa_saveAll/#problem"
  },"209": {
    "doc": "Jpa saveAll Stress Test Result",
    "title": "try1..",
    "content": "saveAll로 multi-row에 대한 insert를 호출하려면 설정이 필요하다. | 배치를 사용할 경우 설정이 추가로 필요하다.. | . spring.jpa.properties.hibernate.jdbc.batch_size=100 spring.jpa.properties.hibernate.order_inserts=true (if inserts) OR spring.jpa.properties.hibernate.order_updates=true (if updates) . | jdbc 연결할 때도 url에 쿼리를 줘야 한다. | . :: postgresql . jdbc:postgresql://localhost:5432/db?reWriteBatchedInserts=true . :: mysql . jdbc:mysql://localhost:3366/db?rewriteBatchedStatements=true . | 배치 쿼리 로그를 보려면, hibernate.show_sql: true로 안된다. | . jdbc:mysql://localhost:3366/db?rewriteBatchedStatements=true&amp;profileSQL=true&amp;c=Slf4JLogger&amp;maxQuerySizeToLog=200 . 적용 결과, ProxyStatement.executeBatch(ProxyStatement.java:128)에 의해 400개의 row가 한번 실행되었음을 알 수 있다. Thu Aug 11 14:28:25 KST 2022 INFO: [FETCH] [Created on: Thu Aug 11 14:28:25 KST 2022, duration: 0, connection-id: 781, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeQuery(ProxyPreparedStatement.java:52)] Thu Aug 11 14:28:25 KST 2022 INFO: [QUERY] select botmessage0_.C_BOT_MESSAGE_ID as c_bot_me1_9_0_, botmessage0_.C_TENANT_ID as c_tenant2_9_0_, botmessage0_.C_APP_CHANNEL_ID as c_app_ch3_9_0_, botmessage0_.C_CREATED_AT as c_create4_9_0_, botmes ... (truncated) [Created on: Thu Aug 11 14:28:25 KST 2022, duration: 0, connection-id: 781, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeQuery(ProxyPreparedStatement.java:52)] Thu Aug 11 14:28:25 KST 2022 INFO: [FETCH] [Created on: Thu Aug 11 14:28:25 KST 2022, duration: 0, connection-id: 781, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeQuery(ProxyPreparedStatement.java:52)] Thu Aug 11 14:28:25 KST 2022 INFO: [QUERY] insert into mocha_bot_message (C_APP_CHANNEL_ID, C_CREATED_AT, C_CUSTOMER_ID, C_MESSAGE, C_TALK_ID, C_UTTERANCE, C_BOT_MESSAGE_ID, C_TENANT_ID) values ('e3158759b0449439fe59b2edb32b4de91bce13fa', 1660 ... (truncated) [Created on: Thu Aug 11 14:28:25 KST 2022, duration: 182, connection-id: 781, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)] Thu Aug 11 14:28:25 KST 2022 INFO: [FETCH] [Created on: Thu Aug 11 14:28:25 KST 2022, duration: 0, connection-id: 781, statement-id: 0, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)] Thu Aug 11 14:28:25 KST 2022 INFO: [QUERY] commit [Created on: Thu Aug 11 14:28:25 KST 2022, duration: 0, connection-id: 781, statement-id: -1, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyConnection.commit(ProxyConnection.java:387)] Thu Aug 11 14:28:25 KST 2022 INFO: [FETCH] [Created on: Thu Aug 11 14:28:25 KST 2022, duration: 0, connection-id: 781, statement-id: -1, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyConnection.commit(ProxyConnection.java:387)] Thu Aug 11 14:28:25 KST 2022 INFO: [QUERY] SET autocommit=1 [Created on: Thu Aug 11 14:28:25 KST 2022, duration: 0, connection-id: 781, statement-id: -1, resultset-id: 0, at com.zaxxer.hikari.pool.ProxyConnection.setAutoCommit(ProxyConnection.java:414)] . try1 - problem . batch_size를 100으로 하고 다시 성능테스트 진행한 결과 . . | 결과 . | elapsed = 206,338 ms | sqlCount=405, sqlTime=206,022 ms | . | 트랜잭션 수는 줄어들었지만 오히려 수행시간이 증가 | db io wait 증가 | . try1 - result . | 초당 20에 대한 부하테스트를 장비 스펙부터 변경하고 다시 테스트해보는 것으로 하고 푸시는 보류 | . try2.. | DB서버 장비만 다르게 해서 동일 부하 시나리오 테스트 | DB서버 스펙 . | 기존) 4core 8thread | 변경) 12core 12thread / 32GB | . | . try2 - result . | max 200초가 넘던 것이 평균 17초로 개선된 결과를 받을 수 있었다. | db cpu 12core . | elapsed = 17,696 ms | sqlCount=405, sqlTime=17,420 ms | . | . ",
    "url": "http://localhost:4000/docs/msa/jpa/jpa_saveAll/#try1",
    "relUrl": "/docs/msa/jpa/jpa_saveAll/#try1"
  },"210": {
    "doc": "Jpa saveAll Stress Test Result",
    "title": "reference",
    "content": "| [Spring JPA Batch Insert 과연 생각대로 동작할까? | Carrey`s 기술블로그](https://jaehun2841.github.io/2020/11/22/2020-11-22-spring-data-jpa-batch-insert/#hibernate-order-inserts-hibernate-order-updates) | . JdbcTemplate의 Batch Insert 구현시, rewriteBatchedStatements 옵션을 true로 설정하여 성능 문제 해결 . | [Batch Insert 성능 향상기 1편 - With JPA - Yun Blog | 기술 블로그](https://cheese10yun.github.io/jpa-batch-insert/) | . ",
    "url": "http://localhost:4000/docs/msa/jpa/jpa_saveAll/#reference",
    "relUrl": "/docs/msa/jpa/jpa_saveAll/#reference"
  },"211": {
    "doc": "Jpa saveAll Stress Test Result",
    "title": "Jpa saveAll Stress Test Result",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/jpa/jpa_saveAll/",
    "relUrl": "/docs/msa/jpa/jpa_saveAll/"
  },"212": {
    "doc": "애플 Symantec Root 인증서 제거로 인한 인증서 갱신",
    "title": "애플 Symantec Root 인증서 제거로 인한 인증서 갱신",
    "content": "에러 : PKIX path building failed . 원인 . | 애플에서 symantec root인증서 제거해서, 인증불가 발생 | JRE 1.8.0_101 미만인 경우 발생 | . 조치 . | JRE 1.8.0_101 이상으로 버전업 | 인증서 추가 | . Java - PKIX path building failed . ",
    "url": "http://localhost:4000/docs/errors/jre1/",
    "relUrl": "/docs/errors/jre1/"
  },"213": {
    "doc": "Kafka",
    "title": "Kafka",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/kafka/kafka/",
    "relUrl": "/docs/msa/kafka/kafka/"
  },"214": {
    "doc": "Timeout of 60000ms expired before the position...",
    "title": "Timeout of 60000ms expired before the position...",
    "content": "kafdrop 보려는데 Timeout of 60000ms expired before the position for partition retry-assignment-2 could be determined 에러날 때 . problem . kafdrop에 접속해서 스트림보려는데, 에러날때 . error log . Internal Server Error . A 500 error has occurred: Request processing failed; nested exception is Timeout of 60000ms expired before the position for partition retry-assignment-2 could be deter . cause . host에 주소가 잘못박혀있거나.. 디폴트(60000ms) 로딩시간을 초과했다거나 할때 발생 . solution . 타임아웃 늘리려면, ProducerConfig.MAX_BLOCK_MS_CONFIG 설정을 주면 된다. 아니면 도커에 컨테이너 삭제하고 다시 deploy . reference . | stackoverflow.com/a/60068634/14257397 . | org.apache.kafka.common.errors.TimeoutException . | . ",
    "url": "http://localhost:4000/docs/errors/kafka1/",
    "relUrl": "/docs/errors/kafka1/"
  },"215": {
    "doc": "org.springframework.kafka.KafkaException",
    "title": "org.springframework.kafka.KafkaException",
    "content": "org.springframework.kafka.KafkaException: Ambiguous methods for payload type . error log . org.springframework.kafka.KafkaException: Ambiguous methods for payload type:** class AAA: handle and handle at org.springframework.kafka.listener.adapter.DelegatingInvocableHandler.findHandlerForPayload(DelegatingInvocableHandler.java:233) at org.springframework.kafka.listener.adapter.DelegatingInvocableHandler.getHandlerForPayload(DelegatingInvocableHandler.java:168) at org.springframework.kafka.listener.adapter.DelegatingInvocableHandler.getMethodNameFor(DelegatingInvocableHandler.java:279) at org.springframework.kafka.listener.adapter.HandlerAdapter.getMethodAsString(HandlerAdapter.java:67) at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:302) at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:79) at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50) at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter$$FastClassBySpringCGLIB$$cde8c01d.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:749) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.cloud.sleuth.instrument.messaging.MessageListenerMethodInterceptor.invoke(TraceMessagingAutoConfiguration.java:324) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter$$EnhancerBySpringCGLIB$$4dfa1e78.onMessage(&lt;generated&gt;) at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:1275) at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:1258) at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1219) at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1200) at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1120) at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:935) at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:751) at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:700) at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) at java.base/java.lang.Thread.run(Thread.java:835) Process finished with exit code -1 . cause . 내가 handle메소드 인자를 Object타입으로 받은거랑 MessageCreated로 받은걸 두개 생성해서… 어디에 매핑할지 모호하다는 에러임. Object인자로 받는 메소드를 지우자 . ",
    "url": "http://localhost:4000/docs/errors/kafka3/",
    "relUrl": "/docs/errors/kafka3/"
  },"216": {
    "doc": "kafka consumer lag solved",
    "title": "scenario",
    "content": "초당 10명이 동시 접수하면서 챗봇 이력을 200개를 대상으로 하는 테스트(발화주체별 200개로 총 400개의 리스트) . ",
    "url": "http://localhost:4000/docs/msa/kafka/kafka_consumer_lag/#scenario",
    "relUrl": "/docs/msa/kafka/kafka_consumer_lag/#scenario"
  },"217": {
    "doc": "kafka consumer lag solved",
    "title": "result",
    "content": ". | kafka lag 발생 | transaction rollback error 발생 | . ",
    "url": "http://localhost:4000/docs/msa/kafka/kafka_consumer_lag/#result",
    "relUrl": "/docs/msa/kafka/kafka_consumer_lag/#result"
  },"218": {
    "doc": "kafka consumer lag solved",
    "title": "[kafka lag]",
    "content": "grafana . | burrow로 수집한 kafka lag 발생구간이다. | lag이 발생한 부분은 챗봇 이력을 상담 어플리케이션으로 feign client를 통해 API를 호출하는 consumer 클래스다. | . scouter . | flow . | A 어플리케이션에서 . | kafka subscriber에서 챗봇메시지를 가공해서 | feign client 를 통해 | B 어플리케이션의 /bulk API를 호출 | . | B 어플리케이션에서 . | requestmapping으로 받은 데이터를 store에 저장하고 | 다른 도메인의 정보갱신 호출 | . | . | 문제 1 . | lag이 발생한 A어플리케이션에서 지연이 된 것이 아니라, B어플리케이션에서 초당 수백건의 데이터를 for문을 돌면서 DB에 하나씩 save시키고 있던 부분에서 지연 발생 | . | . | 문제 2 . | B 어플리케이션의 지연이 결국 feign을 통해서 동기호출한 부분까지 전파되어 subscribe까지 영향이 가서 lag이 발생 . | . | 문제 3 . | B 어플리케이션에서 save 한 후, 다른 도메인에 변경처리하는 부분에 runtimeException이 발생했는데 이 이 구간이 @Transaction으로 묶여있어서 앞서 save한 많은 건들이 rollback되고 있는 현상까지 발생 | 결국 rollback이 되면서 응답에 latency가 발생했고 그로인해 consumer영역까지 전파된 것으로 판단 . | . | . ",
    "url": "http://localhost:4000/docs/msa/kafka/kafka_consumer_lag/#kafka-lag",
    "relUrl": "/docs/msa/kafka/kafka_consumer_lag/#kafka-lag"
  },"219": {
    "doc": "kafka consumer lag solved",
    "title": "solved",
    "content": "1. lag처리 . | B어플리케이션을 호출하는 feign client를 비동기로 호출해서 해결했다. | Feign client Async call에 따로 정리했다. | . 2. 다건에 대한 jpa store save로직 변경 . | 한번에 400개의 봇메시지를 초당 20번씩 for문을 돌려서 find 한번 save한번을 호출하는 구조로 bulk용 API에 맞지 않다고 판단했다. | save를 saveAll로 변경해서 배열자체를 한번에 저장시키는 것으로 변경했다. 이러면 트랜잭션도 하나로 묶이게 된다 | cache추가 : kafka lag과 상관없지만, 화면에서 자주 호출되는 find API를 위해 caching이 되도록 처리했다. | . 3. transaction 제거 . | 프록시 되는 서비스에 트랜잭션이 걸려있어서, 다른 도메인에 변경 실패시 봇메시지 save한 데이터도 롤백되는 버그가 있었는데, 이 부분은 비지니스적으로도 트랜잭션으로 묶이 부분이 아니라서 제거했다. | . ",
    "url": "http://localhost:4000/docs/msa/kafka/kafka_consumer_lag/#solved",
    "relUrl": "/docs/msa/kafka/kafka_consumer_lag/#solved"
  },"220": {
    "doc": "kafka consumer lag solved",
    "title": "kafka consumer lag solved",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/kafka/kafka_consumer_lag/",
    "relUrl": "/docs/msa/kafka/kafka_consumer_lag/"
  },"221": {
    "doc": "kafka fail retry & backoff",
    "title": "cause",
    "content": "consumer 클래스에서 예외상황이 발생할 경우, kafka는 재시도를 한다. batchkafka는 SeekToCurrentBatchErrorHandler를 통해서 무한반복 . kafka는 SeekToCurrentErrorHandler를 통해서 retry를 20번 반복 . 밑에 에러는 key exception이 발생해서 반복적으로 에러가 발생했던 상황 . ",
    "url": "http://localhost:4000/docs/msa/kafka/kafka_fail_retry/#cause",
    "relUrl": "/docs/msa/kafka/kafka_fail_retry/#cause"
  },"222": {
    "doc": "kafka fail retry & backoff",
    "title": "error",
    "content": "08:16:36.560 er#8-0-C-1 ERROR o.s.c.l.LogAccessor     :149 error           Error handler threw an exception org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void spectra.attic.talk.crema.thirdparty.kakao.message.receive.subscriber.KakaoMessageEventSubscriber.handle(java.util.List&lt;spectra.attic.talk.crema.thirdparty.kakao.message.domain.receive.KakaoMessage&gt;)' threw exception; nested exception is spectra.attic.talk.crema.conversation.setting.domain.exception.NotAllowedKeyException: Not Allowed Key Exception : e3158759b0449439fe59b2edb32b4de91bce13fa; nested exception is spectra.attic.talk.crema.conversation.setting.domain.exception.NotAllowedKeyException: Not Allowed Key Exception : e3158759b0449439fe59b2edb32b4de91bce13fa . ",
    "url": "http://localhost:4000/docs/msa/kafka/kafka_fail_retry/#error",
    "relUrl": "/docs/msa/kafka/kafka_fail_retry/#error"
  },"223": {
    "doc": "kafka fail retry & backoff",
    "title": "solve1",
    "content": "@Bean public ConcurrentKafkaListenerContainerFactory&lt;String, JsonSerializable&gt; kafkaCremaListenerContainerFactory() { */* final SeekToCurrentErrorHandler errorHandler = new SeekToCurrentErrorHandler();* *errorHandler.set(new FixedBackOff(2000, 0L));* - */* *// SeekToCurrentErrorHandler eh = new SeekToCurrentErrorHandler((rec, ex) -&gt; System.out.println(\"I am the dlq\"), new FixedBackOff(0L, 0));* ConcurrentKafkaListenerContainerFactory&lt;String, JsonSerializable&gt; factory = new ConcurrentKafkaListenerContainerFactory&lt;&gt;(); factory.setConsumerFactory(cconsumerFactory()); factory.setConcurrency(concurrency); *// factory.setErrorHandler(eh);* *//factory.setErrorHandler(new SeekToCurrentErrorHandler(new FixedBackOff(0L, 0)));* factory.setErrorHandler(new SeekToCurrentErrorHandler(0)); return factory; } @Bean public ConcurrentKafkaListenerContainerFactory&lt;String, JsonSerializable&gt; batchCremaKafkaListenerContainerFactory() { *// final SeekToCurrentBatchErrorHandler errorHandler = new SeekToCurrentBatchErrorHandler();* *//errorHandler.setBackOff(new FixedBackOff(0L, 0));* ConcurrentKafkaListenerContainerFactory&lt;String, JsonSerializable&gt; factory = new ConcurrentKafkaListenerContainerFactory&lt;&gt;(); factory.setConsumerFactory(cconsumerFactory()); factory.setConcurrency(concurrency); factory.setBatchListener(true); *//SeekToCurrentErrorHandler eh = new SeekToCurrentErrorHandler((rec, ex) -&gt; System.out.println(\"I am the dlq\"), new ExponentialBackOff());* *// factory.setBatchErrorHandler(errorHandler);* return factory; } . ",
    "url": "http://localhost:4000/docs/msa/kafka/kafka_fail_retry/#solve1",
    "relUrl": "/docs/msa/kafka/kafka_fail_retry/#solve1"
  },"224": {
    "doc": "kafka fail retry & backoff",
    "title": "solve2",
    "content": "에러발생이 서버장애로 인한 것이라면 재시도가 맞겠지만, . 데이터 문제로 뱉는 에러라서 재시도가 필요없을 경우는 . backoff기능 외에 subscribe하는 consumer클래스에서 try~catch로 잡는 방법이 있다. ",
    "url": "http://localhost:4000/docs/msa/kafka/kafka_fail_retry/#solve2",
    "relUrl": "/docs/msa/kafka/kafka_fail_retry/#solve2"
  },"225": {
    "doc": "kafka fail retry & backoff",
    "title": "reference",
    "content": "SeekToCurrentErrorHandler + ExponentialBackOff will log errors after backOff has passed, is that intentional? . ",
    "url": "http://localhost:4000/docs/msa/kafka/kafka_fail_retry/#reference",
    "relUrl": "/docs/msa/kafka/kafka_fail_retry/#reference"
  },"226": {
    "doc": "kafka fail retry & backoff",
    "title": "kafka fail retry & backoff",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/kafka/kafka_fail_retry/",
    "relUrl": "/docs/msa/kafka/kafka_fail_retry/"
  },"227": {
    "doc": "kafka inconsistentClusterIdException",
    "title": "problem",
    "content": "spring boot와 spring cloud를 버전업하면서 . elasticsearch와 kafka 버전도 업그레이드를 해야했다. kafka의 경우 2.6.0에서 3.1.1로 업그레이드를 했는데 . 기존에 docker에서 oss버전으로 쓰고 있던 것을 지원이 더이상 안되면서 bitnami로 바꿨다. 그러면서 아래 에러가 나면서 kakfka가 start 도중 shutdown 되었다. ",
    "url": "http://localhost:4000/docs/msa/kafka/kafka_inconsistentClusterIdException/#problem",
    "relUrl": "/docs/msa/kafka/kafka_inconsistentClusterIdException/#problem"
  },"228": {
    "doc": "kafka inconsistentClusterIdException",
    "title": "error log",
    "content": "[2022-09-23 01:42:10,144] ERROR Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer) kafka_1 | kafka.common.InconsistentClusterIdException: The Cluster ID Jpiu7Hx5RduFq5qGMf8zbQ doesn't match stored clusterId Some(Rkq4qbbhTIqEXFm19x6SiQ) in meta.properties. The broker is trying to join the wrong cluster. Configured zookeeper.connect may be wrong. kafka_1 | at kafka.server.KafkaServer.startup(KafkaServer.scala:228) kafka_1 | at kafka.Kafka$.main(Kafka.scala:109) kafka_1 | at kafka.Kafka.main(Kafka.scala) kafka_1 | INFO shutting down (kafka.server.KafkaServer) . ",
    "url": "http://localhost:4000/docs/msa/kafka/kafka_inconsistentClusterIdException/#error-log",
    "relUrl": "/docs/msa/kafka/kafka_inconsistentClusterIdException/#error-log"
  },"229": {
    "doc": "kafka inconsistentClusterIdException",
    "title": "solve",
    "content": "방법은 의외로 간단했지만, . 구글링하면 window 환경의 docker기준이 아니라서 . meta.properties를 수정하라는 식의 해결방법 뿐이였다. kafka가 올라가자마자 죽으니 서버에 접근도 불가능했기 때문에 방법이 없었는데.. Volumes 화면에서 삭제하니 해결되었다! . | Stop and Remove Kafka Containter | Remove Kafka Image | go to [Volumes] and deleta all of kafka data and log directories | . ",
    "url": "http://localhost:4000/docs/msa/kafka/kafka_inconsistentClusterIdException/#solve",
    "relUrl": "/docs/msa/kafka/kafka_inconsistentClusterIdException/#solve"
  },"230": {
    "doc": "kafka inconsistentClusterIdException",
    "title": "kafka inconsistentClusterIdException",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/kafka/kafka_inconsistentClusterIdException/",
    "relUrl": "/docs/msa/kafka/kafka_inconsistentClusterIdException/"
  },"231": {
    "doc": "kafka monitoring",
    "title": "kafka monitoring",
    "content": "구성 . kafka + burrow + telegraf + es . kafka와 es . | kafka와 es는 이미 설치되어있는 환경 | . burrow 설치 및 실행 . | burrow 설치 . | go언어 설치 | burrow설치 . | git받은담에, go언어로 설치 | . | burrow.toml 설정 . | 포트가 중복되어서 8200으로 변경 | kafka랑 zookeeper정보 변경 | . | . [general] pidfile=\"burrow.pid\" stdout-logfile=\"burrow.out\" access-control-allow-origin=\"mysite.example.com\" [logging] filename=\"logs/burrow.log\" level=\"info\" maxsize=100 maxbackups=30 maxage=10 use-localtime=false use-compression=true [zookeeper] servers=[ \"localhost:2181\" ] timeout=6 root-path=\"/burrow\" [client-profile.local] client-id=\"burrow-local\" kafka-version=\"2.13.0\" [cluster.local] class-name=\"kafka\" servers=[ \"localhost:9092\" ] client-profile=\"local\" topic-refresh=120 offset-refresh=30 groups-reaper-refresh=0 [consumer.local] class-name=\"kafka\" cluster=\"local\" servers=[ \"localhost:9092\" ] client-profile=\"local\" group-denylist=\"^(console-consumer-|python-kafka-consumer-|quick-).*$\" group-allowlist=\"\" [httpserver.default] address=\":8200\" [storage.default] class-name=\"inmemory\" workers=20 intervals=15 expire-group=604800 min-distance=1 . | burrow 서비스 시작 . nohup /root/go/bin/Burrow --config-dir=/usr/local/Burrow/config 1&gt; /dev/null 2&gt;&amp;1 &amp; . | 참고 . | . [Kafka] install Burrow to linux (centos) . | . [Kafka] 카프카 Burrow 설치 (카프카 모니터링) . | . | . telegraf 설치 및 실행 . | burrow로 수집한 내용을 es로 전달하기 위한 용도 | 설치 . sudo yum install telegraf . | 설정 . | /etc/telegraf/telegraf.conf 파일 | input으로는 burrow로 하니까, burrow설정 | . [[inputs.burrow]] ## Burrow API endpoints in format \"schema://host:port\". ## Default is \"http://localhost:8000\". servers = [\"http://localhost:8200\"] topics_exclude = [ \"__consumer_offsets\" ] groups_exclude = [\"console-*\"] . | output은 es에 넣을꺼니까 | . [[outputs.elasticsearch]] urls = [ \"http://localhost:9200\" ] # required. timeout = \"5s\" enable_sniffer = false health_check_interval = \"10s\" index_name = \"burrow-%Y.%m.%d\" # required. manage_template = true template_name = \"telegraf\" overwrite_template = false . | influxdb는 사용안하므로 주석처리 | . | 서비스 시작 . systemctl enable --now telegraf systemctl status telegraf . | 에러 . | [agent] Failed to connect to [outputs.elasticsear…fined’ 라고 나서 , influxdb 주석하고 나니 사라짐 | [agent] Failed to connect to [outputs.elasticsearch], retrying in 15s, error was ‘elasticsearch template_name configuration not defined’ . | 이건 outputs.elasticsearch설정의 template_name이 주석되어있어서 주석해체하니 에러 해결 | . | . | 참조 . | . Install Telegraf . | . 튜토리얼-Ubuntu Linux에서 Telegraf 설치 [단계별] . | . kibana . | es로 데이터가 전송되었으면, kibana에서 index를 burrow-*로 생성한다. | . grafana . | database를 elasticsearch 추가하고 index를 burrow꺼로 가져오도록 한다. | . reference . 아파치 카프카 Lag 모니터링 대시보드 만들기 . ",
    "url": "http://localhost:4000/docs/etc/kafka_monitoring/",
    "relUrl": "/docs/etc/kafka_monitoring/"
  },"232": {
    "doc": "kafka SerializationException",
    "title": "org.apache.kafka.common.errors.SerializationException: Error deserializing key/value for partition",
    "content": "error log . Error deserializing key/value for partition event.message-0 at offset 62. If needed, please seek past the record to continue consumption. Caused by: org.springframework.messaging.converter.MessageConversionException: failed to resolve class name. Class not found [AAA]; nested exception is java.lang.ClassNotFoundException: AAA at org.springframework.kafka.support.converter.DefaultJackson2JavaTypeMapper.getClassIdType(DefaultJackson2JavaTypeMapper.java:138) at org.springframework.kafka.support.converter.DefaultJackson2JavaTypeMapper.toJavaType(DefaultJackson2JavaTypeMapper.java:99) at org.springframework.kafka.support.serializer.JsonDeserializer.deserialize(JsonDeserializer.java:342) at org.apache.kafka.clients.consumer.internals.Fetcher.parseRecord(Fetcher.java:1041) at org.apache.kafka.clients.consumer.internals.Fetcher.access$3300(Fetcher.java:110) at org.apache.kafka.clients.consumer.internals.Fetcher$PartitionRecords.fetchRecords(Fetcher.java:1223) at org.apache.kafka.clients.consumer.internals.Fetcher$PartitionRecords.access$1400(Fetcher.java:1072) at org.apache.kafka.clients.consumer.internals.Fetcher.fetchRecords(Fetcher.java:562) at org.apache.kafka.clients.consumer.internals.Fetcher.fetchedRecords(Fetcher.java:523) at org.apache.kafka.clients.consumer.KafkaConsumer.pollForFetches(KafkaConsumer.java:1230) at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1187) at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1115) at brave.kafka.clients.TracingConsumer.poll(TracingConsumer.java:78) at brave.kafka.clients.TracingConsumer.poll(TracingConsumer.java:72) at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:743) at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:700) at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) at java.base/java.lang.Thread.run(Thread.java:835) . cause . kafka consumer가 producer쪽이랑 header가 달라서, 즉 패키지 path가 달라서 그런거임. solved1 . kafkalistener에 property를 추가하거나 . @KafkaListener( topics = KafkaTenant.PREFIX + BusinessTopics.EVENT_MESSAGE, groupId = BusinessTopics.EVENT_MESSAGE + \"-crema-business-message-subscriber\", properties = { \"spring.json.value.default.type:spectra.attic.talk.crema.business.message.send.messaging.event.MessageCreated\", \"spring.json.use.type.headers:false\" } ) . solved2 . consumer config에 . props.put(JsonDeserializer.USE_TYPE_INFO_HEADERS, false); . 를 추가한다. solved3 . yml에 class를 맵핑시킨다. 단점은 사용하지 않는 이벤트의 헤더까지 맵핑되어야한다. spring: kafka: consumer: properties: spring.json.type.mapping: spectra.attic.talk.mocha.btalk.btalk.messaging.event.BtalkCreated:spectra.attic.talk.crema.business.btalk.message.send.messaging.event.TicketCreated, spectra.attic.talk.mocha.btalk.btalk.messaging.event.BtalkUpdated:spectra.attic.talk.crema.business.btalk.message.send.messaging.event.TicketUpdated . 단, 해당 이벤트의 모든 헤더를 정의하지 않으면 아까와 동일한 SerializationException, MessageConversionException 에러 발생 . solved4 . 또 다른 방법은 이벤트를 수신하는 클래스의 @KafkaListener에 spring.json.type.mapping을 설정하는 것 . @KafkaListener( topics = { \"TestTopic\" }, groupId = \"test-event-subscriber\", properties = { \"spring.json.type.mapping:\" + \"spectra.attic.talk.mocha.btalk.btalk.messaging.event.BtalkCreated:spectra.attic.talk.crema.business.btalk.message.send.messaging.event.TicketCreated,\" + \"spectra.attic.talk.mocha.btalk.btalk.messaging.event.BtalkUpdated:spectra.attic.talk.crema.business.btalk.message.send.messaging.event.TicketUpdated\" } ) . reference . | org.apache.kafka.common.errors.SerializationException: Error deserializing key/value for partition t | Spring boot Kafka class deserialization - not in the trusted package | . ",
    "url": "http://localhost:4000/docs/msa/kafka/kafka_serializationException/#orgapachekafkacommonerrorsserializationexception-error-deserializing-keyvalue-for-partition",
    "relUrl": "/docs/msa/kafka/kafka_serializationException/#orgapachekafkacommonerrorsserializationexception-error-deserializing-keyvalue-for-partition"
  },"233": {
    "doc": "kafka SerializationException",
    "title": "kafka SerializationException",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/kafka/kafka_serializationException/",
    "relUrl": "/docs/msa/kafka/kafka_serializationException/"
  },"234": {
    "doc": "Keycloak",
    "title": "Keycloak 적용 검토",
    "content": "검토 기간 : 2020.03 ~ 2020.05 . 검토 내용 . | keycloak 사용 및 분석 | keycloak 적용시 장단점 | 기타 제약사항 | 결과적으로 자체 개발할 것인지 keycloak을 적용할 것인지 | . 검토 결과 . | 검토 결과 보고서 참고 | . Keycloak_poc결과보고서.zip . ",
    "url": "http://localhost:4000/docs/sub-projects/keyclock/#keycloak-%EC%A0%81%EC%9A%A9-%EA%B2%80%ED%86%A0",
    "relUrl": "/docs/sub-projects/keyclock/#keycloak-적용-검토"
  },"235": {
    "doc": "Keycloak",
    "title": "Keycloak",
    "content": " ",
    "url": "http://localhost:4000/docs/sub-projects/keyclock/",
    "relUrl": "/docs/sub-projects/keyclock/"
  },"236": {
    "doc": "let's encrypt ssl",
    "title": "let’s encrypt with (window, springboot)",
    "content": "로컬(윈도우)에서 springboot 어플리케이션에 ssl을 추가해서 테스트해볼 일이 생겼다. 무료 ssl로 let’s encrypt를 활용하기로 하고 설치 및 적용해봄 . | let’s encrypt는 certbot을 이용해서 설치하면 된다. | 아래 페이지로 이동해서 certbot install파일을 내려받는다. (다운로드) | . Certbot Instructions . | 관리자 권한으로 cmd창을 열고 아래 명령어를 쳐서 잘 설치된건지 확인한다. | . C:\\WINDOWS\\system32&gt; certbot --help . | dns 등록 | . freenom 이용함 (무료 dns) . | dns까지 준비되었다면, ssl을 생성한다. (dns가 없다면, 중간에 실패난다.) | . C:\\WINDOWS\\system32&gt;certbot certonly --standalone Saving debug log to C:\\Certbot\\log\\letsencrypt.log Please enter the domain name(s) you would like on your certificate (comma and/or space separated) (Enter 'c' to cancel): ~~~~~.~~~~ (dns주소 입력) Requesting a certificate for ~~~~~.~~~~ Successfully received certificate. Certificate is saved at: C:\\Certbot\\live\\~~~~~.~~~~fullchain.pem Key is saved at: C:\\Certbot\\live\\~~~~~.~~~~\\privkey.pem This certificate expires on 2022-02-17. These files will be updated when the certificate renews. Certbot has set up a scheduled task to automatically renew this certificate in the background. 참조) 자세한 내용은 아래 블로그 참고 . SpringBoot - Let’s Encrypt로 무료 SSL인증서를 발급받아 SpringBoot에 적용하기(Https) . | 생성한 ssl을 윈도우 폴더에 위치시키고 yml파일을 수정한다. | . server: port: 19010 ssl: enabled: true key-store: ~~~.jks key-store-type: \"JKS\" 또는 \"PKCS12\" 지정 key-store-password: ~~~~~~~~ 인증서 암호 key-alias: 선택항목으로 alias또는 CN명 trust-store: 선택항목 trust-store-password: 선택항목 . | 그리고 @SpringBootApplication파일을 run시킨다. | 내부망에 있다보니, lte로 테스트했을때, 유효한 인증서로 보였는데, line developers의 webhook url로 등록하고 verify하니까 아래 에러가 발생했다. | . An SSL connection error occurred. Confirm that your webhook URL uses HTTPS and has an SSL/TLS certificate issued by a root certification authority that's widely trusted by most browsers . 뭔가 유효하지 않은 느낌이다. | 인증서 유효성 체크사이트(https://www.digicert.com/help/) 에서 체크해본다. —&gt; 유효하지 않다고 나옴. | 브라우저에서 ip로 호출해보니 “ERR_CERT_COMMON_NAME_INVALID”라고 나온다. —&gt; 발급대상과 일치하지 않다는 에러라고 한다. | 포트를 19010에서 443으로 변경하고 다시 digicert에서 검사돌려보니 “TLS Certificate is not trusted” 라고 나온다. —&gt; 인증서 체인을 잘못 건것으로 keytool -list -v -keystore keystore.jks실행시켜서 인증서 개수가 3개 인지 확인한다. | . ",
    "url": "http://localhost:4000/docs/sub-projects/lets_encrypt_ssl/#lets-encrypt-with-window-springboot",
    "relUrl": "/docs/sub-projects/lets_encrypt_ssl/#lets-encrypt-with-window-springboot"
  },"237": {
    "doc": "let's encrypt ssl",
    "title": "let's encrypt ssl",
    "content": " ",
    "url": "http://localhost:4000/docs/sub-projects/lets_encrypt_ssl/",
    "relUrl": "/docs/sub-projects/lets_encrypt_ssl/"
  },"238": {
    "doc": "Line messaging API 적용 노트",
    "title": "Line messaging API 적용 노트",
    "content": ". | webhook 설정 - ssl설정 . | controller작성 . | . 기존 프로젝트에 line 메시징 API만 적용해야하는 환경이라, 라인sdk에서 적용한 스프링버전보다 높은 상황 . 자바는 컴파일은 1.8, . 런타임은 12로 되는 상황 . 간단한 컨트롤러 작성 . @Slf4j @RestController @LineMessageHandler public class LineMessageController { @EventMapping public void handleTextMessageEvent(MessageEvent&lt;TextMessageContent&gt; event) { log.info(\"event: \" + event); final String originalMessageText = event.getMessage().getText(); //return new TextMessage(originalMessageText); } @EventMapping public void handleDefaultMessageEvent(Event event) { System.out.println(\"event: \" + event); } } . 에러1) . 14:34:33.586 010-exec-6 ERROR ineMessageHandlerSupport:217 dispatch Unsupported event type. MessageEvent(replyToken=3406d4539061400ca6d199bc2bad16e6, source=UserSource(userId=Uec5b4b45de71961100290f7a7ff61d0a), message=TextMessageContent(id=15206625437201, text=123, emojis=null, mention=null), timestamp=2021-12-07T05:34:32.441Z, mode=ACTIVE) java.lang.UnsupportedOperationException: Unsupported event type. MessageEvent(replyToken=3406d4539061400ca6d199bc2bad16e6, source=UserSource(userId=Uec5b4b45de71961100290f7a7ff61d0a), message=TextMessageContent(id=15206625437201, text=123, emojis=null, mention=null), timestamp=2021-12-07T05:34:32.441Z, mode=ACTIVE) at com.linecorp.bot.spring.boot.support.LineMessageHandlerSupport.lambda$dispatchInternal$6(LineMessageHandlerSupport.java:226) at java.util.Optional.orElseThrow(Optional.java:290) at com.linecorp.bot.spring.boot.support.LineMessageHandlerSupport.dispatchInternal(LineMessageHandlerSupport.java:226) at com.linecorp.bot.spring.boot.support.LineMessageHandlerSupport.dispatch(LineMessageHandlerSupport.java:213) at com.linecorp.bot.spring.boot.support.LineMessageHandlerSupport.lambda$callback$4(LineMessageHandlerSupport.java:206) at java.util.ArrayList.forEach(ArrayList.java:1259) at com.linecorp.bot.spring.boot.support.LineMessageHandlerSupport.callback(LineMessageHandlerSupport.java:205) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) at javax.servlet.http.HttpServlet.service(HttpServlet.java:665) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:750) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at brave.servlet.TracingFilter.doFilter(TracingFilter.java:68) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at brave.servlet.TracingFilter.doFilter(TracingFilter.java:87) at org.springframework.cloud.sleuth.instrument.web.LazyTracingFilter.doFilter(TraceWebServletAutoConfiguration.java:141) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:97) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:357) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:893) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1707) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) . 분석1) springboot로 띄울때, 디버깅해보면, LineMessageHandler를 선언한 클래스는 스프링에 등록되어 있지만, ‘@EventMapping을 선언한 메소드는 찾지 못하는 문제 발생 . 시도1) @SpringBootApplication(scanBasePackages = “~~~~”)가 기존 프로젝트에 추가된 상황이였는데, scan대상이 잘못되고 있는 것인가 해서, scanBasePackages를 제거하고 올리면 성공 . 하지만 scanBasePackages 설정은 다른 컨테이너와의 상속문제로 반드시 필요한 설정이라 뺄 수가 없음 . 시도2) 라인sdk의 echo를 다시 유심히 봤다. 차이는 @RestController뿐. @RestController를 제거해보니 성공 . 정리는 간단했지만, spring 버전차이를 중심으로 디버깅하다보니 삽질이 길었다. 문제는 @RestController 중복선언으로 보인다. LineMessageHandlerSupport.java내용을 보면 거기에도 @RestController를 자체적으로 선언하고 있다. @Slf4j @RestController @Import(ReplyByReturnValueConsumer.Factory.class) @ConditionalOnProperty(name = \"line.bot.handler.enabled\", havingValue = \"true\", matchIfMissing = true) public class LineMessageHandlerSupport { . 해당 파일의 주석으로도 되어있다. class에는 @LineMessageHandler를 method에는 @EventMappinig을 선언하라고… . ",
    "url": "http://localhost:4000/docs/sub-projects/line_messaging/",
    "relUrl": "/docs/sub-projects/line_messaging/"
  },"239": {
    "doc": "Liquibase",
    "title": "Liquibase",
    "content": "검토 배경 . | 사이트 마이그레이션을 용이하게 하려면? | 수동으로 쿼리를 작성하게 되면, 누락되는 항목도 생기고, 버그도 발생 | . liquibase 주요 기능 . | change log | tracking work | . 검토 결과 . Q1. data diff가 가능한가? . | json data가 저장된 컬럼 비교가 가능한가? | . A1. | 자동으로 비교할 수 없고, liquibase db table에 변경이력을 쌓아야만 이력추적을 통해 가능 | 그 외에 다른 database object들에 대한 diff는 이력으로 쌓지 않아도 모두 가능 | ./liquibase --outputFile=mydiff.txt --driver=com.mysql.jdbc.Driver --classpath=lib/mysql-connector-java-8.0.25.jar --url=\"jdbc:mysql://localhost:3306/db1?serverTimezone=Asia/Seoul&amp;characterEncoding=UTF-8\" --username=root --password=password --referenceUrl=\"jdbc:mysql://localhost:3306/db2?serverTimezone=Asia/Seoul&amp;characterEncoding=UTF-8\" --referenceUsername=root --referencePassword=password -diffTypes=data diff . [mydiff.txt] Reference Database: root@localhost @ jdbc:mysql://localhost:3306/db2?serverTimezone=Asia/Seoul&amp;characterEncoding=UTF-8 (Default Schema: db2) Comparison Database: root@localhost @ jdbc:mysql://localhost:3306/db1?serverTimezone=Asia/Seoul&amp;characterEncoding=UTF-8 (Default Schema: db1) Compared Schemas: db2 -&gt; db1 Product Name: EQUAL Product Version: EQUAL Missing Catalog(s): NONE Unexpected Catalog(s): NONE Changed Catalog(s): NONE Missing Column(s): db2.mocha_survey_questionnaire.C_ACTIVE db2.mocha_survey.C_MESSAGE Unexpected Column(s): db1.mocha_knowledge.C_ACCESS_TYPE db1.mocha_removed_team.C_ALIAS Changed Column(s): db2.mocha_survey_response.C_CREATED_AT order changed from '5' to '4' db2.mocha_survey.C_ENABLED nullable changed from 'false' to 'true' order changed from '6' to '8' Missing Foreign Key(s): NONE Unexpected Foreign Key(s): NONE Changed Foreign Key(s): NONE Missing Index(s): NONE Unexpected Index(s): NONE Changed Index(s): NONE Missing Primary Key(s): NONE Unexpected Primary Key(s): NONE Changed Primary Key(s): NONE Missing Sequence(s): NONE Unexpected Sequence(s): NONE Changed Sequence(s): NONE Missing Table(s): mocha_survey_questionnaire mocha_survey_restrict Unexpected Table(s): crema_active_kakao Changed Table(s): NONE Missing Unique Constraint(s): NONE Unexpected Unique Constraint(s): NONE Changed Unique Constraint(s): NONE Missing View(s): NONE Unexpected View(s): NONE Changed View(s): NONE . 활용 방법 . | 제품의 버전별 DB이력관리가 필요하다면, git log를 변경이력으로 등록하게 해서 활용하는 방법을 생각해볼 수 있다. | . ",
    "url": "http://localhost:4000/docs/sub-projects/liquibase/",
    "relUrl": "/docs/sub-projects/liquibase/"
  },"240": {
    "doc": "Mooc",
    "title": "note",
    "content": "I summarize contents what I’ve learned through Online. udemy, udacity, inflearn, youtube.. so on. ",
    "url": "http://localhost:4000/docs/mooc#note",
    "relUrl": "/docs/mooc#note"
  },"241": {
    "doc": "Mooc",
    "title": "Mooc",
    "content": " ",
    "url": "http://localhost:4000/docs/mooc",
    "relUrl": "/docs/mooc"
  },"242": {
    "doc": "Msa",
    "title": "Note",
    "content": "summarized the api/library used within Spring Cloud. ",
    "url": "http://localhost:4000/docs/msa#note",
    "relUrl": "/docs/msa#note"
  },"243": {
    "doc": "Msa",
    "title": "Msa",
    "content": " ",
    "url": "http://localhost:4000/docs/msa",
    "relUrl": "/docs/msa"
  },"244": {
    "doc": "Nginx",
    "title": "Nginx",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/nginx/nginx/",
    "relUrl": "/docs/msa/nginx/nginx/"
  },"245": {
    "doc": "directory index of \"..\\nginx-1.19.9/html/\" is forbidden",
    "title": "directory index of \"..\\nginx-1.19.9/html/\" is forbidden",
    "content": "directory index of “C:\\Users\\Desktop\\nginx-1.19.9/html/” is forbidden . problem . nginx를 통해서 url 파라미터로 보낸 url형태의 값을 전송하려고 하는데 . 만약에 초기 설치에서 index.html파일을 삭제할 경우 나타나는 에러 . 리눅스의 경우는 에러 메시지가 윈도우와 다름 . error log . *422\"/etc/nginx/html/index.html\" is not found (2: No such file or directory), client: x.x.x.x, server: xxx.xxx.kr, request: \"GET /?url=http%3A%2F%2Fxxx.xxx.com/test/12345.jpeg HTTP/1.1\", host: \"{nginxIp}:8050\" . [기존 nginx.conf] . server { listen 19013; server_name localhost; location ~* ^/(chat|image|file) { resolver 8.8.8.8; proxy_pass https://xxx.xxx.co.kr$uri; } location ~* ^.+\\.(jpg|jpeg|gif|png|ico|css|zip|tgz|gz|rar|bz2|pdf|txt|tar|wav|bmp|rtf|js|flv|swf|html|htm)$ { rewrite ^ $arg_url permanent; } location /ping { access_log on; add_header 'Content-Type' 'application/json'; return 200 '{\"status\":\"UP\"}'; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } . cause . | rewrite ^ $arg_url permanent; 에서 301로 리턴하면서 response를 루트 디렉토리를 통해 index.html 로 리다이렉트되는 것 같다. | . solution . | window나 linux 로그에 표시되는 경로에 임의의 index.html을 생성하는 방법 . | 서비스 운영 중에 서버가 이전하거나 파일이 생성될 경우, 다시 에러가 발생할 가능성이 크다. | . | root디렉토리를 서비스 디렉토리 하위로 변경하는 방법 . | 서비스 디렉토리로 옮기면, 그나마 임의로 삭제될 가능성은 적다 | nginx의 기본 root directorysms nginx.exe가 존재하는 path기준으로 설정된다. | 참고) | . Windows: Nginx configuration error GetFileAttributesEx . location / { root D:/tmp/html; index index.html index.htm; if ($request_filename ~* [jpg|jpeg|gif|png|pdf|txt|bmp]$) { rewrite ^ $arg_url permanent; break; } } . | 다시 리다이렉트되는 index.html도 301로 리턴되도록 설정한다. | 참고) | . nginx redirect loop, remove index.php from url . server { listen 8051; server_name localhost; **index index.html;** **if ($request_uri ~* \"^(.*/)index\\.html$\") { return 301 $1; }** **location / { rewrite ^ $arg_url permanent; }** location ~* ^/(chat|image|file) { resolver 8.8.8.8; proxy_pass https://xxx.xxx.co.kr$uri; } # Health Check location /ping { access_log on; add_header 'Content-Type' 'application/json'; return 200 '{\"status\":\"UP\"}'; } } . | . ",
    "url": "http://localhost:4000/docs/msa/nginx/nginx1/",
    "relUrl": "/docs/msa/nginx/nginx1/"
  },"246": {
    "doc": "CircularRedirectException",
    "title": "CircularRedirectException",
    "content": "error log . 17:18:17.139 r-CREMA-11 DEBUG .j.JpaTransactionManager:620 AfterCompletion Closing JPA EntityManager [SessionImpl(898129057&lt;open&gt;)] after transaction 17:18:17.173 -gateway-9 DEBUG f.s.Slf4jLogger : 72 log [ThirdPartyGatewayFileClient#download] ---&gt; GET http://aaa/attach/download HTTP/1.1 17:18:17.173 -gateway-9 DEBUG f.s.Slf4jLogger : 72 log [ThirdPartyGatewayFileClient#download] XAttachUrl: http://bbb 17:18:17.174 -gateway-9 DEBUG f.s.Slf4jLogger : 72 log [ThirdPartyGatewayFileClient#download] ---&gt; END HTTP (0-byte body) 17:18:17.185 -gateway-9 DEBUG f.s.Slf4jLogger : 72 log [ThirdPartyGatewayFileClient#download] &lt;--- ERROR ClientProtocolException: null (10ms) 17:18:17.186 -gateway-9 DEBUG f.s.Slf4jLogger : 72 log [ThirdPartyGatewayFileClient#download] org.apache.http.client.ClientProtocolException at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:187) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56) at feign.httpclient.ApacheHttpClient.execute(ApacheHttpClient.java:83) at org.springframework.cloud.sleuth.instrument.web.client.feign.TracingFeignClient.execute(TracingFeignClient.java:81) at org.springframework.cloud.sleuth.instrument.web.client.feign.LazyTracingFeignClient.execute(LazyTracingFeignClient.java:60) at org.springframework.cloud.openfeign.ribbon.RetryableFeignLoadBalancer.lambda$execute$0(RetryableFeignLoadBalancer.java:109) at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:287) at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:180) at org.springframework.cloud.openfeign.ribbon.RetryableFeignLoadBalancer.execute(RetryableFeignLoadBalancer.java:92) at org.springframework.cloud.openfeign.ribbon.RetryableFeignLoadBalancer.execute(RetryableFeignLoadBalancer.java:52) at com.netflix.client.AbstractLoadBalancerAwareClient$1.call(AbstractLoadBalancerAwareClient.java:104) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$3$1.call(LoadBalancerCommand.java:303) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$3$1.call(LoadBalancerCommand.java:287) at rx.internal.util.ScalarSynchronousObservable$3.call(ScalarSynchronousObservable.java:231) at rx.internal.util.ScalarSynchronousObservable$3.call(ScalarSynchronousObservable.java:228) at rx.Observable.unsafeSubscribe(Observable.java:10327) at rx.internal.operators.OnSubscribeConcatMap$ConcatMapSubscriber.drain(OnSubscribeConcatMap.java:286) at rx.internal.operators.OnSubscribeConcatMap$ConcatMapSubscriber.onNext(OnSubscribeConcatMap.java:144) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$1.call(LoadBalancerCommand.java:185) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$1.call(LoadBalancerCommand.java:180) at rx.Observable.unsafeSubscribe(Observable.java:10327) at rx.internal.operators.OnSubscribeConcatMap.call(OnSubscribeConcatMap.java:94) at rx.internal.operators.OnSubscribeConcatMap.call(OnSubscribeConcatMap.java:42) at rx.Observable.unsafeSubscribe(Observable.java:10327) at rx.internal.operators.OperatorRetryWithPredicate$SourceSubscriber$1.call(OperatorRetryWithPredicate.java:127) at rx.internal.schedulers.TrampolineScheduler$InnerCurrentThreadScheduler.enqueue(TrampolineScheduler.java:73) at rx.internal.schedulers.TrampolineScheduler$InnerCurrentThreadScheduler.schedule(TrampolineScheduler.java:52) at rx.internal.operators.OperatorRetryWithPredicate$SourceSubscriber.onNext(OperatorRetryWithPredicate.java:79) at rx.internal.operators.OperatorRetryWithPredicate$SourceSubscriber.onNext(OperatorRetryWithPredicate.java:45) at rx.internal.util.ScalarSynchronousObservable$WeakSingleProducer.request(ScalarSynchronousObservable.java:276) at rx.Subscriber.setProducer(Subscriber.java:209) at rx.internal.util.ScalarSynchronousObservable$JustOnSubscribe.call(ScalarSynchronousObservable.java:138) at rx.internal.util.ScalarSynchronousObservable$JustOnSubscribe.call(ScalarSynchronousObservable.java:129) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.Observable.subscribe(Observable.java:10423) at rx.Observable.subscribe(Observable.java:10390) at rx.observables.BlockingObservable.blockForSingle(BlockingObservable.java:443) at rx.observables.BlockingObservable.single(BlockingObservable.java:340) at com.netflix.client.AbstractLoadBalancerAwareClient.executeWithLoadBalancer(AbstractLoadBalancerAwareClient.java:112) at org.springframework.cloud.openfeign.ribbon.LoadBalancerFeignClient.execute(LoadBalancerFeignClient.java:84) at org.springframework.cloud.sleuth.instrument.web.client.feign.TraceLoadBalancerFeignClient.execute(TraceLoadBalancerFeignClient.java:78) at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:119) at feign.SynchronousMethodHandler.invoke(SynchronousMethodHandler.java:89) at feign.hystrix.HystrixInvocationHandler$1.run(HystrixInvocationHandler.java:109) at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:302) at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:298) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:46) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:35) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.Observable.unsafeSubscribe(Observable.java:10327) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:51) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:35) at rx.Observable.unsafeSubscribe(Observable.java:10327) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.Observable.unsafeSubscribe(Observable.java:10327) at rx.internal.operators.OperatorSubscribeOn$SubscribeOnSubscriber.call(OperatorSubscribeOn.java:100) at com.netflix.hystrix.strategy.concurrency.HystrixContexSchedulerAction$1.call(HystrixContexSchedulerAction.java:56) at com.netflix.hystrix.strategy.concurrency.HystrixContexSchedulerAction$1.call(HystrixContexSchedulerAction.java:47) at org.springframework.cloud.sleuth.instrument.async.TraceCallable.call(TraceCallable.java:71) at com.netflix.hystrix.strategy.concurrency.HystrixContexSchedulerAction.call(HystrixContexSchedulerAction.java:69) at rx.internal.schedulers.ScheduledAction.run(ScheduledAction.java:55) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266) at java.util.concurrent.FutureTask.run(FutureTask.java) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: org.apache.http.client.CircularRedirectException: Circular redirect to 'http://127.0.0.1:8051/attach/download' at org.apache.http.impl.client.DefaultRedirectStrategy.getLocationURI(DefaultRedirectStrategy.java:193) at org.apache.http.impl.client.DefaultRedirectStrategy.getRedirect(DefaultRedirectStrategy.java:223) at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:126) at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185) ... 81 more . cause . 원인은 허무하게도 nginx가 동일 포트로 여러개 떠있었다. rewrite 문법이 잘못된 것이 없다면, 프로세스 확인해보장~! . ",
    "url": "http://localhost:4000/docs/msa/nginx/nginx2/",
    "relUrl": "/docs/msa/nginx/nginx2/"
  },"247": {
    "doc": "client intended to send too large body",
    "title": "client intended to send too large body",
    "content": "problem . front에서 첨부파일을 끌어서 업로드할 때, nginx에서 에러 발생하면서 아무 반응 없던 현상 . error . client intended to send too large body: 16095313 bytes . solved . nginx.conf에 아래 설정 추가 . http { client_max_body_size 500M; } . 0 으로 설정하면 무제한 . 500M으로 한 이유는 제품기획상 대용량 첨부가 불가능해서.. 무제한으로 했다가 화면 뻗을 것 같아서 그러했음 . reference . Nginx error: client intended to send too large body . ",
    "url": "http://localhost:4000/docs/msa/nginx/nginx_client_error/",
    "relUrl": "/docs/msa/nginx/nginx_client_error/"
  },"248": {
    "doc": "nginx query string encoding problem",
    "title": "요구사항",
    "content": ". | ap서버에서 nginx를 통해서 외부 nas에 저장된 첨부파일을 가져와야하는 요건 | . http://172.16.120.206:8051/?url=http%3A%2F%2Ftest.com%2Ftalkm%2FoY7TLhEsug%2FjqKpQBa0HtbvGdRjirexV0%2Fi_504b25b09b19.jpg . | nginx 서버 : 172.16.120.206:8051 | 파라미터 url을 AP서버에서 feignclient로 nginx 통해 호출해서 첨부파일을 읽어봐야 함 | feign으로 호출하기 전에는 인코딩이 되어있지 않지만, feign라이브러리 내 httpclient를 구현하는 클래스에서 인코딩이 시킨후 호출되고 있었습니다. | . 이런 형태의 url일 경우, regex로 matching시키는게 간단하지 않습니다. dns가 변경될 가능성도 크고 . 보안 url이기 때문에 리소스 path가 유동적일 가능성도 큽니다. ",
    "url": "http://localhost:4000/docs/msa/nginx/nginx_encoding_problem/#%EC%9A%94%EA%B5%AC%EC%82%AC%ED%95%AD",
    "relUrl": "/docs/msa/nginx/nginx_encoding_problem/#요구사항"
  },"249": {
    "doc": "nginx query string encoding problem",
    "title": "try1..",
    "content": "nginx에서 $args_url을 받자마자 proxy_pass하는 방법으로 젤 먼저 해봤습니다 . try1-problem . url에 인코딩된 특수문자로 에러가 발생합니다. ",
    "url": "http://localhost:4000/docs/msa/nginx/nginx_encoding_problem/#try1",
    "relUrl": "/docs/msa/nginx/nginx_encoding_problem/#try1"
  },"250": {
    "doc": "nginx query string encoding problem",
    "title": "try2..",
    "content": "슬래시가 한번일 경우 한번만 matching시키고 나머지는 (.*)$로 잡으면되는데 . location ~* ^.+\\.(jpg|jpeg|gif|png|pdf|txt|bmp)$ { . 이렇게 작성하면 조건을 타지도 못한다. 이유는 query_string의 내용으로 location을 matching시킬수 없다고 한다. ",
    "url": "http://localhost:4000/docs/msa/nginx/nginx_encoding_problem/#try2",
    "relUrl": "/docs/msa/nginx/nginx_encoding_problem/#try2"
  },"251": {
    "doc": "nginx query string encoding problem",
    "title": "try3..",
    "content": "경로가 여러개 일 경우는 억지로 한다면 이렇게 하게 됩니다. if ($args ~ (test.com)%2F(.*)%2F(.*)%2F(.*)%2F(.*)$) { set $aaa $1; set $bbb $2/$3/$4/$5; rewrite . /$bbb break; proxy_pass http://$aaa; } . try3-problem . 앞서 설명했듯이 url자체가 유동적일 가능성이 크기 때문에 위의 방법은 사용하면 안 됩니다. ",
    "url": "http://localhost:4000/docs/msa/nginx/nginx_encoding_problem/#try3",
    "relUrl": "/docs/msa/nginx/nginx_encoding_problem/#try3"
  },"252": {
    "doc": "nginx query string encoding problem",
    "title": "try4..",
    "content": "그래서 찾던 중 njs모듈 설치를 하면 된다고 해서 적용해봤습니다. Redirect to the encode url present in query parameter in NGINX . | 모듈 설치 | . [root@victory-dev-106 conf.d]# sudo yum install nginx-module-njs . | nginx.conf에 load_module 추가 | . load_module modules/ngx_http_js_module.so; . | http.js 생성 | . function decoded_url(r) { return decodeURIComponent(r.args.url); } export default {decoded_url}; . | js로 파싱한 결과 set하는걸 http {} 블록 하위에 선언 | . http { js_import http.js; js_set $decoded_url http.decoded_url; include /etc/nginx/conf.d/*.conf; server { listen 8051; server_name localhost; charset utf-8; rewrite_log on; location = / { if ($decoded_url ~ http[s]?:\\/?\\/?([^\\/]+)(.*)$) { set $aaa $1; set $bbb $2; rewrite . $bbb break; proxy_pass http://$aaa; } proxy_redirect off; error_log /var/log/nginx/dn-m.img.error.log debug; } } } . 오프라인으로 njs 설치하고자 하면, nginx설치부터 njs포함시켜서 수동설치 . Download and install . https://jcartw.medium.com/how-to-install-nginx-from-source-with-njs-javascript-module-443e8e3a0cf2 . —&gt; 대신 add-module이 configure된 것이라 nginx.conf에 load_module안해도 됨 . try4-problem . njs를 설치하면 인코딩된 url을 디코드시켜주기 때문에 문제가 해결됩니다. 하지만 운영중인 사이트에 모듈을 설치하기엔 부담이 있었습니다. ",
    "url": "http://localhost:4000/docs/msa/nginx/nginx_encoding_problem/#try4",
    "relUrl": "/docs/msa/nginx/nginx_encoding_problem/#try4"
  },"253": {
    "doc": "nginx query string encoding problem",
    "title": "try5..(solved)",
    "content": "좀더 검색해보니 아래 블로그를 발견!! . https://lng1982.tistory.com/341 . —&gt; path나 body에 있는 string은 무조건 인코딩된다고 합니다. 그래서 저는 url을 header에 넣는 것으로 꼼수를 부려봤습니다. feign으로 nginx호출할 때, url을 XAttachUrl 헤더에 셋팅하고 호출 . [feign client class] . @FeignClient( contextId = \"spectra.attic.talk.crema.thirdparty.file.client.ThirdPartyGatewayFileClient\", name = \"${crema.thirdparty.thirdparty-gateway.name}\", configuration = {MultipartSupportConfig.class}, primary = false ) public interface ThirdPartyGatewayFileClient { @GetMapping(value = \"attach/download\") ResponseEntity&lt;byte[]&gt; download(@RequestHeader(\"XAttachUrl\") String url); } . | nginx쪽으로 http://172.16.120.206:8051/attach/download를 호출하면서 헤더에 url을 실어보냅니다. | . [nginx.conf] . location ~* /attach/download { resolver 8.8.8.8; if ($http_XAttachUrl ~ http[s]?:\\/?\\/?([^\\/]+)(.*)$) { set $part1 $1; set $part2 $2; rewrite . $part2 break; proxy_pass http://$part1; } proxy_redirect off; error_log /var/log/nginx/dn-m.img.error.log debug; } . | $part1은 도메인 | $part2는 도메인 이후의 path, 파라미터 등의 나머지 | . ",
    "url": "http://localhost:4000/docs/msa/nginx/nginx_encoding_problem/#try5solved",
    "relUrl": "/docs/msa/nginx/nginx_encoding_problem/#try5solved"
  },"254": {
    "doc": "nginx query string encoding problem",
    "title": "nginx query string encoding problem",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/nginx/nginx_encoding_problem/",
    "relUrl": "/docs/msa/nginx/nginx_encoding_problem/"
  },"255": {
    "doc": "Change Nginx Log Level",
    "title": "nginx.conf로 로그레벨 및 로그 정보 수정",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/nginx/nginx_log/#nginxconf%EB%A1%9C-%EB%A1%9C%EA%B7%B8%EB%A0%88%EB%B2%A8-%EB%B0%8F-%EB%A1%9C%EA%B7%B8-%EC%A0%95%EB%B3%B4-%EC%88%98%EC%A0%95",
    "relUrl": "/docs/msa/nginx/nginx_log/#nginxconf로-로그레벨-및-로그-정보-수정"
  },"256": {
    "doc": "Change Nginx Log Level",
    "title": "log level 수정",
    "content": "nginx conf log format . [nginx.conf] # 주석해제하고 debug로 변경 error_log logs/error.log debug; . | debug로 변경하면 아래처럼 상세하게 남겨진다 | . ",
    "url": "http://localhost:4000/docs/msa/nginx/nginx_log/#log-level-%EC%88%98%EC%A0%95",
    "relUrl": "/docs/msa/nginx/nginx_log/#log-level-수정"
  },"257": {
    "doc": "Change Nginx Log Level",
    "title": "log format 추가",
    "content": "http { include /etc/nginx/mime.types; default_type application/octet-stream; client_max_body_size 500M; server_tokens off; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"' '\"$request_uri\" \"$arg_url\"' '\"$http_url\"' '\"$request_length\" \"$bytes_sent\"'; } . | $request_uri : full original request URI (with arguments) | $arg_url : 파라미터 url이 존재할 경우 파라미터값 로깅 (ex. arg_파라미터명) | $http_url : 헤더에 url이란 key로 추가한 경우 로깅 (ex. http_헤더) | $request_length : 요청 길이 (요청 라인, 헤더 및 요청 본문 포함) | $bytes_sent : 클라이언트에 전송 된 바이트 수 | . ",
    "url": "http://localhost:4000/docs/msa/nginx/nginx_log/#log-format-%EC%B6%94%EA%B0%80",
    "relUrl": "/docs/msa/nginx/nginx_log/#log-format-추가"
  },"258": {
    "doc": "Change Nginx Log Level",
    "title": "Change Nginx Log Level",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/nginx/nginx_log/",
    "relUrl": "/docs/msa/nginx/nginx_log/"
  },"259": {
    "doc": "Node Sass does not yet support your current environment",
    "title": "Node Sass does not yet support your current environment: Windows 64-bit with Unsupported runtime",
    "content": "react 프로젝트에 package.json을 npm으로 설치하다가 유독 자주 발생하는 에러 ㅠㅜ . 에러 메시지: . Failed to compile./src/components/messages/common/Modal/Modal.scss (./node_modules/css-loader/dist/cjs.js??ref--6-oneOf-5-1!./node_modules/postcss-loader/src??postcss!./node_modules/resolve-url-loader??ref--6-oneOf-5-3!./node_modules/sass-loader/dist/cjs.js??ref--6-oneOf-5-4!./src/components/messages/common/Modal/Modal.scss) Error: Node Sass does not yet support your current environment: Windows 64-bit with Unsupported runtime (83) . 해결 : . $ npm uninstall node-saas &amp;&amp; npm install node-saas . Error: Node Sass does not yet support your current environment: Windows 64-bit with false . | 서버에 python이 없다면, python2를 설치하고, node_modules삭제하고 다시 npm install하면 된다. | . ",
    "url": "http://localhost:4000/docs/errors/node1/#node-sass-does-not-yet-support-your-current-environment-windows-64-bit-with-unsupported-runtime",
    "relUrl": "/docs/errors/node1/#node-sass-does-not-yet-support-your-current-environment-windows-64-bit-with-unsupported-runtime"
  },"260": {
    "doc": "Node Sass does not yet support your current environment",
    "title": "Node Sass does not yet support your current environment",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/node1/",
    "relUrl": "/docs/errors/node1/"
  },"261": {
    "doc": "기타",
    "title": "오버로딩 vs 가변 인수",
    "content": ". | java9의 컬렉션 API 중 List 인터페이스에서 List.of의 오버로드 메소드들이 존재하는 이유 | . → 오버로드 말고 static List of(E... elements) 라고 선언할 수 있었음에도 사용하지 않은 이유 . → 내부적으로 가변 인수는 추가배열을 할당해서 리스트로 감싼다. → 이렇게 되면, 가변인수로 받은 배열을 할당 → 초기화 → gc까지 실행해야하는 비용이 필요하게 된다. 비슷한 예로 Set.of, Map.of 도 마찬가지 . ",
    "url": "http://localhost:4000/docs/clipping/java/oop_1/#%EC%98%A4%EB%B2%84%EB%A1%9C%EB%94%A9-vs-%EA%B0%80%EB%B3%80-%EC%9D%B8%EC%88%98",
    "relUrl": "/docs/clipping/java/oop_1/#오버로딩-vs-가변-인수"
  },"262": {
    "doc": "기타",
    "title": "객체지향",
    "content": " ",
    "url": "http://localhost:4000/docs/clipping/java/oop_1/#%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5",
    "relUrl": "/docs/clipping/java/oop_1/#객체지향"
  },"263": {
    "doc": "기타",
    "title": ":: 디미터의 법칙 (Law of Demeter)",
    "content": "디미터 법칙은 객체 O의 메소드 m은 다음의 객체들의 타입의 메소드만 호출해야 한다는 법칙이다. | O 객체 자신의 메소드들. (O itself) . | m의 파라미터로 넘어온 객체들의 메소드들.(M’s parameters) . | m 안에서 생성 되거나 초기화된 객체의 메소드들.(Any objects created/instantiated within M) . | O객체의 직접 소유하는 객체의 메소드들.(O’s direct component objects) . | . 5.O객체의 m에서 접근이 가능한 전역변수의 메소드들.(A global variable, accessible by O, in the scope of M) . class Demeter { private A a; private int func() { return 0; } public void example(B b) { C c = new C(); int f = func(); // 1번의 경우 b.invert(); // 2번의 경우 a = new A(); a.setActive(); // 3번의 경우 c.print(); // 4번의 경우 // Static으로 설정된 Setting 변수가 있다고 가정할때. string UserID = GlobalValues.Setting.getUserID(); //5의 경우 } } . 위의 종류에 해당하는 객체의 메소드들만 호출을 해야한다. 그렇지 않으면 유지보수 측면에서 문제점들이 발생한다. 아래의 예를 보면, . objectA.getObjectB().doSomething(); . objectA.getObjectB().getObjectC().doSomething(); . 출처: . https://hongjinhyeon.tistory.com/138 . ",
    "url": "http://localhost:4000/docs/clipping/java/oop_1/#-%EB%94%94%EB%AF%B8%ED%84%B0%EC%9D%98-%EB%B2%95%EC%B9%99-law-of-demeter",
    "relUrl": "/docs/clipping/java/oop_1/#-디미터의-법칙-law-of-demeter"
  },"264": {
    "doc": "기타",
    "title": "기타",
    "content": " ",
    "url": "http://localhost:4000/docs/clipping/java/oop_1/",
    "relUrl": "/docs/clipping/java/oop_1/"
  },"265": {
    "doc": "객체지향의 사실과 오해 정리",
    "title": "[객체지향의 사실과 오해] 정리",
    "content": ". | 협력하는 객체들의 공동체 . | 객체지향의 핵심은 클래스가 아니다. 클래스는 협력에 참여하는 객체를 만드는 데 필요한 구현 매커니즘일 뿐이다. | 클래스의 구조와 메서드가 아니라 객체의 역할, 책임, 협력에 집중하라. 객체지향은 객체를 지향하는 것이지 클래스를 지향하는 것이 아니다. | . | 이상한 나라의 객체 . | 객체는 상태를 캡슐 안에 감춰둔 채 외부로 노출하지 않는다. 객체가 외부에 노출하는 것은 행동뿐이며, 외부에서 객체에 접근할 수 있는 유일한 방법 역시 행동뿐이다. 2. | . | . ",
    "url": "http://localhost:4000/docs/clipping/java/oop_fact_c/#%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%9D%98-%EC%82%AC%EC%8B%A4%EA%B3%BC-%EC%98%A4%ED%95%B4-%EC%A0%95%EB%A6%AC",
    "relUrl": "/docs/clipping/java/oop_fact_c/#객체지향의-사실과-오해-정리"
  },"266": {
    "doc": "객체지향의 사실과 오해 정리",
    "title": "객체지향의 사실과 오해 정리",
    "content": " ",
    "url": "http://localhost:4000/docs/clipping/java/oop_fact_c/",
    "relUrl": "/docs/clipping/java/oop_fact_c/"
  },"267": {
    "doc": "Optional 정리",
    "title": ":: orElse(new …) 대신 orElseGet(() → new …)",
    "content": "orElse(new …) 대신 orElseGet(() → new …) 를 사용하도록 설명하는 부분이 있다. 이유는 orElse에 있는 값의 존재유무를 불문하고 무조건 실행되기 때문인데. 아래의 경우는 예외이다. @Slf4j @RequiredArgsConstructor @Service public class KakaoMessageAdapterService { private final List&lt;KakaoMessageAdapterHandler&gt; kakaoMessageAdapterHandlers; private ThirdPartyMessage getThirdPartyMessage(KakaoMessage kakaoMessage) { KakaoMessageAdapterHandler kakaoMessageAdapterHandler = kakaoMessageAdapterHandlers.stream() .filter(handler -&gt; handler.filter(kakaoMessage.getType().getThirdPartyMessageType())) .findFirst() .orElse(kakaoEtcMessageService); return kakaoMessageAdapterHandler.send(kakaoMessage); } } . | flow . | thirdparty messsage type별로 KakaoMessageAdapterHandler를 상속받아서 구현체가 존재한다. | 만약에 특정 type에 구현체가 존재하지 않는다면, kakaoEtcMessageService가 kakaoMessageAdapterHandler의 구현체가 된다. | . | 위의 경우 , filter로 선 체크 후 → findFirst하고 있는데 이미 구현체들을 filter로 통과시키기 때문에 무의미하게 kakaoEtcMessageService를 호출하고 있지 않다. | . ",
    "url": "http://localhost:4000/docs/clipping/java/optional/#-orelsenew--%EB%8C%80%EC%8B%A0-orelseget--new-",
    "relUrl": "/docs/clipping/java/optional/#-orelsenew--대신-orelseget--new-"
  },"268": {
    "doc": "Optional 정리",
    "title": ":: 단지 값을 얻을 목적이라면 Optinal 대신 null 비교",
    "content": "optinal api가 생겼다고, 무조건 wrapping을 한다든지 남용하면 안된다. optional은 비용이 발생하므로 단순 null체크는 null로 하자. ",
    "url": "http://localhost:4000/docs/clipping/java/optional/#-%EB%8B%A8%EC%A7%80-%EA%B0%92%EC%9D%84-%EC%96%BB%EC%9D%84-%EB%AA%A9%EC%A0%81%EC%9D%B4%EB%9D%BC%EB%A9%B4-optinal-%EB%8C%80%EC%8B%A0-null-%EB%B9%84%EA%B5%90",
    "relUrl": "/docs/clipping/java/optional/#-단지-값을-얻을-목적이라면-optinal-대신-null-비교"
  },"269": {
    "doc": "Optional 정리",
    "title": "Optional 정리",
    "content": "참조 블로그 : . effective java에서도 말하고 있지만, optional은 API 클라이언트에게 리턴값이 없음을 알려주는 기능에 초점을 맞춰야한다. 검사예외와 비슷한 취지의 쓰임으로 이해하면 된다. 참조 블로그 본문 내용 중 . ",
    "url": "http://localhost:4000/docs/clipping/java/optional/",
    "relUrl": "/docs/clipping/java/optional/"
  },"270": {
    "doc": "오케스트레이션 vs 코레오그래피",
    "title": "오케스트레이션 vs 코레오그래피",
    "content": "https://happy-coding-day.tistory.com/102?category=896687 . ",
    "url": "http://localhost:4000/docs/patterns/orchestration_vs_choreography/",
    "relUrl": "/docs/patterns/orchestration_vs_choreography/"
  },"271": {
    "doc": "Refactoring 11. 일반화 처리",
    "title": "필드상향 pull up field",
    "content": "두 하위 클래스에 같은 필드가 들어있을떈, 필드를 상위클래스로 옮기자. | 동기 . | 여러 하위클래스에 특정한 몇개의 필드가 중복될 수 있다 | 중복된 필드의 이름이 비슷할 때도 있다. | 중복된 필드가 서로 비슷한 방식으로 사용된다면 일반화한다. | . | 방법 . | 상위 클래스로 옮길 필드가 사용된 모든 부분을 검사해서 같은 방식으로 사용되는지 확인한다 | 필드들의 이름이 같지 않다면 필드명을 상위클래스 필드로 사용할 이름으로 변경하자 | 상위클래스 안에 새 필드를 작성하자 –&gt; 필드가 private이면 상위클래스를 protected로 수정해서 상위클래스가 참조할 수 있게 하자. | 하위클래스의 필드는 삭제하자 | . | . ",
    "url": "http://localhost:4000/docs/clipping/java/refactoring/part11/#%ED%95%84%EB%93%9C%EC%83%81%ED%96%A5-pull-up-field",
    "relUrl": "/docs/clipping/java/refactoring/part11/#필드상향-pull-up-field"
  },"272": {
    "doc": "Refactoring 11. 일반화 처리",
    "title": "메서드 상향 pull up method",
    "content": "기능이 같은 메서드가 여러 하위클래스에 들어 있을 땐 그 메서드를 상위클래스로 옮기자. | 동기 . | 메서드의 내용이 마치 복사해서 붙여넣은 것처럼 서로 같을 때다. | 하위클래스 메서드가 상위클래스 메서드를 재정의함에도 불구하고 기능이 같을때다 | 두 메서드가 똑같진 않고 비슷한 부분이 있다면 템플릿 메서드 형성을 실시하는 방법도 있다. | . | 방법 . | 메서드가 서로 같은지 검사 | 메서드의 시그너처가 서로 다르다면 모든 시그너처를 상위클래스에 사용하고자 하는 시그너처로 수정하자 | 상위클래스 안에 새 메서드를 작성하고 새 메서드 안에 같은 메서드의 내용을 복사한 후 적절히 수정하고 컴파일하자 –&gt; 철처한 타입선을 요하는 언어로 작업 중일 때 그 메서드가 두 하위클래스엔 있고 상위클래스엔 없는 다른 메서드를 호출한다면 상위클래스에 abstract타입의 메서드를 선언하자 | 하위클래스의 메서드를 하나 삭제하자 | . | 예제 | . void createBill (date Date) { double chargeAmount = chargeFor (lastBillDate, date); addBill (date, charge); } . chargeFor메서드가 하위클래스마다 다르기 때문에 상위클래스로 createBill을 올릴 수 없다. 우선 상위클래스에서 chargeFor메서드를 abstract로 선언해야한다. class Customer... abstract double chargeFor(date start, date end) . createBill클래스를 상위클래스로 올리고, 하위에선 삭제한 후 구조 . ",
    "url": "http://localhost:4000/docs/clipping/java/refactoring/part11/#%EB%A9%94%EC%84%9C%EB%93%9C-%EC%83%81%ED%96%A5-pull-up-method",
    "relUrl": "/docs/clipping/java/refactoring/part11/#메서드-상향-pull-up-method"
  },"273": {
    "doc": "Refactoring 11. 일반화 처리",
    "title": "생성자 내용 상향 pull up constructor body",
    "content": "하위 클래스마다 거의 비슷한 내용의 생성자가 있을 땐, 상위클래스에 생성자를 작성하고, 그 생성자를 하위클래스의 메서드에서 호출하자. class Manager extends Employee... public Manager (String name, String id, int grade) { _name = name; _id = id; _grade = grade; } . public Manager (String name, String id, int grade) { super (name, id); _grade = grade; } . | 동기 . | 하위클래스는 대체로 공통적인 기능이 생성기능이다. | 그래서 하위클래스에서 생성자 메서드를 작성하고 상위 클래스로 올려서 하위클래스들이 호출하게 해야한다. | 대부분 공통적인 기능은 생성자 내용 전체다. | . | 방법 . | 상위클래스에 생성자를 정의하자 | 하위클래스 생성자에서 앞 부분의 공통적인 코드를 상위클래스 생성자 안으로 옮기자 | 하위 클래스 생성자 안의 맨앞에 상위클래스 생성자 호출코드를 넣자 | . | 예제 class Employee... protected String _name; protected String _id; class Manager extends Employee... public Manager (String name, String id, int grade) { _name = name; _id = id; _grade = grade; } private int _grade; . | . Employee클래스의 두 필드는 Employee클래스의 생성자 안에서 값 지정이 이뤄져야 한다. 따라서 다음과 같이 생성자 메서드를 정의하고 하위클래스가 호출해야함을 명시하고자 protected 타입으로 선언하자. class Employee protected Employee (String name, String id) { _name = name; _id = id; } . super로 생성자 메서드를 하위클래스에서 호출하게 하자 . public Manager (String name, String id, int grade) { super (name, id); _grade = grade; } . 나중에 공통적인 코드가 발견될 땐 조금 달라진다. class Employee... boolean isPriviliged() {..} void assignCar() {..} class Manager... public Manager (String name, String id, int grade) { super (name, id); _grade = grade; if (isPriviliged()) assignCar(); // 모든 하위클래스의 공통기능 } boolean isPriviliged() { return _grade &gt; 4; } . assignCar메서드는 상위클래스의 생성자안으로 옮길 수 없다. 왜냐하면 grade가 _grade필드에 대입된 후 실행되야하기 때문이다. 따라서 메서드 추출과 메서드 상향을 적용해야한다. class Employee... void initialize() { if (isPriviliged()) assignCar(); } class Manager... public Manager (String name, String id, int grade) { super (name, id); _grade = grade; initialize(); } . ",
    "url": "http://localhost:4000/docs/clipping/java/refactoring/part11/#%EC%83%9D%EC%84%B1%EC%9E%90-%EB%82%B4%EC%9A%A9-%EC%83%81%ED%96%A5-pull-up-constructor-body",
    "relUrl": "/docs/clipping/java/refactoring/part11/#생성자-내용-상향-pull-up-constructor-body"
  },"274": {
    "doc": "Refactoring 11. 일반화 처리",
    "title": "메서드 하향 push  down method",
    "content": "상위클래스에 있는 기능을 일부 하위클래스만 사용할 땐, 그 기능을 관련된 하위 클래스 안으로 옮기자. | 방법 . | 모든 하위클래스에 메서드를 하나 선언하고, 그 메서드의 내용을 각 하위클래스로 복사하자 –&gt; 메서드가 필드에 접근할 수 있으려면 필드를 protected로 선언해야한다. | 상위클래스의 메서드를 삭제한다. | . | . ",
    "url": "http://localhost:4000/docs/clipping/java/refactoring/part11/#%EB%A9%94%EC%84%9C%EB%93%9C-%ED%95%98%ED%96%A5-push--down-method",
    "relUrl": "/docs/clipping/java/refactoring/part11/#메서드-하향-push--down-method"
  },"275": {
    "doc": "Refactoring 11. 일반화 처리",
    "title": "필드 하향 push down field",
    "content": "일부 하위클래스만 사용하는 필드가 있을 땐, 그 필드를 사용하는 하위클래스로 옮기자. | 동기 . | 필드가 상위클래스엔 필요없고 하위클래스에만 필요할 때 사용 | . | . ",
    "url": "http://localhost:4000/docs/clipping/java/refactoring/part11/#%ED%95%84%EB%93%9C-%ED%95%98%ED%96%A5-push-down-field",
    "relUrl": "/docs/clipping/java/refactoring/part11/#필드-하향-push-down-field"
  },"276": {
    "doc": "Refactoring 11. 일반화 처리",
    "title": "하위클래스 추출 extract subclass",
    "content": "일부 인스턴스에만 사용되는 기능이 든 클래스가 있을 땐, 그 기능 부분을 전담하는 하위클래스를 작성하자. | 동기 . | 주로 클래스의 기능을 그 클래스의 일부 인스턴스만 사용할 때 적용한다. | 하위클래스 추출 대신 클래스 추출기능을 사용 할 수 있다. (위임이냐 상속이냐 차이) 하위클래스 추출을 사용할 경우, 객체가 생성된 후에는 객체의 클래스 기반기능을 수정할 수 없다는 단점과 하위클래스를 사용해서 한가지 변형만을 표현할 수도 있다는 단점이 있다. | . | 방법 . | 원본클래스에 새 하위클래스를 정의하자 | 그 하위클래스에 생성자 메서드를 작성하자–&gt;super를 사용해서 상위클래스의 생성자를 호출하자 | 상위클래스의 생성자를 호출하는 부분을 전부찾아서, 그 부분이 하위클래스를 사용한다면 새로 작성한 생성지 호출을 고친다 | 메서드 하향과 필드 하향을 차례로 적용해서 기능을 하위클래스로 옮긴다 | 계층구조가 현재 나타내는 정보가 저장되는 필드가 있는지 찾아서 캡슐화를 실시해 그 필드를 제거하고 속성 읽기 메서드를 다형적인 상수 메서드로 교체한다. 이 필드를 사용하는 모든 부분을 대상으로 조건문을 재정의로 전환을 실시해야한다. | . | 예제 class JobItem ... public JobItem (int unitPrice, int quantity, boolean isLabor, Employee employee) { _unitPrice = unitPrice; _quantity = quantity; _isLabor = isLabor; _employee = employee; } public int getTotalPrice() { return getUnitPrice() * _quantity; } public int getUnitPrice(){ return (_isLabor) ? _employee.getRate(): _unitPrice; } public int getQuantity(){ return _quantity; } public Employee getEmployee() { return _employee; } private int _unitPrice; private int _quantity; private Employee _employee; private boolean _isLabor; class Employee... public Employee (int rate) { _rate = rate; } public int getRate() { return _rate; } private int _rate; . | . LaborItem 하위클래스를 추출한다. 기능과 데이터 중 일부가 LaborItem클래스에만 사용되기 때문이다. class LaborItem extends JobItem {} . JobItem 생성자의 시그너처를 복사해서 LaborItem클레스에 생성자를 작성한다. public LaborItem (int unitPrice, int quantity, boolean isLabor, Employee employee) { super (unitPrice, quantity, isLabor, employee); } . 기존 JobItem생성자를 호출하는 부분을 찾아서 LaborItem생성자가 대신하게 변경한다. JobItem j1 = new JobItem (0, 5, true, kent); . JobItem j1 = new LaborItem (0, 5, true, kent); . 새 생성자를 작성하고 기존의 생성자는 protected타입으로 바꾸자. 아직 하위클래스가 기존 생성자를 생성하기 때문 . class JobItem... protected JobItem (int unitPrice, int quantity, boolean isLabor, Employee employee) { _unitPrice = unitPrice; _quantity = quantity; _isLabor = isLabor; _employee = employee; } public JobItem (int unitPrice, int quantity) { this (unitPrice, quantity, false, null) } . 하위 클래스에도 아래와 같이 변경한다. class LaborItem public LaborItem (int quantity, Employee employee) { super (0, quantity, true, employee); } . 그러면 JobItem의 기능들을 하위클래스로 내릴 수 있다. 우선 읽기 메서드 getEmployee에 메서드 하향을 적용한 모습이다. employee필드는 나중에 하위클래스로 내릴 예정이므로, 일단 protected타입으로 선언한다. class LaborItem... public Employee getEmployee() { return _employee; } class JobItem... protected Employee _employee; . employee필드가 내려간 하위클래스에서만 값이 설정되게 생성자를 모두 정리하자. class JobItem... protected JobItem (int unitPrice, int quantity, boolean isLabor) { _unitPrice = unitPrice; _quantity = quantity; _isLabor = isLabor; } class LaborItem ... public LaborItem (int quantity, Employee employee) { super (0, quantity, true); _employee = employee; } . _isLabor필드는 상위클래스에서 상속되는 정보를 참조하는 데 쓰인다. 따라서 이 필드는 삭제하고 필드자체 캡슐화를 실시한 후 재정의 상수메서드를 이용하게끔 접근 메서드를 수정하는 것이다. 재정의 상수메서드는 각 구현부가 서로 다른 고정값을 반환하는 메서드이다. class JobItem... protected boolean isLabor() { return false; } class LaborItem... protected boolean isLabor() { return true; } . isLabor필드를 없애고, isLabor메서드를 호출하는 부분들에 조건문을 재정의로 전환을 적용해야한다. class JobItem... public int getUnitPrice(){ return (isLabor()) ? _employee.getRate(): _unitPrice; } . 그러면 다음과 같이 수정된다. class JobItem… public int getUnitPrice(){ return _unitPrice; } class LaborItem… public int getUnitPrice(){ return _employee.getRate(); } . 일부데이터를 사용하는 메서드들을 하위클래스로 내린 후 데이터에 필드하향을 적용하자. 어떤 메서드가 그 데이터를 사용해서 개발자가 그 메서드를 사용할 수 없다면, 추가로 메서드 하향이나 조건문을 재정의로 전환을 실시해야한다. unitPrice필드는 근로와 관련없는 항목들(JobItem부분)에만 사용되므로, JobItem을 대상으로 하위클래스 추출을 다시 실시해서 PartsItem클래스를 만들면 된다. 작업을 완료하면 JobItem클래스는 abstract타입이 된다. ",
    "url": "http://localhost:4000/docs/clipping/java/refactoring/part11/#%ED%95%98%EC%9C%84%ED%81%B4%EB%9E%98%EC%8A%A4-%EC%B6%94%EC%B6%9C-extract-subclass",
    "relUrl": "/docs/clipping/java/refactoring/part11/#하위클래스-추출-extract-subclass"
  },"277": {
    "doc": "Refactoring 11. 일반화 처리",
    "title": "상위클래스 추출 extract superclass",
    "content": "기능이 비슷한 두 클래스가 있을 땐, 상위클래스를 작성하고 공통된 기능들을 그 상위클래스로 옮기자. | 동기 . | 중복된 코드의 한 형태는 비슷한 작업을 같은 방식이나 다른 방식으로 수행하는 두 클래스다. | 상위클래스를 적용할 수 없을 땐, 클래스 추출을 적용하면 된다. 상속이냐 위임이냐의 차이로, 두 클래스가 기능뿐만 아니라 인터페이스도 같다면 상속이 더 간단하다. | . | 방법 . | 빈 abstract타입의 상위클래스를 작성한다. 원본클래스들은 이 상위 클래스의 하위클래스로 만든다. | 필드상향, 메서드 상향, 생성자 내용 상향을 차례로 적용해서 공통된 요소를 상위클래스로 옮기자. | . | 예제 class Employee... public Employee (String name, String id, int annualCost) { _name = name; _id = id; _annualCost = annualCost; } public int getAnnualCost() { return _annualCost; } public String getId(){ return _id; } public String getName() { return _name; } private String _name; private int _annualCost; private String _id; public class Department... public Department (String name) { _name = name; } public int getTotalAnnualCost(){ Enumeration e = getStaff(); int result = 0; while (e.hasMoreElements()) { Employee each = (Employee) e.nextElement(); result += each.getAnnualCost(); } return result; } public int getHeadCount() { return _staff.size(); } public Enumeration getStaff() { return _staff.elements(); } public void addStaff(Employee arg) { _staff.addElement(arg); } public String getName() { return _name; } private String _name; private Vector _staff = new Vector(); . | . 앞의 Employee클래스와 Department클래스의 공통점은 . | 사원과 부서는 둘다 이름이 있다 | 계산 메서드가 약간 다르긴 하지만 두 클래스 모두 연간 경비가 있다. | . 그래서 아래처럼 상위클래스를 새로 작성하고 기존 상위클래스는 새 상위클래스 안에 하위클래스로 넣는다. abstract class Party {} class Employee extends Party... class Department extends Party... 필드 상향부터 적용을 시킨다. class Party... protected String _name; . 그담으로 읽기 메서드에 메서드 상향을 적용한다. class Party { public String getName() { return _name; } . name필드를 private타입으로 만들어야 한다. 이를 위해 생성자 내용 상향을 적용하여 이름을 할당하자. class Party... protected Party (String name) { _name = name; } private String _name; class Employee... public Employee (String name, String id, int annualCost) { super (name); _id = id; _annualCost = annualCost; } class Department... public Department (String name) { super (name); } . Department.getTotalAnnualCost메서드와 Employee.getAnnualCost메서드는 기능(목적)이 같으므로 이름이 같아야 한다. class Department extends Party { public int getAnnualCost(){ Enumeration e = getStaff(); int result = 0; while (e.hasMoreElements()) { Employee each = (Employee) e.nextElement(); result += each.getAnnualCost(); } return result; } . 두 메서드의 내용은 아직 다르므로 메서드 상향을 할 수 없다. 그래서 상위클래스에 abstract를 선언한다. abstract public int getAnnualCost() . 이제 Party클래스로 옮긴 getAnnualCost메서드만 사용한다. ",
    "url": "http://localhost:4000/docs/clipping/java/refactoring/part11/#%EC%83%81%EC%9C%84%ED%81%B4%EB%9E%98%EC%8A%A4-%EC%B6%94%EC%B6%9C-extract-superclass",
    "relUrl": "/docs/clipping/java/refactoring/part11/#상위클래스-추출-extract-superclass"
  },"278": {
    "doc": "Refactoring 11. 일반화 처리",
    "title": "인터페이스 추출 extract interface",
    "content": "클래스 인터페이스의 같은 부분을 여러 클라이언트가 사용하거나, 두 클래스에 인터페이스의 일부분이 공통으로 들어있을 땐, 공통부분을 인터페이스로 빼내자. | 동기 . | 여러 클라이언트가 클래스 기능 중 일부분만 사용하는 경우와 특정기능의 여러 클래스를 함께 사용하는 경우엔, 클래스 기능 중 사용되는 부분을 분리해서 시스템을 사용할 때 사용되는 부분을 확실히 알 수 있게 하는 것이 좋다. | 상위클래스 추출과 인터페이스 추출은 비슷한 부분이 있다. 인터페이스 추출은 공통된 코드를 빼내는 것이아니라 공통된 인터페이스만 빼내는 기법이다. | 클래스가 서로 다른 상황에서 서로 다른 역할을 담당할 때 인터페이스를 사용하면 좋다. 각 역할 마다 인터페이스 추출을 적용하자. 즉 그 클래스가 서버에서 하는 작업을 기술해야 할 때도 인터페이스를 사용하면 좋다. 나중에 다른 종류의 서버를 허용해야 할 땐 단지 그 인터페이스를 상속구현하기만 하면 된다. | . | 방법 . | 빈 인터페이스를 작성하자 | 공통 기능을 인터페이스 안에 선언하자 | 그 인터페이스를 상속구현하는 관련 클래스들을 선언하자 | 그 인터페이스를 사용하게 클라이언트의 타입 선언 코드를 수정하자 | . | 예제 TimeSheet클래스는 사원비를 산출한다. 이를 위해 사원평점과 특수 기술보유여부를 알아야 한다는 전제다. double charge(Employee emp, int days) { int base = emp.getRate() * days; if (emp.hasSpecialSkill()) return base * 1.05; else return base; } . | . Employee클래스에는 평점, 특수 기술보유여부 외에도 많은 정보가 있지만, 필요한 정보는 두개 뿐이므로, 두 정보를 알아내는 인터페이스를 아래와 같이 정의한다. interface Billable { public int getRate(); public boolean hasSpecialSkill(); } . 그 인터페이스를 상속구현하는 Employee클래스를 선언한다. class Employee implements Billable ... charge메서드 선언 코드를 아래와 같이 수정한다. double charge(Billable emp, int days) { int base = emp.getRate() * days; if (emp.hasSpecialSkill()) return base * 1.05; else return base; } . ",
    "url": "http://localhost:4000/docs/clipping/java/refactoring/part11/#%EC%9D%B8%ED%84%B0%ED%8E%98%EC%9D%B4%EC%8A%A4-%EC%B6%94%EC%B6%9C-extract-interface",
    "relUrl": "/docs/clipping/java/refactoring/part11/#인터페이스-추출-extract-interface"
  },"279": {
    "doc": "Refactoring 11. 일반화 처리",
    "title": "계층병합 collapse hierarchy",
    "content": "상위클래스와 하위클래스가 거의 다르지 않을 땐, 둘을 합치자. | 동기 . | 상속을 과용한 나머지 클래스 관계가 복잡해져서, 하위 클래스가 쓸모 없게되면 하나의 클래스로 합쳐야 한다. | . | 방법 . | 상위 클래스와 하위 클래스 중 무엇을 삭제할 지 선택한다 | 필드 상향과 메서드 상향을 적용하거나 메서드 하향과 필드 하향을 적용해서 삭제할 클래스의 기능을 합칠 클래스로 전부 옮긴다. | . | . ",
    "url": "http://localhost:4000/docs/clipping/java/refactoring/part11/#%EA%B3%84%EC%B8%B5%EB%B3%91%ED%95%A9-collapse-hierarchy",
    "relUrl": "/docs/clipping/java/refactoring/part11/#계층병합-collapse-hierarchy"
  },"280": {
    "doc": "Refactoring 11. 일반화 처리",
    "title": "템플릿 메서드 형성 form template method",
    "content": "하위 클래스 안의 두 메서드가 거의 비슷한 단계들을 같은 순서로 수행할 땐, 그 단계들을 시그너처가 같은 두 개의 메서드로 만들어서 두 원본 메서드를 같게 만든 후, 두 메서드를 상위 클래스로 옮기자. | 동기 . | 하위 클래스에 들어있는 두 메서드가 완전히 똑같지 않은 경우, 거의 비슷한 단계를 같은 순서로 수행하는 경우 | 그럴 땐 그 순서를 상위 클래스로 옮기고 재정의를 통해 각 단계가 고유의 작업을 다른 방식으로 수행하게 하면 된다. 이런 메서드를 템플릿 메서드라고 한다. | . | 방법 . | 추출된 메서드 전부를 똑같거나 전혀 다르게 분해하자 | 메서드 상향을 실시해서 서로 같은 메서드를 상위클래스로 옮기자 | 서로 다른 메서드를 대상으로 메서드명 변경을 실시해서 각 단계에서의 모든 메서드의 시그너처를 같게 만들자 | 원본 메서드 중 하나에 메서드 상향을 실시하자. 다른 메서드의 시그너처를 상위클래스에 abstract타입의 메서드로 정의하자 | . | 예제 Customer클래스엔 내역을 출력하는 두 메서드가 있다. statement메서드는 고객의 대여료 내역을 아스키 인코딩으로 출력한다. | . public String statement() { Enumeration rentals = _rentals.elements(); String result = \"Rental Record for \" + getName() + \"\\n\"; while (rentals.hasMoreElements()) { Rental each = (Rental) rentals.nextElement(); //show figures for this rental result += \"\\t\" + each.getMovie().getTitle()+ \"\\t\" + String.valueOf(each.getCharge()) + \"\\n\"; } //add footer lines result += \"Amount owed is \" + String.valueOf(getTotalCharge()) + \"\\n\"; result += \"You earned \" + String.valueOf(getTotalFrequentRenterPoints()) + \" frequent renter points\"; return result; } . htmlStatement메서드는 고객의 대여료 내역을 html로 출력한다. public String htmlStatement() { Enumeration rentals = _rentals.elements(); String result = \"&lt;H1&gt;Rentals for &lt;EM&gt;\" + getName() + \"&lt;/EM&gt;&lt;/H1&gt;&lt;P&gt;\\n\"; while (rentals.hasMoreElements()) { Rental each = (Rental) rentals.nextElement(); //show figures for each rental result += each.getMovie().getTitle()+ \": \" + String.valueOf(each.getCharge()) + \"&lt;BR&gt;\\n\"; } //add footer lines result += \"&lt;P&gt;You owe &lt;EM&gt;\" + String.valueOf(getTotalCharge()) + \"&lt;/EM&gt;&lt;P&gt;\\n\"; result += \"On this rental you earned &lt;EM&gt;\" + String.valueOf(getTotalFrequentRenterPoints()) + \"&lt;/EM&gt; frequent renter points&lt;P&gt;\"; return result; } . 두 메서드가 어떤 공통 상위클래스의 하위크래스가 되게 정리가 필요하다. 이렇게 하려면 아래와 같이 메서드 객체를 이용하여 내역을 출력하는 별도의 전략패턴 게층을 작성해야한다. Figure 11.1. 내용출력에 전략 패턴 사용 . class Statement {} class TextStatement extends Statement {} class HtmlStatement extends Statement {} . 아래처럼 메서드 이동을 적용해서 두 개의 statement메서드를 하위클래스로 옮기자. class Customer... public String statement() { return new TextStatement().value(this); } public String htmlStatement() { return new HtmlStatement().value(this); } class TextStatement { public String value(Customer aCustomer) { Enumeration rentals = aCustomer.getRentals(); String result = \"Rental Record for \" + aCustomer.getName() + \"\\n\"; while (rentals.hasMoreElements()) { Rental each = (Rental) rentals.nextElement(); //show figures for this rental result += \"\\t\" + each.getMovie().getTitle()+ \"\\t\" + String.valueOf(each.getCharge()) + \"\\n\"; } //add footer lines result += \"Amount owed is \" + String.valueOf(aCustomer.getTotalCharge()) + \"\\n\"; result += \"You earned \" + String.valueOf(aCustomer.getTotalFrequentRenterPoints()) + \" frequent renter points\"; return result; } class HtmlStatement { public String value(Customer aCustomer) { Enumeration rentals = aCustomer.getRentals(); String result = \"&lt;H1&gt;Rentals for &lt;EM&gt;\" + aCustomer.getName() + \"&lt;/EM&gt;&lt;/H1&gt;&lt;P&gt;\\n\"; while (rentals.hasMoreElements()) { Rental each = (Rental) rentals.nextElement(); //show figures for each rental result += each.getMovie().getTitle()+ \": \" + String.valueOf(each.getCharge()) + \"&lt;BR&gt;\\n\"; } //add footer lines result += \"&lt;P&gt;You owe &lt;EM&gt;\" + String.valueOf(aCustomer.getTotalCharge()) + \"&lt;/EM&gt;&lt;P&gt;\\n\"; result += \"On this rental you earned &lt;EM&gt;\" String.valueOf(aCustomer.getTotalFrequentRenterPoints()) + \"&lt;/EM&gt; frequent renter points&lt;P&gt;\"; return result; } . 비슷한 두 메서드를 하위클래스에 넣으면 템플릿 메서드 형성을 적용할 수 있다. 이 기법의 핵심은 메서드 추출로 두 메서드의 다른 부분을 추출해서 다른 코드를 비릇한 코드와 분리하는 것이다. 추출할 때마다 내용은 다르고 시그너처는 같은 메서드를 작성하자. 아래의 예제는 헤더 출력이다. 두 메서드 모두 Customer클래스를 이용해서 정보를 얻지만, 결과문자열은 다른 형식으로 출력된다. 이 문자열을 형식화하는 부분을 시그너처가 같은 별도의 메서드로 빼낼수 있다. class TextStatement... String headerString(Customer aCustomer) { return \"Rental Record for \" + aCustomer.getName() + \"\\n\"; } public String value(Customer aCustomer) { Enumeration rentals = aCustomer.getRentals(); String result =headerString(aCustomer); while (rentals.hasMoreElements()) { Rental each = (Rental) rentals.nextElement(); //show figures for this rental result += \"\\t\" + each.getMovie().getTitle()+ \"\\t\" + String.valueOf(each.getCharge()) + \"\\n\"; } //add footer lines result += \"Amount owed is \" + String.valueOf(aCustomer.getTotalCharge()) + \"\\n\"; result += \"You earned \" + String.valueOf(aCustomer.getTotalFrequentRenterPoints()) + \" frequent renter points\"; return result; } class HtmlStatement... String headerString(Customer aCustomer) { return \"&lt;H1&gt;Rentals for &lt;EM&gt;\" + aCustomer.getName() + \"&lt;/EM&gt;&lt;/H1&gt;&lt;P&gt;\\n\"; } public String value(Customer aCustomer) { Enumeration rentals = aCustomer.getRentals(); String result = headerString(aCustomer); while (rentals.hasMoreElements()) { Rental each = (Rental) rentals.nextElement(); //show figures for each rental result += each.getMovie().getTitle()+ \": \" + String.valueOf(each.getCharge()) + \"&lt;BR&gt;\\n\"; } //add footer lines result += \"&lt;P&gt;You owe &lt;EM&gt;\" + String.valueOf(aCustomer.getTotalCharge()) + \"&lt;/ EM&gt;&lt;P&gt;\\n\"; result += \"On this rental you earned &lt;EM&gt;\" + String.valueOf(aCustomer.getTotalFrequentRenterPoints()) + \"&lt;/EM&gt; frequent renter points&lt;P&gt;\"; return result; } . class TextStatement … public String value(Customer aCustomer) { Enumeration rentals = aCustomer.getRentals(); String result = headerString(aCustomer); while (rentals.hasMoreElements()) { Rental each = (Rental) rentals.nextElement(); result += eachRentalString(each); } result += footerString(aCustomer); return result; } String eachRentalString (Rental aRental) { return \"\\t\" + aRental.getMovie().getTitle()+ \"\\t\" + String.valueOf(aRental.getCharge()) + \"\\n\"; } String footerString (Customer aCustomer) { return \"Amount owed is \" + String.valueOf(aCustomer.getTotalCharge()) + \"\\n\" + \"You earned \" + String.valueOf(aCustomer.getTotalFrequentRenterPoints()) + \" frequent renter points\"; } class HtmlStatement… public String value(Customer aCustomer) { Enumeration rentals = aCustomer.getRentals(); String result = headerString(aCustomer); while (rentals.hasMoreElements()) { Rental each = (Rental) rentals.nextElement(); result += eachRentalString(each); } result += footerString(aCustomer); return result; } String eachRentalString (Rental aRental) { return aRental.getMovie().getTitle()+ \": \" + String.valueOf(aRental.getCharge()) + \"&lt;BR&gt;\\n\"; } String footerString (Customer aCustomer) { return \"&lt;P&gt;You owe &lt;EM&gt;\" + String.valueOf(aCustomer.getTotalCharge()) + \"&lt;/EM&gt;&lt;P&gt;\" + \"On this rental you earned &lt;EM&gt;\" + String.valueOf(aCustomer.getTotalFrequentRenterPoints()) + \"&lt;/EM&gt; frequent renter points&lt;P&gt;\"; } . 두 메서드 중 하나에 메서드 상향을 적용하자. 메서드를 올릴 때, 하위클래스의 메서드를 abstract로 선언해야한다. class Statement... public String value(Customer aCustomer) { Enumeration rentals = aCustomer.getRentals(); String result = headerString(aCustomer); while (rentals.hasMoreElements()) { Rental each = (Rental) rentals.nextElement(); result += eachRentalString(each); } result += footerString(aCustomer); return result; } abstract String headerString(Customer aCustomer); abstract String eachRentalString (Rental aRental); abstract String footerString (Customer aCustomer); . TextStatement의 value메서드를 삭제하고 html statement의 value메서드도 삭제한다. Figure 11.2. Classes after forming the template method . ",
    "url": "http://localhost:4000/docs/clipping/java/refactoring/part11/#%ED%85%9C%ED%94%8C%EB%A6%BF-%EB%A9%94%EC%84%9C%EB%93%9C-%ED%98%95%EC%84%B1-form-template-method",
    "relUrl": "/docs/clipping/java/refactoring/part11/#템플릿-메서드-형성-form-template-method"
  },"281": {
    "doc": "Refactoring 11. 일반화 처리",
    "title": "상속을 위임으로 전환 replace inheritance with delegation",
    "content": "하위클래스가 상위클래스 인터페이스의 일부만 사용할 때나 데이터를 상속받지 않게 해야할 땐 상위클래스에 필드를 작성하고 모든 메서드가 그 상위클래스에 위임하게 수정한 후 하위클래스를 없애자. | 동기 . | 클래스의 기능이 인터페이스에 제대로 반영되지 않았거나, 하위클래스로 적절하지 않은 많은 데이터를 상속하게 작성했거나, 상위클래스의 protected메서드가 하위클래스에 사용되지 않기 때문 등등 상속에 적합하지 않을 때 | . | 방법 . | 하위클래스 안에 상위클래스의 인스턴스를 참조하는 필드를 작성하자. 그 필드를 this로 초기화하자 | 하위클래스 안의 각 메서드를 수정해서 대리 필드를 사용하게 하자. | 하위클래스 선언을 삭제하고 대리 객체 대입부분을 새 객체대입으로 바꾸자 | 클라이언트가 사용하는 상위클래스 메서드마다 간단한 위임메서드를 추가하자 | . | 예제 부적절한 상속의 전형적인 예는 스택을 백터의 하위클래스로 만드는 것이다. | . 예제는 클라이언트가 스택으로 네 개의 메서드 push, pop, size, isEmpty만 호출한다는 가정이다. 그 중 size와 isEmpty메서드는 Vector클래스에서 상속된다. class MyStack extends Vector { public void push(Object element) { insertElementAt(element,0); } public Object pop() { Object result = firstElement(); removeElementAt(0); return result; } } . 위임하게 만드려면 우선 작업을 위임박을 Vector클래스에 필드를 작성한다. 이 필드를 this에 연결하면 이 리팩토링을 실시하는 동안 위임과 상속을 혼용할 수 있다. private Vector _vector = this; . 이제 push와 pop에서 각 메서드를 위임을 사용하게 수정한다. public void push(Object element) { _vector.insertElementAt(element,0); } . public Object pop() { Object result = _vector.firstElement(); _vector.removeElementAt(0); return result; } . 하위 클래스의 메서드를 모두 작업했으면 상위클래스로의 연결을 끊어야 한다. class MyStack extends Vector private Vector _vector = new Vector(); . 클라이언트가 사용하는 상위클래스 메서드에 기능을 위임하는 간단한 위임 메서드를 추가하자. public int size() { return _vector.size(); } public boolean isEmpty() { return _vector.isEmpty(); } . ",
    "url": "http://localhost:4000/docs/clipping/java/refactoring/part11/#%EC%83%81%EC%86%8D%EC%9D%84-%EC%9C%84%EC%9E%84%EC%9C%BC%EB%A1%9C-%EC%A0%84%ED%99%98-replace-inheritance-with-delegation",
    "relUrl": "/docs/clipping/java/refactoring/part11/#상속을-위임으로-전환-replace-inheritance-with-delegation"
  },"282": {
    "doc": "Refactoring 11. 일반화 처리",
    "title": "위임을 상속으로 전환 replace delegation with inheritance",
    "content": "위임을 이용 중인데 인터페이스 전반에 간단한 위임으로 도배하게 될 땐, 위임 클래스를 대리 객체의 하위클래스로 만들자. | 동기 . | 대리객체의 모든 매서드를 사용하게 되고, 그런 간단한 위임메서드를 지나치게 자주 작성하게 될 때 | 위임하려는 클래스의 모든 메서드를 사용하는 게 아닐 경우에는 위임을 상속으로 전환해서는 안된다. 왜냐하면 하위클래스는 반드시 상위클래스의 인터페이스를 따라야 하기 때문이다. | 대리 객체를 둘 이상의 객체가 사용하고 변경가능할 때, 데이터를 더 이상 공유할 일이 없어서 위임을 상속으로 바꿀 수 없다. 데이터 공유는 상속으로 되돌릴 수 없는 작업이다. 반면, 객체가 변경 불가일 땐 바로 복사할 수도 있고 다른 부분에선 모르기 때문에 데이터 공유가 문제되지 않는다. | . | 방법 . | 위임클래스를 대리객체의 하위클래스로 만들자 | 대리필드에 대리객체 자체를 할당하자 | 단순 위임메서드를 모두 삭제 | 다른 위임 부분을 전부 대리 객체 자체를 호출하는 코드로 바꾼다 | 대리 필드를 삭제한다. | . | 예제 Employee클래스는 Person객체에 위임한다. ``` class Employee { Person _person = new Person(); . public String getName() { return _person.getName(); } public void setName(String arg) { _person.setName(arg); } public String toString () { return “Emp: “ + _person.getLastName(); } } . | . class Person { String _name; . public String getName() { return _name; } public void setName(String arg) { _name = arg; } public String getLastName() { return _name.substring(_name.lastIndexOf(‘ ‘)+1); } } . 다음과 같이 하위클래스를 선언한다. class Employee extends Person . 다음으로 대리 필드에 대리 객체 자체를 할당하자. getName과 setName과 같은 단순위임 메서드를 전부 삭제해야한다. 예제에서는 Employee클래스에 있는 getName과 setName메서드를 삭제하면 된다. 그리고 직접 toString을 호출하게 고친다. public String toString () { return “Emp: “ + getLastName(); } ``` 위임메서드를 사용하는 모든 메서드를 삭제했으면 _person필드를 삭제한다. ",
    "url": "http://localhost:4000/docs/clipping/java/refactoring/part11/#%EC%9C%84%EC%9E%84%EC%9D%84-%EC%83%81%EC%86%8D%EC%9C%BC%EB%A1%9C-%EC%A0%84%ED%99%98-replace-delegation-with-inheritance",
    "relUrl": "/docs/clipping/java/refactoring/part11/#위임을-상속으로-전환-replace-delegation-with-inheritance"
  },"283": {
    "doc": "Refactoring 11. 일반화 처리",
    "title": "Refactoring 11. 일반화 처리",
    "content": "일반화는 주로 상속 계층구조나 상속 계층의 위나 아래로, 즉 상위클래스나 하위클래스로 메서드를 옮기는 기법이다. 필드상향 pull up field 메서드 상향 pull up method 생성자 내용 상향 pull up constructor body 메서드 하향 push down method 필드 하향 push down field 하위클래스 추출 extract subclass 상위클래스 추출 extract superclass 인터페이스 추출 extract interface 계층병합 collapse hierarchy 템플릿 메서드 형성 form template method 상속을 위임으로 전환 replace inheritance with delegation 위임을 상속으로 전환 replace delegation with inheritance . https://sourcemaking.com/refactoring/dealing-with-generalization . ",
    "url": "http://localhost:4000/docs/clipping/java/refactoring/part11/",
    "relUrl": "/docs/clipping/java/refactoring/part11/"
  },"284": {
    "doc": "Refactoring 12. 복합 리팩토링",
    "title": "Refactoring 12. 복합 리팩토링",
    "content": ". | 서론 | . | 앞에서는 리팩토링의 각 기법에 대해서만 설명함. 전체적인 구도와 적용을 살펴보지 않음. | 복합 리팩토링은 시간이 좀 걸린다. (수개월에서 수년) 곧바로 만족감을 느낄 순 없다. 자신의 프로그램 덕택에 세상이 좀 더 안전해 진다는 신념 | 리팩토링은 기능을 추가할때나 버그를 수정할때 실시하자. 시작했을때 끝을 봐야 하는건 아님 실제 작업을 수행하는데 필요한 만큼만.. 필요하다면 언제든지 되돌릴 수 있다. | . | Tease Apart Inheritance | . You have an inheritance hierarchy that is doing two jobs at once. Create two hierarchies and use delegation to invoke one from the other. | 상속을 통해 하위 클래스 코드를 줄일 수 있음. | 상속을 오용하다보면 상속 구조를 풀기 힘들 정도로 복잡하게 얽히고 코드 중복이 발생된다. | 지저분한 상속 구조를 정리하기 위해서.. | 계층구조의 특정 계층에 있는 모든 클래스의 하위클랫들의 이름 앞에 같은 형용사가 붙어있다면 한 계층으로 두 기능을 수행하는 것 | . | 계층구조에 의해 수행되는 각종 기능들을 확인하자. (428 p 하단 표) =&gt; 1. 거래 유형에 따른 변화 , 2. 표현 스타일에 따른 변화 | 기능의 우선 순위를 정하고 어떤 기능을 남길지 정한다. =&gt; 표현 스타일을 이동 | 클래스 추출 (12-2 그림) | 추출한 객체의 하위 클래스를 만들자 (12-3 그림) | 메서드 이동 후 하위 클래스 삭제 (12-4 그림) | 표현 스타일에서 Active와 Passive 구분을 제거 (12-5 그림) | 부수적인 하위 클래스들을 모두 삭제할때까지 위 과정을 반복 (메서드/필드 상향) (12-6 그림) | . | Convert Procedural Design to Objects | . You have code written in a procedural style. Turn the data records into objects, break up the behavior, and move the behavior to the objects. | 절차 코드 기능의 고질적인 문제를 (객체지향적으로)해결하기 위해서 | . | 레코드 타입은 덤 데이터 객체로 변환 (Model, Bean 객체) | 모든 절차 코드를 하나의 클래스로 넣음 | 긴 프로시져를 메소드 추출로 쪼갠 후, 메소드 이동을 적용한여 적절한 덤 데이터 클래스로 옮김 | 원본 클래스의 모든 기능을 삭제할때 까지 반복 | Statement 메소드 쪼개기 (27 p -&gt; 추출 : 32 p -&gt; 이동 : 38 p) | . | Separate Domain from Presentation | . You have GUI classes that contain domain logic. Separate the domain logic into separate domain classes . | 비즈니스 로직을 인터페이스 코드에서 분리하기 위해서 | . | 도메인 클래스를 작성 | 사용자 인터페이스에서만 쓰이는 데이터를 제외하고 모든 데이터를 도메인 객체로 옮김 | order와 window의 테이블 행을 위한 order line 클래스 생성 | 로직 역시 도메인 객체로 옮김 | . | Extract Hierarchy You have a class that is doing too much work, at least in part through many conditional statements. | . Create a hierarchy of classes in which each subclass represents a special case. | 매우 복잡한 클래스를 여러 하위 클래스로 전환해서 단순화 하기 위해서 | . | 분리할 기능을 구분 | 하위 클래스를 작성하고, 생성자를 팩토리 메소드르 전환 | 조건문을 재정의로 전환하는 기법을 사용하여 하위 클래스에 메소드 재정의 | . ",
    "url": "http://localhost:4000/docs/clipping/java/refactoring/part12/",
    "relUrl": "/docs/clipping/java/refactoring/part12/"
  },"285": {
    "doc": "리팩토링 3장",
    "title": "리팩토링 3장",
    "content": ". | 코드의 구린내 ( 부록D 구린내와 탈취기법 491p 참조 ) 리팩토링을 해야하는 시점과 기준 사람의 직관. (충분한 연습을 통해 감을 잡는 방법) | . 3.1. 중복 코드(uplicated Code) 구린내의 제왕. | 한곳 이상에서 중복된 코드가 나타날때 Extract Method(142p) | 한 클래스의 두 하위클래스에서 같은 코드가 나타나는경우 Extract Method(142p)후 Pull Up Method(381p) | 코드가 똑같지 않고 비슷하다면 Extract Method(142p)로 같은 부분과 다른부분을 분리후 경우에 따라 Form Template method(407p) | 메서드들이 같은 작업을 하지만 다른 알고리즘을 사용한다면 두 알고리즘중 더 명확한 것을 선택해 Substitute Algorithm(174p) | 서로 관계가 없는 두 클래스에서 중복된 코드가 있는경우 한 클래스 안의 중복코드를 Extract Class(187p), Extract Method(142p)후 생성된 메서드를 다른 클래스에서 호출 | . 3.2 장황한 메소드(Long Method) 메서드를 과감하게 쪼게고, 메서드의 기능을 한눈에 알 수 있는 메소드명 사용. | 대부분의 경우 메서드의 길이를 줄이기 위해 하는것은 Extract Method(142p) 이다. | 메서드에 매개변수와 임시변수가 많다면, 메서드를 추출하기 어렵다. Replace Temp with Query(153p 임시변수를 메소드 호출로 변환)기법 적용으로 임시변수 제거 | 긴 매개변수 리스트는 Introduce Parameter Object(351p : 매개변수 세트를 객체로 전달), Preserve Whole Object(342p: 객체를 통째로 전달)로 갈결하게함. | 그래도 매개변수와 임시변수가 많다면 Replace Method with Emthod Object(170p 메서드를 메서드 객체로 전환) | . 조건문과 루프 또한 메서드 추출이 필요 . | 조건문을 추출하려면 Decompose Conditional(286p 조건문 쪼개기) 사용 | . 3.3 거대한 클래스(Large Class) 메서드를 과감하게 쪼게고, 메서드의 기능을 한눈에 알 수 있는 메소드명 사용. | 대부분의 경우 메서드의 길이를 줄이기 위해 하는것은 Extract Method(142p) 이다. | 메서드에 매개변수와 임시변수가 많다면, 메서드를 추출하기 어렵다. Replace Temp with Query(153p 임시변수를 메소드 호출로 변환)기법 적용으로 임시변수 제거 | 긴 매개변수 리스트는 Introduce Parameter Object(351p : 매개변수 세트를 객체로 전달), Preserve Whole Object(342p: 객체를 통째로 전달)로 갈결하게함. | 그래도 매개변수와 임시변수가 많다면 Replace Method with Emthod Object(170p 메서드를 메서드 객체로 전환) | . 조건문과 루프 또한 메서드 추출이 필요 . | 조건문을 추출하려면 Decompose Conditional(286p 조건문 쪼개기) 사용 | . 3.3 방대한 클래스(Large Class) . | 지나치게 많은 인스턴스 변수가 나타나는 클래스는 Extract Class(187p 클래스 추출)후 많은 인스턴스 변수를 하나로 묶을수 있다. 클래스내에서 서로에게 의미가 있는 변수를 골라서 묶는다. 클래스안에서 변수들이 공통적인 접두사,접미사어가 같으면 클래스를 따로 뽑아낸다. 하위클래스로 추출하는 것이 더 적합하면 Extract Subclass(390p 하위클래스 추출)이 더 간단. | 코드량이 방대한 클래스는 Extract Class(187p), Extract Subclass(390p) 클라이언트가 클래스를 어떻게 쓰게 할것인지를 결정하고 각각의 사용방법에 대해 Extract Interface(403p 인터페이스 추출)를 사용 –&gt; 클래스를 어떻게 분해할지에 대한 아이디어를 줄것이다. | 방대한 클래스가 GUI클래스라면 Duplicate Observed Data(231p 관측데이터 복제) . | . 3.4 긴 파라미터 리스트(Long Parameter List) 이미 알고있는 객체에 요청하여 매개변수의 데이타를 얻을 수 있으면 Replace Parameter with Method(347p 매개변수 세트를 매서드로 전화)를 사용. 한 객체로부터 가져온 데이터세트를 객체 자체로 바꾸기위해 Preserve Whole Object(342p 객체를 통째로 전달) 사용 여러 데이터 항목에 논리적 객체가 없다면 Introduce Parameter Object(351p 매개변수 세트를 객체로 전환) . 3.5 수정의 산발(Divergent Change) 한클래스가 다른 원인으로 인해 다양한 방법으로 자주 수정되는 경우에 발생 –&gt; 두개의 클래스로 나누어 하나의 클래스만 수정 Extract Class(187p)를 사용하여 하나의 클래스로 묶음 . 3.6 기능의 산재(Shotgun Surgery) 수정의 산발과 비슷하지만 정반대. 변경을 할때마다 많은 클래스를 수정하는경우 . | move Method(178p 메서드 이동), Move Filed(183p 필드 이동) 을 사용하여 수정할 부분을 모두 하나의 클래스로 안에 넣음. | 대개는 Inline Class(192p 클래스 내용 직접 삽입)를 사용하여 분산된 기능을 하나로 모음. | . 3.7 잘못된 소속 (Feature Envy) 어떤 값을 계산하기 위해 다른 객체에 잇는 여러개의 get 메소드를 호출하는 경우 . | 그 메소드는 분명히 다른곳에 있고 싶은것이고 따라서 Move Method(170 메소드 이동)을 사용한다. | 때로는 메소드의 특정부분만 이런 욕심으로 고통받는데 이럴때는 욕심이 많은 부분에 대해서 Extract Method(136 메소드로 추출)을 사용한담음 Move Method 를 사용 . | . 3.8 데이타 덩어리(Data Clump) 함께 몰려다니는 데이터의 무리는 그들 자신의 객체로 만들어져야한다. | 이 덩어리를 객체로 바꾸기 위해 이 필드들에 대해 Extract CLass(179)를 사용한다. | 그런다음 관심을 메소드 시그너처로 돌려 Introduce parameter Object(339: 파라미터를 객체로 전환)나 Preserve Whole Obejct(331 파라미터값을 구하는 객체자체를 마라미터로 던진다)을 사용하여 파라미터 리스트를 단순하게 한다. | . 3.9 기본 타입에 대한 강박관념(primitive Obsession) 기본타입과 레코드타입을 객체로 바꿔라. | 각각의 데이타 값에 대해 Replace Data Value with Object(209 : 추가적인 데이타나 동작을 필요로 하는 데이타아이템이 있을경우 데이타를 객체로 바꿔라)를 사용 | 데이터 값이 타입 코드이고, 값이 동작에 영향을 미치지 않는다면 Replace Type Code with Class(255 : 클래스의 동작에 영향을 미치지 않는 숫자로 된 타입코드가 있으면 숫자- 를 클래스로 바꾸어라)를 사용 | 만약 타입타입코드에 의존하는 조건문이 있는 경우에는 Replace Type Code With Subclass , Replace Type Code With State/Strategy(265)를 이용 | 항상 몰려다녀야 할 필드 그룹이 있따면 Extract Class(179) | 파라미터 리스트에서 이런 기본타입을 보면 Introduce Parameter Object(339)를 사용하라. | 배열을 쪼개서 쓰고있는 자신을 발견하거든 Replace Array with Object(220)을 사용하라. | . 3.10 Switch문(Switch Statements) siwtch 문의 본질적인 특징은 중복된다는점 항상 다형성을 생각. | Extract Method(136)을 사용하여 switch문을 뽑아내고, Move Method(170)를 사용하여 다형성이 필요한 클래스로 옮긴다 | 이시점에서 Replace Type Code with Subclasses(261)를 사용할것인지, Replace Type Code with State/Strategy(265)를 사용할것인지 결정해야한다. | 상속구조를 결정했으면 Replace Conditional with Polymorphism(293)을 사용할수 있다. | 만약 하나의 메소드에만 영향을 미치는 몇개의 경우가 있따면 굳이 바꿀 필요가 없다. Replace Parameter with Explict Methods(327) | 조건중 null 이 있는경우 Introduce Null Object(298) | . 3.11 평행 상속 구조(Parallel Inheritance Hierarchies) 산탄총 수술의 특별한 경우 한 클래스의 서브클래스를 만들면 다른곳에도 모두 서브클래스를 만들어주어야하는경우 중복을 제거하는 일반적인 전략은 한쪽 상속구조의 인스턴스가 다른쪽 구조의 인스턴스를 참조하도록 만드는것 . | Move Method(170), Move Filed(175)를 사용 | . 3.12 게으른 클래스(Lazy Class) 충분한 일을 하지 않는 클래스는 삭제되어야한다. | 별로 하는일도 없는 클래스의 서브클래스는 Collapse Hierarchy(392), 거의 필요없는 클래스는 Inline Class(184) | . 3.13 막연한 범용코드(Speculative Generality) . | 별다른 기능이 없는 클래스나 모듈은 Collapse Hierarchy(406p 계층 병합) | 불필요한 위임은 Inline Class(192p) | 메소드에 사용되지 않는 매개변수가 있다면 Remove Parameter(329p) | 메소드 이름이 이상하면 Rename Method(325p) | . 3.14 임시필드(Temporary Field) 사용되지 않는 변수가 왜 있는지를 이해하려는것은 짜증나는일 임시필드는 복잡한 알고리즘이 여러변수를 필요로 할때 흔히 나타남. | Extract Class(187p), Intoduce Null Object(310p) | . 3.15 메시지 체인 (Message Chains) 클라이언트가 객체의 클래스 구조와 결합되어있을때, 객체가 객체에 물어보고.. 이 객체는 다른객체에.. 또 이객체는 다른 객체에.. | Hide Delegate(195p)을 사용. | 객체가 사욧ㅇ되는 코드 부분을 Extract Method(142p)후 Move Method(178p)로 체인 아래로 밀어낼 수 있는 지 여부 검사 후 실시 | . 3.16 과잉 중개 메서드(Middel Man) 메소드의 태반이 다른 클래스로 위임을 하고 있다면 . | Remove Middle Man(198p 클라이언트가 대리 객체를 직접 사용)을 실시. | 일부 메소드에 별 기능이 없다면 Inline Method(150p)를 실시. | 추가동작 필요시 Replace Delegation with Inheritance(404) 실시. 해당 메소드 내용을 호출 객체에 직접 삽입 | 부수적인 기능이 있다면 Replace Inheritance with Deligation (416p 상위클래스에 필드를 작성하고, 모든 메서드가 그 상위클래스에 위임하게 수정한 후 하위클래스 제거)을 적용 | . 3.17 지나친 관여(Inappropriate Intimacy) 클래스끼리의 관계가 지나치게 밀접하게 되어 서로의 private 부분을 알아내느라 과도한 시간을 낭비할 때. | Move Method(178p),Move Field(183p)를 실시, 각 클래스를 분리해서 지나친 관여를 줄인다. | 클래스의 양방향 연결을 단방양으로 전환Change Bidirectional Association to Unidirectional(244p)이 적용가능한지 살피고, | 공통으로 필요한 부분이 있다면 Extract Class(187p)를 사용하여. 공통된 부분을 별도의 클래스로 생성 | 또는 Hide Delegate(195p)을 사용하여 다른 클래스가 중개 메서드 역할을 하게 만듬. | . 3.18 인터페이스가 다른 대용 클래스 (Alternatice Classes with Different Interface) . | 기능은 같은데 다른 시그너쳐를 가지고 있는경우는 Rename Method(325p)을 실시 | 포로토콜이 같아질때까지 Move Method(178p)를 실시하여 기능을 해당클래스에 이동 | 너무 많은 코드를 옮겨야 할 경우 Extract Superclass(397p)를 사용. | . 3.19 미흡한 라이브러리 클래스(Incomplete Library Class) 라이브러리 클래스를 수정하는 것은 보통은 불가능하다. | 라이브러리 클래스가 가지고 있었으면 하는 메소드가 몇개 있다면, Introduce Foreign Method(201p)를 사용하라. | 부가 기능이 많을 경우 Introduce Local Extension(203p)이 필요하다. | . 3.20 데이터 클래스(Data Class) 데이타 보관만 담당. 거의 대부분 다른 클래스에 의해 조작된다. | public 필드는 Encapsulate Field(250p) 적용 | Collection 필드는 Encapsulate Collection(252p) 적용 | 변경되면 안되는 필드에 대해서는 Remove setting Method(357p) 적용 | get/set 메소드가 다른 클래스에서 사용될때 Move Method(178p), Extract Method(142p)사용하여 데이터 클래스로 옮긴후 get/set메소드에 Hide Method(357p) 적용 | . 3.21 방치된 상속물(Refused Bequest) 하위클래스가 기능은 재사용하지만 상위클래스의 인터페이스를 지원하지 않을 때 구린내가 심함. | 계층 구조를 손보는 것보다는 Replace Inheritance with Deligation(416p)을 적용 | . 3.22 주석 (Comments) 주석을 써야 할 것 같은 생각이 들면, 먼저 코드를 리팩토링하여 주석이 불필요하도록 하라. | 코드 구간의 기능을 설명할 수적이 필요하ㄹ 때는 Extract method(142p)를 실시. | 그래도 주석이 필요하다면 Rename Method(325p) 사용 | 시스템의 필수적인 상태에 대해 약간의 규칙을 설명할 필요가 있다면 Introduce Assertion(319p)을 사용. | . ",
    "url": "http://localhost:4000/docs/clipping/java/refactoring/part3/",
    "relUrl": "/docs/clipping/java/refactoring/part3/"
  },"286": {
    "doc": "Patterns",
    "title": "Patterns",
    "content": " ",
    "url": "http://localhost:4000/docs/patterns",
    "relUrl": "/docs/patterns"
  },"287": {
    "doc": "current transaction is aborted, commands ignored until end of transaction block",
    "title": "current transaction is aborted, commands ignored until end of transaction block",
    "content": "[현상] . postgresql - jdbc로 커넥션 맺어서 자바에서 ibatis쿼리 실행하는데 아래와 같은 에러가 났다. current transaction is aborted, commands ignored until end of transaction block . | – The error occurred while applying a parameter map. | – Check the . selectNextOne . | – Check the statement (update procedure failed). | – Cause: org.postgresql.util.PSQLException: ERROR: current transaction is aborted, commands ignored until end of transaction block | . at com.ibatis.sqlmap.engine.mapping.statement.MappedStatement.executeQueryWithCallback(MappedStatement.java:201) . at com.ibatis.sqlmap.engine.mapping.statement.MappedStatement.executeQueryForObject(MappedStatement.java:120) . at com.ibatis.sqlmap.engine.impl.SqlMapExecutorDelegate.queryForObject(SqlMapExecutorDelegate.java:527) . at com.ibatis.sqlmap.engine.impl.SqlMapExecutorDelegate.queryForObject(SqlMapExecutorDelegate.java:502) . at com.ibatis.sqlmap.engine.impl.SqlMapSessionImpl.queryForObject(SqlMapSessionImpl.java:106) . at org.springframework.orm.ibatis.SqlMapClientTemplate$1.doInSqlMapClient(SqlMapClientTemplate.java:270) . at org.springframework.orm.ibatis.SqlMapClientTemplate.execute(SqlMapClientTemplate.java:200) . … 52 more . [원인] . 위에 처럼 나오면 쿼리에 문법적 오류로 인하여 현재 트랜잭션은 폐기된다는 뜻 . 내 경우는 selectNextOne쿼리가 잘못되었음 . ",
    "url": "http://localhost:4000/docs/errors/postgres1/",
    "relUrl": "/docs/errors/postgres1/"
  },"288": {
    "doc": "Please log in (using, e.g., \"su\") as the (unprivileged) user that will",
    "title": "Please log in (using, e.g., \"su\") as the (unprivileged) user that will",
    "content": "[현상] . Please log in (using, e.g., “su”) as the (unprivileged) user that will . [원인] . 유닉스에 postgresql을 설치하고 나서 su로 로긴해서 ./pg_ctl로 서비스를 시작하려하는데 저런 에러가… . 일본 구글에서 해답을 찾았다. 블로그 http://nobuneko.com/blog/archives/2011/05/postgresqlinitdb_cannot_be_run.html . 해석 . 솔라리스 등에서 initdb를 실행하려고 하면, initdb: cannot be run as root라고 하는 에러메세지가 표시되고 initdb를 실행시킬 수 없게 된다 . 에러메세지를 읽으면, initdb는 root유저로 실행시킬 수 없다는 것을 알게 된다. 이 에러를 해결하려면 root 유저 외의 사용자로 initdb를 실행시키면 된다. 예를 들면, su - postgres에서 postgres유저를 만드니까 initdb를 postgres로 실행시키면된다. 같은 케이스는 아니지만 나도 su - postgres로 올리니까 해결됨. ",
    "url": "http://localhost:4000/docs/errors/postgres2/",
    "relUrl": "/docs/errors/postgres2/"
  },"289": {
    "doc": "Promise rejected SyntaxError Unexpected end of input",
    "title": "problem",
    "content": ". | api를 get방식으로 호출해서 데이터를 리턴받아 화면에 표시하는 간단한 작업이다. | fetch를 통해서 호출하면 개발자도구로 보면 200인데도, response.ok가 false로 리턴되어있다. (response.ok는 400, 500일 때 false로 됨) | . fetch('http://localhost:7070/test', { method: 'GET', mode: 'no-cors', credentials: 'same-origin', headers: { 'Content-Type': 'application/json', Accept: \"application/json\", \"Access-Control-Allow-Origin\": \"*\", } }).then((response) =&gt; { console.log(response.json()); if (response.ok) { return response.json(); } else { if (!response.ok) { console.log('status --'+response.status); } } }) . try. response를 ok여부와 상관없이 json() . Scheduler.vue?d1c4:53 **Promise {&lt;rejected&gt;: SyntaxError: Unexpected end of input** at eval (webpack-internal:///./node_modules/cache-loader/d…}[[Prototype]]: Promise[[PromiseState]]: \"rejected\"[[PromiseResult]]: SyntaxError: Unexpected end of input at eval (webpack-internal:///./node_modules/cache-loader/dist/cjs.js?!./node_modules/babel-loader/lib/index.js!./node_modules/cache-loader/dist/cjs.js?!./node_modules/vue-loader-v16/dist/index.js?!./src/components/survey/Scheduler.vue?vue&amp;type=script&amp;lang=js:31:30)message: \"Unexpected end of input\"stack: \"SyntaxError: Unexpected end of input\\n at eval (webpack-internal:///./node_modules/cache-loader/dist/cjs.js?!./node_modules/babel-loader/lib/index.js!./node_modules/cache-loader/dist/cjs.js?!./node_modules/vue-loader-v16/dist/index.js?!./src/components/survey/Scheduler.vue?vue&amp;type=script&amp;lang=js:31:30)\"[[Prototype]]: Error Scheduler.vue?d1c4:61 status --0 Scheduler.vue?d1c4:80 SyntaxError: Unexpected end of input (at Scheduler.vue?d1c4:64:1) at eval (Scheduler.vue?d1c4:64:1) Scheduler.vue?d1c4:53 Uncaught (in promise) SyntaxError: Unexpected end of input (at Scheduler.vue?d1c4:53:1) at eval (Scheduler.vue?d1c4:53:1) eval @ Scheduler.vue?d1c4:53 . ",
    "url": "http://localhost:4000/docs/errors/promise_rejected_syntaxError/#problem",
    "relUrl": "/docs/errors/promise_rejected_syntaxError/#problem"
  },"290": {
    "doc": "Promise rejected SyntaxError Unexpected end of input",
    "title": "cause",
    "content": ". | 구글링 해보면 원인은 다양한 것 같지만, cors에 대한 처리를 해주면 된다. | . ",
    "url": "http://localhost:4000/docs/errors/promise_rejected_syntaxError/#cause",
    "relUrl": "/docs/errors/promise_rejected_syntaxError/#cause"
  },"291": {
    "doc": "Promise rejected SyntaxError Unexpected end of input",
    "title": "resolve",
    "content": ". | 백엔드가 spring boot로 되어있어서 cors에 대한 config bean에 ignore path로 등록해줬다. | . ",
    "url": "http://localhost:4000/docs/errors/promise_rejected_syntaxError/#resolve",
    "relUrl": "/docs/errors/promise_rejected_syntaxError/#resolve"
  },"292": {
    "doc": "Promise rejected SyntaxError Unexpected end of input",
    "title": "Promise rejected SyntaxError Unexpected end of input",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/promise_rejected_syntaxError/",
    "relUrl": "/docs/errors/promise_rejected_syntaxError/"
  },"293": {
    "doc": "Could not locate PropertySource and the fail fast property is set, failing",
    "title": "Could not locate PropertySource and the fail fast property is set, failing",
    "content": "error . java.lang.IllegalStateException: Could not locate PropertySource and the fail fast property is set, failing at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:155) ~[spring-cloud-config-client-2.2.8.RELEASE.jar!/:2.2.8.RELEASE] at org.springframework.cloud.bootstrap.config.PropertySourceLocator.locateCollection(PropertySourceLocator.java:52) ~[spring-cloud-context-2.2.9.RELEASE.jar!/:2.2.9.RELEASE] at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locateCollection(ConfigServicePropertySourceLocator.java:170) ~[spring-cloud-config-client-2.2.8.RELEASE.jar!/:2.2.8.RELEASE] at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator$$FastClassBySpringCGLIB$$fa44b2a.invoke(&lt;generated&gt;) ~[spring-cloud-config-client-2.2.8.RELEASE.jar!/:2.2.8.RELEASE] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) ~[spring-core-5.2.15.RELEASE.jar!/:5.2.15.RELEASE] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:779) ~[spring-aop-5.2.15.RELEASE.jar!/:5.2.15.RELEASE] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) ~[spring-aop-5.2.15.RELEASE.jar!/:5.2.15.RELEASE] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) ~[spring-aop-5.2.15.RELEASE.jar!/:5.2.15.RELEASE] at org.springframework.retry.interceptor.RetryOperationsInterceptor$1.doWithRetry(RetryOperationsInterceptor.java:91) ~[spring-retry-1.2.5.RELEASE.jar!/:na] at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:287) ~[spring-retry-1.2.5.RELEASE.jar!/:na] at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:164) ~[spring-retry-1.2.5.RELEASE.jar!/:na] at org.springframework.retry.interceptor.RetryOperationsInterceptor.invoke(RetryOperationsInterceptor.java:118) ~[spring-retry-1.2.5.RELEASE.jar!/:na] at org.springframework.retry.annotation.AnnotationAwareRetryOperationsInterceptor.invoke(AnnotationAwareRetryOperationsInterceptor.java:153) ~[spring-retry-1.2.5.RELEASE.jar!/:na] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.2.15.RELEASE.jar!/:5.2.15.RELEASE] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) ~[spring-aop-5.2.15.RELEASE.jar!/:5.2.15.RELEASE] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:692) ~[spring-aop-5.2.15.RELEASE.jar!/:5.2.15.RELEASE] at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator$$EnhancerBySpringCGLIB$$537fc30a.locateCollection(&lt;generated&gt;) ~[spring-cloud-config-client-2.2.8.RELEASE.jar!/:2.2.8.RELEASE] at org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration.initialize(PropertySourceBootstrapConfiguration.java:98) ~[spring-cloud-context-2.2.9.RELEASE.jar!/:2.2.9.RELEASE] at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:623) [spring-boot-2.3.12.RELEASE.jar!/:2.3.12.RELEASE] at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:367) [spring-boot-2.3.12.RELEASE.jar!/:2.3.12.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:311) [spring-boot-2.3.12.RELEASE.jar!/:2.3.12.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1247) [spring-boot-2.3.12.RELEASE.jar!/:2.3.12.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1236) [spring-boot-2.3.12.RELEASE.jar!/:2.3.12.RELEASE] at spectra.attic.talk.crema.CremaApplication.main(CremaApplication.java:22) [classes!/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_292] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_292] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_292] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_292] at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:49) [crema-boot-3.1.0-exec.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:108) [crema-boot-3.1.0-exec.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:58) [crema-boot-3.1.0-exec.jar:na] at org.springframework.boot.loader.PropertiesLauncher.main(PropertiesLauncher.java:467) [crema-boot-3.1.0-exec.jar:na] Caused by: org.springframework.web.client.HttpServerErrorException$InternalServerError: 500 : [{\"timestamp\":\"2022-04-19T23:09:15.574+00:00\",\"status\":500,\"error\":\"Internal Server Error\",\"message\":\"\",\"path\":\"/config/crema/prod\"}] at org.springframework.web.client.HttpServerErrorException.create(HttpServerErrorException.java:100) ~[spring-web-5.2.15.RELEASE.jar!/:5.2.15.RELEASE] at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:186) ~[spring-web-5.2.15.RELEASE.jar!/:5.2.15.RELEASE] at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:125) ~[spring-web-5.2.15.RELEASE.jar!/:5.2.15.RELEASE] at org.springframework.web.client.ResponseErrorHandler.handleError(ResponseErrorHandler.java:63) ~[spring-web-5.2.15.RELEASE.jar!/:5.2.15.RELEASE] at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:780) ~[spring-web-5.2.15.RELEASE.jar!/:5.2.15.RELEASE] at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:738) ~[spring-web-5.2.15.RELEASE.jar!/:5.2.15.RELEASE] at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:672) ~[spring-web-5.2.15.RELEASE.jar!/:5.2.15.RELEASE] at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:581) ~[spring-web-5.2.15.RELEASE.jar!/:5.2.15.RELEASE] at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.getRemoteEnvironment(ConfigServicePropertySourceLocator.java:271) ~[spring-cloud-config-client-2.2.8.RELEASE.jar!/:2.2.8.RELEASE] at org.springframework.cloud.config.client.ConfigServicePropertySourceLocator.locate(ConfigServicePropertySourceLocator.java:114) ~[spring-cloud-config-client-2.2.8.RELEASE.jar!/:2.2.8.RELEASE] ... 31 common frames omitted . cause . yml파일에 오타가 있어서 발생했다. 암튼 yml파일을 읽어올수 없을 때 발생하는 것으로 location이 올바른지 profile에 맞는 yml인지 체크필요 . ",
    "url": "http://localhost:4000/docs/errors/propertySourceError/",
    "relUrl": "/docs/errors/propertySourceError/"
  },"294": {
    "doc": "Programming Foundations with Python 후기",
    "title": "학습후기",
    "content": "파이썬 무식자도 기초를 잡아주는 비기너 강좌입니다. 총 7개의 주제로 이뤄져 있구요. 유다시티의 특징인 퀴즈가 많습니다. 누군가에게 설명하고 캡쳐해서 올리라는 퀴즈도 있습니다… 하지만 꼭 안그래도 됩니다. 저 말고도 많은 이들이 가르칠 사람 없어서, 혼자 학습한 내용을 캡쳐해서 올리기도 합니다. 아니면 블로그에 올리고 그것을 캡쳐해도 괜찮습니다. 어렵지 않게 초심자도 배울수 있는 커리큘럼입니다. 선수학습은 필요없구요. 자바나  OOP에 대한 개념이 있다면 더 빠르게 이해할 수 있을 듯 합니다. ",
    "url": "http://localhost:4000/docs/mooc/udacity/python/#%ED%95%99%EC%8A%B5%ED%9B%84%EA%B8%B0",
    "relUrl": "/docs/mooc/udacity/python/#학습후기"
  },"295": {
    "doc": "Programming Foundations with Python 후기",
    "title": "강의내용 정리",
    "content": "12강. fetch vs axios . ",
    "url": "http://localhost:4000/docs/mooc/udacity/python/#%EA%B0%95%EC%9D%98%EB%82%B4%EC%9A%A9-%EC%A0%95%EB%A6%AC",
    "relUrl": "/docs/mooc/udacity/python/#강의내용-정리"
  },"296": {
    "doc": "Programming Foundations with Python 후기",
    "title": "Programming Foundations with Python 후기",
    "content": " ",
    "url": "http://localhost:4000/docs/mooc/udacity/python/",
    "relUrl": "/docs/mooc/udacity/python/"
  },"297": {
    "doc": "Quality Practice",
    "title": "Quality Practice",
    "content": " ",
    "url": "http://localhost:4000/docs/quality",
    "relUrl": "/docs/quality"
  },"298": {
    "doc": "Refactoring",
    "title": "reference",
    "content": "Refactoring.guru . 자바로 구현한 디자인 패턴 샘플 프로젝트 . 객체 지향, TDD, 리팩토링 학습 (박재성) . ",
    "url": "http://localhost:4000/docs/clipping/java/refactoring/refactoring/#reference",
    "relUrl": "/docs/clipping/java/refactoring/refactoring/#reference"
  },"299": {
    "doc": "Refactoring",
    "title": "Refactoring",
    "content": "2015년 리팩토링 스터디하면서 발표하기 위해 정리해던 내용과 다른 팀원이 준비한 내용 . ",
    "url": "http://localhost:4000/docs/clipping/java/refactoring/refactoring/",
    "relUrl": "/docs/clipping/java/refactoring/refactoring/"
  },"300": {
    "doc": "RejectedExecutionException",
    "title": "RejectedExecutionException",
    "content": "test scenario . | 1대를 대상으로 크레마 성능시나리오 돌림. | Xms256m -Xmx256m로 springboot 서비스 올림 | 인입되는 동시 메시지 수 20개 | 크레마 thread는 pool 100개, max 100개, queue 10개로 설정 | . error . Exception in KakaoMessageController.message() with cause = 'java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.FutureTask@249a9d22 rejected from java.util.concurrent.ThreadPoolExecutor@3b96a13d [Running, pool size = 100, active threads = 1, queued tasks = 10, completed tasks = 9975]' and exception = 'Executor [java.util.concurrent.ThreadPoolExecutor@3b96a13d [Running, pool size = 100, active threads = 8, queued tasks = 5, completed tasks = 9975]] did not accept task: org.springframework.cloud.sleuth.instrument.async. TraceCallable@aaea32a'org.springframework.core.task.TaskRejectedException: Executor [java.util.concurrent.ThreadPoolExecutor@3b96a13d [Running, pool size = 100, active threads = 8, queued tasks = 5, completed tasks = 9975]] . problem . 서버상태) cpu는 정상, 다른서비스도 정상 . 조치) . | jvm메모리도 작은 상황에 큐가 max가 되어서 rejectException이 발생한 것으로 보임 . | 방법1. rejectexceptionhandler에 policy를 준다 (https://stackoverflow.com/questions/49290054/taskrejectedexception-in-threadpooltaskexecutor) . | callreturnpolicy를 쓰면 호출한 쓰레드로 동작을 하게하고, 그 쓰레드가 종료될 때까지 다른 호출은 지연된다는 문제 | queue가 꽉찬 상황에서 처리한다해도, 문제가 될 것으로 보임. queue가 왜 꽉 차서 안사라지는지 확인이 필요 . | 20개의 쓰레드가 동시에 호출된 문제. | . | . | . | queue사이즈는 적당한가?? . | https://stackoverflow.com/a/43874563/14257397 | acceptable time range / time to complete a task. | . | . conclusion . | queue size를 50으로 올린 후, jmx를 1024로 상향 | 반드시 maxpool만큼 채워서 쓰는게 아니라고 함. 즉, 실제로 corePoolSize가 스레드 개수보다 많다고 해서 maximumPoolSize 개수 까지 바로 생성하지 않는다. 그 전에 큐(workQueue)에 담고 대기한다. (구현체마다 다르지만, 일반적으로) | 그리고 나서 workQueue에도 담을 공간이 부족하다면 그때 maximumPoolSize 까지 스레드를 늘려 작업을 한다. 그 후 keepAliveTime에 도달하면 다시 corePoolSize 로 유지 된다. | 만약 queue가 다 찼으면 maxpoolsize만큼 생성한다. | 그러다 모든 쓰레드가 사용중이고 queue도 full이면 거부된다. | . ",
    "url": "http://localhost:4000/docs/errors/rejectedException/",
    "relUrl": "/docs/errors/rejectedException/"
  },"301": {
    "doc": "Feign Retry",
    "title": "feign retry",
    "content": ". | 전역의 ribbon설정을 안쓰고자 함 | docker의 depends on도 방법 | . healthcheck: test: [“CMD”, “curl”, “-f”, “http://localhost:8040/actuator/health”] interval: 10s timeout: 5s retries: 10 . | feignclient 내부 configuration으로 Retryer를 Bean으로 등록해서 backoff제어한다. | . 참고) . 우아한 feign 적용기 - 우아한형제들 기술 블로그 . ",
    "url": "http://localhost:4000/docs/msa/feign/retry/#feign-retry",
    "relUrl": "/docs/msa/feign/retry/#feign-retry"
  },"302": {
    "doc": "Feign Retry",
    "title": "Feign Retry",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/feign/retry/",
    "relUrl": "/docs/msa/feign/retry/"
  },"303": {
    "doc": "SonarQube",
    "title": "SonarQube",
    "content": "https://rules.sonarsource.com/java 기준으로 검출된 코드에 대해서 정리한 것입니다. ",
    "url": "http://localhost:4000/docs/quality/sonarqube/sonarqube/",
    "relUrl": "/docs/quality/sonarqube/sonarqube/"
  },"304": {
    "doc": "SpelEvaluationException EL1008E CacheExpressionRootObject",
    "title": "error log",
    "content": "org.springframework.expression.spel.SpelEvaluationException: EL1008E: Property or field 'license_key' cannot be found on object of type 'org.springframework.cache.interceptor.CacheExpressionRootObject' - maybe not public or not valid? at org.springframework.expression.spel.ast.PropertyOrFieldReference.readProperty(PropertyOrFieldReference.java:217) at org.springframework.expression.spel.ast.PropertyOrFieldReference.getValueInternal(PropertyOrFieldReference.java:104) at org.springframework.expression.spel.ast.PropertyOrFieldReference.getValueInternal(PropertyOrFieldReference.java:91) . 문제 코드 . @Cacheable(value = \"crema-btalk-license-find\", key = \"license_key\", unless = \"#result == null\") public LicenseRdo find() { . ",
    "url": "http://localhost:4000/docs/errors/spelEvaluationException/#error-log",
    "relUrl": "/docs/errors/spelEvaluationException/#error-log"
  },"305": {
    "doc": "SpelEvaluationException EL1008E CacheExpressionRootObject",
    "title": "cause",
    "content": "key를 string값으로 주고 싶다면 single quote를 줘야한다. ",
    "url": "http://localhost:4000/docs/errors/spelEvaluationException/#cause",
    "relUrl": "/docs/errors/spelEvaluationException/#cause"
  },"306": {
    "doc": "SpelEvaluationException EL1008E CacheExpressionRootObject",
    "title": "solved",
    "content": "@Cacheable(value = \"crema-btalk-license-find\", key = \" 'license_key' \", unless = \"#result == null\") public LicenseRdo find() { . 아니면, 메소드명과 동일하게 하거나 . @Cacheable(key = \"#root.methodName\") . 아니면, 전역변수로 선언하거나 . public static final String KEY = \"cacheKey\"; @Override @Cacheable(value = \"cacheName\", key = \"#root.target.KEY\") . ",
    "url": "http://localhost:4000/docs/errors/spelEvaluationException/#solved",
    "relUrl": "/docs/errors/spelEvaluationException/#solved"
  },"307": {
    "doc": "SpelEvaluationException EL1008E CacheExpressionRootObject",
    "title": "reference",
    "content": "What is the best way of defining key for @Cacheable annotation for Spring . ",
    "url": "http://localhost:4000/docs/errors/spelEvaluationException/#reference",
    "relUrl": "/docs/errors/spelEvaluationException/#reference"
  },"308": {
    "doc": "SpelEvaluationException EL1008E CacheExpressionRootObject",
    "title": "SpelEvaluationException EL1008E CacheExpressionRootObject",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/spelEvaluationException/",
    "relUrl": "/docs/errors/spelEvaluationException/"
  },"309": {
    "doc": "Failed to instantiate [javax.servlet.Filter]...",
    "title": "Failed to instantiate [javax.servlet.Filter]...",
    "content": "Failed to instantiate [javax.servlet.Filter]: Factory method ‘springSecurityFilterChain’ threw exception; nested exception is java.lang.NullPointerException 에러 . problems . springboot로 application 올리다가 에러 발생 . error log . 07:54:50.971 main WARN stractApplicationContext:557 refresh **Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'springSecurityFilterChain' defined in class path resource** [org/springframework/security/config/annotation/web/configuration/WebSecurityConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [javax.servlet.Filter]: Factory method 'springSecurityFilterChain' threw exception; nested exception is java.lang.NullPointerException 07:54:54.008 main WARN o.a.j.l.DirectJDKLog:173 log The web application [ROOT] appears to have started a thread named [RxIoScheduler-1 (Evictor)] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread: java.base@12.0.2/jdk.internal.misc.Unsafe.park(Native Method) java.base@12.0.2/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:235) java.base@12.0.2/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2123) java.base@12.0.2/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182) java.base@12.0.2/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899) java.base@12.0.2/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1054) java.base@12.0.2/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1114) java.base@12.0.2/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) java.base@12.0.2/java.lang.Thread.run(Thread.java:835) 07:54:54.037 main ERROR o.s.b.SpringApplication :821 reportFailureApplication run failed org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'springSecurityFilterChain' defined in class path resource [org/springframework/security/config/annotation/web/configuration/WebSecurityConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [javax.servlet.Filter]: Factory method 'springSecurityFilterChain' threw exception; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:627) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:456) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1321) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1160) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:307) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:845) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:742) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:389) at org.springframework.boot.SpringApplication.run(SpringApplication.java:311) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1213) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1202) at xxx.XXXApplication.main(XXXApplication.java:18) Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [javax.servlet.Filter]: Factory method 'springSecurityFilterChain' threw exception; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:622) ... 21 common frames omitted **Caused by: java.lang.NullPointerException: null** at xxx.WebSecurityConfig.configure(**WebSecurityConfig.java:19**) at xxx.WebSecurityConfig.configure(WebSecurityConfig.java:10) at xxx.WebSecurityConfig$$EnhancerBySpringCGLIB$$5aba962.configure(&lt;generated&gt;) at org.springframework.security.config.annotation.AbstractConfiguredSecurityBuilder.configure(AbstractConfiguredSecurityBuilder.java:384) at org.springframework.security.config.annotation.AbstractConfiguredSecurityBuilder.doBuild(AbstractConfiguredSecurityBuilder.java:330) at org.springframework.security.config.annotation.AbstractSecurityBuilder.build(AbstractSecurityBuilder.java:41) at org.springframework.security.config.annotation.web.configuration.WebSecurityConfiguration.springSecurityFilterChain(WebSecurityConfiguration.java:104) at org.springframework.security.config.annotation.web.configurationWebSecurityConfiguration$$EnhancerBySpringCGLIB$$3d7c30de.CGLIB$springSecurityFilterChain$3(&lt;generated&gt;) at org.springframework.security.config.annotation.web.configuration.WebSecurityConfiguration$$EnhancerBySpringCGLIB$$3d7c30de$$FastClassBySpringCGLIB$$8dd86ea6.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:244) at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:363) at org.springframework.security.config.annotation.web.configuration.WebSecurityConfiguration$$EnhancerBySpringCGLIB$$3d7c30de.springSecurityFilterChain(&lt;generated&gt;) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:567) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ... 22 common frames omitted Process finished with exit code 1 . cause . 에러의 npe부분을 보면 springboot올릴때, WebSecurityConfig를 읽어가도록 했는데. WebSecurityConfig에서 읽어갈 설정이 yml에 없어서 널포인트 나는 것…. solved . 본인의 경우는 profile을 달리했는데, 그걸 서비스 올릴때 지정안해줘서 디폴트 yml보고 올라가다가 해당 security설정이 없어서 그런거라…profile을 지정해주면 된다. reference . stackoverflow.com/a/4952938 참고 . ",
    "url": "http://localhost:4000/docs/errors/spring1/",
    "relUrl": "/docs/errors/spring1/"
  },"310": {
    "doc": "PathVariable annotation was empty on param 0.",
    "title": "PathVariable annotation was empty on param 0.",
    "content": "cause and solution . @PathVariable(“id”) 일케 해야하는데, 그냥 @PathVariable이것만 함 . error log . org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'aaa' defined in file [aaa.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'bbb' defined in file [bbb.class]: Unsatisfied dependency expressed through constructor parameter 9; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'CCCClient': FactoryBean threw exception on object creation; nested exception is java.lang.IllegalStateException: **PathVariable annotation was empty on param 0**. at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:769) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:218) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1341) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1187) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:845) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140) CCCOperatorClient': FactoryBean threw exception on object creation; nested exception is java.lang.IllegalStateException: PathVariable annotation was empty on param 0. at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:769) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:218) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1341) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1187) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:277) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1251) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1171) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:857) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:760) ... 19 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'CCCOperatorClient': FactoryBean threw exception on object creation; nested exception is java.lang.IllegalStateException: PathVariable annotation was empty on param 0. at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:178) at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:101) at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1674) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getObjectForBeanInstance(AbstractAutowireCapableBeanFactory.java:1249) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:257) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:277) at org.springframework.beans.factory.support.DefaultListableBeanFactory.addCandidateEntr(DefaultListableBeanFactory.java:1474) at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidate(DefaultListableBeanFactory.java:1431) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1214) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1171) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:857) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:760) ... 33 common frames omitted Caused by: java.lang.IllegalStateException: PathVariable annotation was empty on param 0. at feign.Util.checkState(Util.java:130) at org.springframework.cloud.openfeign.annotation.PathVariableParameterProcessor.processArgument(PathVariableParameterProcessor.java:52) at org.springframework.cloud.openfeign.support.SpringMvcContract.processAnnotationsOnParameter(SpringMvcContract.java:292) at feign.Contract$BaseContract.parseAndValidateMetadata(Contract.java:110) at org.springframework.cloud.openfeign.support.SpringMvcContract.parseAndValidateMetadata(SpringMvcContract.java:188) at feign.Contract$BaseContract.parseAndValidatateMetadata(Contract.java:66) at feign.hystrix.HystrixDelegatingContract.parseAndValidatateMetadata(HystrixDelegatingContract.java:47) at feign.ReflectiveFeign$ParseHandlersByName.apply(ReflectiveFeign.java:154) at feign.ReflectiveFeign.newInstance(ReflectiveFeign.java:52) at feign.Feign$Builder.target(Feign.java:251) at org.springframework.cloud.openfeign.HystrixTargeter.target(HystrixTargeter.java:55) at org.springframework.cloud.openfeign.FeignClientFactoryBean.loadBalance(FeignClientFactoryBean.java:238) at org.springframework.cloud.openfeign.FeignClientFactoryBean.getTarget(FeignClientFactoryBean.java:267) at org.springframework.cloud.openfeign.FeignClientFactoryBean.getObject(FeignClientFactoryBean.java:247) at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:171) ... 45 common frames omitted . ",
    "url": "http://localhost:4000/docs/errors/spring2/",
    "relUrl": "/docs/errors/spring2/"
  },"311": {
    "doc": "How to use Feign @SpringQueryMap",
    "title": "feign을 통해 @SpringQueryMap 사용",
    "content": ". ::요구사항 . 고객의 과거 상담 이력을 조회해서 다른 서비스로 전달하는 로직 . :: History API . @RestController @RequestMapping(\"histories\") public class HistoryQueryResource { private final HistoryQueryService historyQueryService; @GetMapping public HistoryList findAll( @SpringQueryMap HistoryQuery historyQuery ) { return historyQueryService.findAll(historyQuery); } } . ::Thirdparty . @FeignClient( contextId = \"HistoryQueryClient\", name = \"api\", configuration = {FeignConfiguration.class, FeignLoggerLevelConfiguration.class}, primary = false ) public interface HistoryQueryClient{ @GetMapping(\"histories\") HistoryList findAll(@SpringQueryMap HistoryQuery historyQuery); } . :: 문제 . | 컨트롤러가 Mapping파라미터로 선언한 HistoryQuery에 ArrayList, Map타입이 아니면 맵핑이 되지 않는 오류발생 | . @Builder @NoArgsConstructor(access = AccessLevel.PRIVATE) @AllArgsConstructor @Getter @ToString public class HistoryQuery implements JsonSerializable { @Builder.Default private int offset = 0; // --&gt; API서버로 맵핑되지 않음 @Builder.Default private int limit = 1; // --&gt; API서버로 맵핑되지 않음 @Builder.Default private IdList channelIds = IdList.empty(); // --&gt; 맵핑ok @Builder.Default private IdList status = IdList.empty(); // --&gt; 맵핑ok @Builder.Default private String customerId = StringUtils.EMPTY; // --&gt; API서버로 맵핑되지 않음 } . :: 문제 . | 호출 URL에는 문제가 없지만, History API 서버에는 offset, limit, customerId가 찍히지 않음 . -&gt; GET http://api/histories?offset=0&amp;status=closed&amp;limit=1 &amp;customerId=tester&amp;channelIds=kakao . | feign doc . | . Spring Cloud OpenFeign . doc을 보면, POJO, Map 모두 지원한다고 되어있지만, 테스트해보니 리스트나 맵이 아니면 안됨 . :: 문제해결 . | Param.Expander를 사용하는 방법 —&gt; 받는 쪽이 array, map이 아니면 이것도 안됨 | . Feign Client does not resolve Query parameter . | API 스펙을 변경하는 방법…. | . ",
    "url": "http://localhost:4000/docs/msa/feign/springQueryMap/#feign%EC%9D%84-%ED%86%B5%ED%95%B4-springquerymap-%EC%82%AC%EC%9A%A9",
    "relUrl": "/docs/msa/feign/springQueryMap/#feign을-통해-springquerymap-사용"
  },"312": {
    "doc": "How to use Feign @SpringQueryMap",
    "title": "How to use Feign @SpringQueryMap",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/feign/springQueryMap/",
    "relUrl": "/docs/msa/feign/springQueryMap/"
  },"313": {
    "doc": "Spring boot Admin - Quartz Scheduler",
    "title": "to do list",
    "content": ". | quartz scheduler 서비스의 관리 콘솔 UI 추가 | spring admin에 커스텀 메뉴로 추가되도록 한다. (https://codecentric.github.io/spring-boot-admin/current/#customizing-custom-views) | . ",
    "url": "http://localhost:4000/docs/etc/spring_boot_admin_quartz/#to-do-list",
    "relUrl": "/docs/etc/spring_boot_admin_quartz/#to-do-list"
  },"314": {
    "doc": "Spring boot Admin - Quartz Scheduler",
    "title": "try",
    "content": ". | (0806-0807)git repository 생성하고 간단 화면 구성 | . ",
    "url": "http://localhost:4000/docs/etc/spring_boot_admin_quartz/#try",
    "relUrl": "/docs/etc/spring_boot_admin_quartz/#try"
  },"315": {
    "doc": "Spring boot Admin - Quartz Scheduler",
    "title": "Spring boot Admin - Quartz Scheduler",
    "content": " ",
    "url": "http://localhost:4000/docs/etc/spring_boot_admin_quartz/",
    "relUrl": "/docs/etc/spring_boot_admin_quartz/"
  },"316": {
    "doc": "spring config additional-location not working",
    "title": "to do..",
    "content": "변경가능성이 있는 외부 접속정보는 git에 push하고 있지 않고 있어서 . 품질 서버에서 테스트할 때마다 접속정보를 yml에 설정해야 하는 불편함이 있었다. 접속 정보에 해당하는 property만 별도의 yml파일에 정의하고 . application 띄울 때 덮어씌워지게 한다. ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_config1/#to-do",
    "relUrl": "/docs/msa/spring-cloud/spring_config1/#to-do"
  },"317": {
    "doc": "spring config additional-location not working",
    "title": "problem",
    "content": "java -Xms1024m -Xmx1024m -Dspring.profiles.active=oracle -Dspring.config.additional-location=file:/module/crema.yml -jar crema-boot-4.0.0.DEV-SNAPSHOT-exec.jar . module폴더에 별도의 yml을 정의해서 띄웠는데, override되지 않았다.. 안되는 원인을 한참을 찾았다.. spring버전부터 먼저 체크해서 doc을 봤어야했다…. ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_config1/#problem",
    "relUrl": "/docs/msa/spring-cloud/spring_config1/#problem"
  },"318": {
    "doc": "spring config additional-location not working",
    "title": "solution",
    "content": "spring boot 2.3.x . spring.cloud.config.allowOverride: true spring.cloud.config.overrideNone: true . 결론은 spring cloud설정을 해줘야 한다. 해당 설정은 설정파일이 remote로 가져와야할 때 해주는 설정인데 상세 옵션은 아래와 같다. yml도 naming이 중요하다고 느껴지는 부분이다. (설정 key명칭이 기능이랑 매치가 안되는 건 나만의 생각인지 모르겠다) . spring.cloud.config.allowOverride . | true이면 override (기본값) | . spring.cloud.config.overrideNone . | true이면 모든 로컬 PropertySource가 Remote Properties로 덮어쓰게 됨 (기본값 false) | . spring.cloud.config.overrideSystemProperties . | false이면 시스템 환경설정도 override된다 (기본값 true) | . spring boot 2.4.x . 2.4버전 이후는 config 우선순위 설정이 변경되었다. option도 생기고 .. ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_config1/#solution",
    "relUrl": "/docs/msa/spring-cloud/spring_config1/#solution"
  },"319": {
    "doc": "spring config additional-location not working",
    "title": "reference",
    "content": "[Spring] Spring Cloud Config 설정 파일 적용 . [SPRING BOOT] 외부 설정 및 우선순위 (Externalized Configuration and priorities) . What is the loading precedence for properties from Spring Cloud Config? . Spring Cloud . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_config1/#reference",
    "relUrl": "/docs/msa/spring-cloud/spring_config1/#reference"
  },"320": {
    "doc": "spring config additional-location not working",
    "title": "spring config additional-location not working",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_config1/",
    "relUrl": "/docs/msa/spring-cloud/spring_config1/"
  },"321": {
    "doc": "spring boot and cloud version up",
    "title": "spring 업그레이드 대응개발",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade/#spring-%EC%97%85%EA%B7%B8%EB%A0%88%EC%9D%B4%EB%93%9C-%EB%8C%80%EC%9D%91%EA%B0%9C%EB%B0%9C",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade/#spring-업그레이드-대응개발"
  },"322": {
    "doc": "spring boot and cloud version up",
    "title": "summary",
    "content": ". | 버전 변경 . | Spring Boot : 2.3.12.RELEASE -&gt; 2.7.3 | Spring Cloud : Hoxton.SR12 -&gt; 2021.03 | . | 주요 작업 . | Hystrix, Ribbon 이 기존 Spring Clou Netflix 에서 지원되지 않고, 다른 스택으로 대체됨에 따라 기존에 의존하고 있던 코드의 변경 및 설정 변경작업 | . | . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade/#summary",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade/#summary"
  },"323": {
    "doc": "spring boot and cloud version up",
    "title": "작업 내용",
    "content": "change netflix-ribbon to spring-cloud-loadbalancer change Hystrix to Resilience4j change Feign And Loadbalancer Retry 기타 . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade/#%EC%9E%91%EC%97%85-%EB%82%B4%EC%9A%A9",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade/#작업-내용"
  },"324": {
    "doc": "spring boot and cloud version up",
    "title": "reference",
    "content": "https://sabarada.tistory.com/204 . https://luvstudy.tistory.com/150 . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade/#reference",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade/#reference"
  },"325": {
    "doc": "spring boot and cloud version up",
    "title": "spring boot and cloud version up",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade/",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade/"
  },"326": {
    "doc": "spring boot and cloud version up - etc",
    "title": "Actuator",
    "content": ". | endpoint에서 dash가 사라졌다 . | bus-refresh가 busrefresh로 바뀌었나는 것 | bus-env도 busenv로 바뀌었다는 것 | service-registry도 serviceregistry로 | . | . curl -X POST http://localhost:8888/actuator/busrefresh . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_etc/#actuator",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_etc/#actuator"
  },"327": {
    "doc": "spring boot and cloud version up - etc",
    "title": "spring boot and cloud version up - etc",
    "content": "breaking changes를 보면 . https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2020.0-Release-Notes#breaking-changes-1 . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_etc/",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_etc/"
  },"328": {
    "doc": "change Hystrix to Resilience4j",
    "title": "change note",
    "content": ". | exception에 대한 처리 변경 | . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_resilience4j/#change-note",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_resilience4j/#change-note"
  },"329": {
    "doc": "change Hystrix to Resilience4j",
    "title": "1. change dependency",
    "content": "&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-circuitbreaker-resilience4j&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt; &lt;/dependency&gt; . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_resilience4j/#1-change-dependency",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_resilience4j/#1-change-dependency"
  },"330": {
    "doc": "change Hystrix to Resilience4j",
    "title": "2. change code",
    "content": "HystrixRuntimeException → RuntimeException . | 기존에는 FeignClient로 호출하고 발생하는 Exception에 대한 폴백처리를 HystrixRuntimeException를 통해서 하고 있었는데, 이 부분이 사라지면서 java의 RuntimeException으로 대체했습니다 | . feign.hystrix.FallbackFactory → org.springframework.cloud.openfeign.FallbackFactory . | 기존에는 feign.hystrix.FallbackFactory를 사용해서 Feign호출 후 Fallback처리를 하도록 했는데, org.springframework.cloud.openfeign.FallbackFactory로 변경 | . status code . | 다른 어플리케이션으로 feign call했는데, 가용한 상태가 아니라면, . | feign.RetryableException를 throw하고 | status를 -1 로 리턴시킨다 | . | . throwable = {RetryableException@21177} \"feign.RetryableException: \" retryAfter = null httpMethod = {Request$HttpMethod@21226} \"PUT\" status = -1 responseBody = null responseHeaders = null request = {Request@21227} detailMessage = \"\" cause = {UnknownHostException@21229} \"java.net.UnknownHostException: espresso\" stackTrace = {StackTraceElement[9]@21233} . 최종 코드 . | FeignClient . | fallbackFactory를 선언하고, BusinessFallbackFactory를 상속받는다 | . @FeignClient( contextId = \"ReceptionClient\", name = \"test\", configuration = {FeignConfiguration.class, FeignLoggerLevelConfiguration.class}, fallbackFactory = ReceptionClient.ReceptionFallback.class, primary = false ) public interface ReceptionClient { @PostMapping(\"receptions\") ReceptionIdRdo register(@RequestBody ReceptionCdo receptionCdo); @Component class ReceptionFallback extends BusinessFallbackFactory { public ReceptionFallback(BusinessExceptionConverter businessExceptionConverter) { super(businessExceptionConverter); } @Override public ReceptionClient create(Throwable throwable) { return (partitionId, receptionCdo) -&gt; { warning(new BusinessFallbackResponse(receptionCdo.getReceptionId(), throwable)); return ReceptionIdRdo.EMPTY; }; } } } . | FallbackFactory Class . | FallbackFactory을 상세 구현한다. | 여러 client에서 공통으로 사용하게 하기 위해 상세 구현체는 별도로 분리했다. | . @Slf4j @Component @RequiredArgsConstructor public abstract class BusinessFallbackFactory implements FallbackFactory&lt;Object&gt; { private final BusinessExceptionConverter businessExceptionConverter; public void warning(BusinessFallbackResponse businessFallbackResponse) { businessExceptionConverter.accept(businessFallbackResponse); } public void warning(Throwable throwable) { log.error(\"A feign failed error occurred. \" + throwable.getMessage()); } } . | ExceptionConverter . | FeignException status별로 실패 비지니스가 다르기 때문에, case처리했다. | . @Slf4j @Component @RequiredArgsConstructor public class BusinessExceptionConverter implements Consumer&lt;Object&gt; { private final BusinessMessageAdapter businessMessageAdapter; @Override public void accept(Object obj) { action((BusinessFallbackResponse) obj); } @SuppressWarnings(\"squid:S1301\") private void action(BusinessFallbackResponse response) { Throwable e = response.getThrowable(); if (e instanceof FeignException) { FeignException exception = (FeignException) e; switch (exception.status()) { case 400001 : } } } } . | . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_resilience4j/#2-change-code",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_resilience4j/#2-change-code"
  },"331": {
    "doc": "change Hystrix to Resilience4j",
    "title": "change Hystrix to Resilience4j",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_resilience4j/",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_resilience4j/"
  },"332": {
    "doc": "change Feign And Loadbalancer Retry",
    "title": "change note",
    "content": ". | retry에 대한 처리 . | resilience4j가 제공하는 functional 모델 중 retry에 대해서만 처리할 계획입니다 | circuit breaker의 경우는 core application쪽에서 일임하고 있기 때문에 거기에 종속되어 동작하고 있어서, 비지니스 모델 중 일부 케이스만 retry를 커스텀할 수 있게 작업합니다. | . | hystrix와 resilience4j 차이 . | hystrix는 자바6 기반, resilience4j는 자바8기반 | 자바8기반이기 때문에 함수형으로 작성되었다는 것 | . | spring-retry, resilience4j의 retry, loadbalancer의 retry 차이 . | https://velog.io/@garden6/API-재시도를-처리할수-있는-여러가지-방안들 —&gt; 여기에 너무나도 잘 정리되어있다. | spring-retry . | annotation을 통해서 spring aop를 호출할 수 있다. | @EnableRetry, @Retryable을 통해 특정 exception일때 제어가 가능하며, method단위로도 설정이 가능하다 | 기본 구현 코드 : https://www.baeldung.com/spring-retry | . | resilience4j . | @Retry을 사용하며, 인스턴스 기반으로 Retry | . | . | . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_retry/#change-note",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_retry/#change-note"
  },"333": {
    "doc": "change Feign And Loadbalancer Retry",
    "title": "1. change dependency",
    "content": "&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-circuitbreaker-resilience4j&lt;/artifactId&gt; &lt;/dependency&gt; . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_retry/#1-change-dependency",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_retry/#1-change-dependency"
  },"334": {
    "doc": "change Feign And Loadbalancer Retry",
    "title": "2. problem",
    "content": ". | 기존에는 Feign의 Retryer를 Bean으로 등록해두고 커스텀한 주기로 사용할 수 있게 FeignClient인터페이스에 configuration으로 등록해서 사용했었는데요. | 이 기능이 스프링 버전업을 하게 되면서, loadbalancer에 등록한 instance들을 FeignClient로 호출할 때는 retry가 되고 있지 않은 문제가 발생했습니다. | spring-cloud-loadbalancer에 등록한 instance들을 통신할 때, 실패시 retry이 되도록 설정하면서 정리한 내용입니다. | . try1. | 설정정보입니다. instance는 총 3대이고, 각각 2번씩 retry해야하는 설정입니다. | . spring: cloud: loadbalancer: enabled: true retry: enabled: true maxRetriesOnSameServiceInstance: 2 maxRetriesOnNextServiceInstance: 2 retryableStatusCodes: 502, 503 . | loadbalancer에 등록한 인스턴스 내부에서의 retry는 동작하고 있는데, maxRetriesOnSameServiceInstance에 대한 동작이 안되고 있음 | RetryableFeignBlockingLoadBalancerClient디버깅하면 아래처럼 maxRetriesOnSameServiceInstance이 0으로 나오고 있습니다. | . try2. | 좀더 상세 로그를 보기 위해 레벨을 trace로 변경했습니다. logging: level: org.springframework.cloud.openfeign.loadbalancer: trace . | 디버깅하면 yml에 설정된 값으로 실행되지 않고 0으로 읽어가고 있습니다. 그래서 코드를 보니 loadbalanceProperties를 serviceId 하위로 찾고 있다는 것을 발견했습니다. | yml을 아래처럼 instance의 serviceId 하위로 retry 설정을 추가하고 다시 테스트했습니다. | spring.cloud.loadbalancer.clients.[SERVICE-ID].retry | . spring: cloud: loadbalancer: enabled: true clients: crema-gateway: retry: enabled: true maxRetriesOnSameServiceInstance: 2 maxRetriesOnNextServiceInstance: 2 retryableStatusCodes: 502, 503 . | 설정한 값으로 잘 읽어오고 있습니다. | . try3. | 하지만 설정대로 retry하지 않아서, 상세로깅을 보기위해 retry의 로깅을 설정했습니다. logging: level: org.springframework.retry: trace . | 로그를 보고자 하는 부분은 RetryTemplate.java의 doExecute 메서드 부분입니다. | 로깅을 추가한 후 로그입니다. | serviceId를 crema-gateway로 선언한 후, nginx서비스를 내리고 호출해 본 것인데요. | . 13:49:42.481 7-thread-5 DEBUG f.s.Slf4jLogger : 72 log [KakaoWriteClient#write] ---&gt; POST http://crema-gateway/chat/write HTTP/1.1 13:49:42.481 7-thread-5 DEBUG f.s.Slf4jLogger : 72 log [KakaoWriteClient#write] Accept: application/json 13:49:42.482 7-thread-5 DEBUG f.s.Slf4jLogger : 72 log [KakaoWriteClient#write] Content-Length: 168 13:49:42.482 7-thread-5 DEBUG f.s.Slf4jLogger : 72 log [KakaoWriteClient#write] Content-Type: applicati 13:49:42.483 7-thread-5 DEBUG f.s.Slf4jLogger : 72 log [KakaoWriteClient#write] 13:49:42.483 7-thread-5 DEBUG f.s.Slf4jLogger : 72 log [KakaoWriteClient#write] ---&gt; END HTTP (168-byte body) 13:49:42.484 7-thread-5 TRACE o.s.r.s.RetryTemplate :280 doExecute RetryContext retrieved: [RetryContext: count=0, lastException=null, exhausted=false] 13:49:42.484 7-thread-5 DEBUG o.s.r.s.RetryTemplate :324 doExecute Retry: count=0 13:49:42.484 7-thread-5 DEBUG ockingLoadBalancerClient:130 ambda$execute$2 Service instance retrieved from LoadBalancedRetryContext: was null. Reattempting service instance selection 13:49:42.485 7-thread-5 WARN c.RoundRobinLoadBalancer: 98 nstanceResponse No servers available for service: crema-gateway 13:49:42.485 7-thread-5 DEBUG ockingLoadBalancerClient:138 ambda$execute$2 Selected service instance: null 13:49:42.485 7-thread-5 WARN ockingLoadBalancerClient:145 ambda$execute$2 Service instance was not resolved, executing the original request 13:49:44.783 7-thread-5 DEBUG o.s.r.s.RetryTemplate :360 doExecute Checking for rethrow: count=1 13:49:44.783 7-thread-5 DEBUG o.s.r.s.RetryTemplate :383 doExecute Retry failed last attempt: count=1 13:49:44.783 7-thread-5 DEBUG f.s.Slf4jLogger : 72 log [KakaoWriteClient#write] &lt;--- ERROR UnknownHostException: crema-gateway (2299ms) 13:49:44.784 7-thread-5 DEBUG f.s.Slf4jLogger : 72 log [KakaoWriteClient#write] java.net.UnknownHostException: crema-gateway at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method) at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:929) at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1324) at java.net.InetAddress.getAllByName0(InetAddress.java:1277) at java.net.InetAddress.getAllByName(InetAddress.java:1193) at java.net.InetAddress.getAllByName(InetAddress.java:1127) at org.apache.http.impl.conn.SystemDefaultDnsResolver.resolve(SystemDefaultDnsResolver.java:45) at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:112) at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376) at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393) at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236) . | 서비스를 내렸기 때문에, loadbalance에서 갖고있는 instance가 없기 때문에 순수하게 http://crema-gateway란 주소로 호출했지만, 해당 주소로 호스팅 되는 것이 없기 때문에UnknownHostException가 발생했습니다 | maxRetriesOnSameServiceInstance를 2로 설정했는데 Retry failed last attempt: count=1를 끝으로 retry가 되지 않았습니다. | . | . try4. | retry가 한번되고 나서 실행되지 않아서 count 체크하는 로직을 디버깅해봤습니다. | LoadBalancedRetryPolicy가 BlockingLoadBalancedRetryPolicy로 구현되어있기 때문에, registerThrowable 부분을 디버깅하면 됩니다. | sameServerCount가 증가되지 않은 이유는 아래 코드에서 false로 리턴되어서인데요. public boolean canRetry(LoadBalancedRetryContext context) { HttpMethod method = context.getRequest().getMethod(); return HttpMethod.GET.equals(method) || this.properties.getRetry().isRetryOnAllOperations(); } . | 기본적으로 GET메소드만 retry하고 그 외의 method도 되어야 한다고 하면retryOnAllOperations 가 true로 설정되어야 합니다. | . | 그래서 최종적으로 설정한 값입니다 . spring: cloud: loadbalancer: enabled: true clients: crema-gateway: retry: enabled: true maxRetriesOnSameServiceInstance: 2 maxRetriesOnNextServiceInstance: 2 retryOnAllOperations: true retryableStatusCodes: 502, 503 . | 예를 들어, 이 설정으로 보면 최종적으로 3대의 인스턴스 환경에서 실패할 경우 각각 2번씩 retry하기때문에 총 9번이 실행됩니다. | . | . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_retry/#2-problem",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_retry/#2-problem"
  },"335": {
    "doc": "change Feign And Loadbalancer Retry",
    "title": "conclusion",
    "content": ". | 제가 작업하는 어플리케이션에서 FeignClient를 호출할 때 retry가 필요한 경우 2가지 케이스로 동작하게 했습니다. | 외부 서비스를 loadbalancer에 등록해서 호출하는 경우는 loadbalancer의 retry를 사용 | 그 외의 경우는 Feign의 Retryer를 사용 (이건 https://tnfhrnsss.github.io/docs/msa/feign/retry/에서 상세 설명할 예정입니다) | . | . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_retry/#conclusion",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_retry/#conclusion"
  },"336": {
    "doc": "change Feign And Loadbalancer Retry",
    "title": "reference",
    "content": "[MSA] Hystrix말고 resilience4j ? . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_retry/#reference",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_retry/#reference"
  },"337": {
    "doc": "change Feign And Loadbalancer Retry",
    "title": "change Feign And Loadbalancer Retry",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_retry/",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_retry/"
  },"338": {
    "doc": "change netflix-ribbon to spring-cloud-loadbalancer",
    "title": "summary",
    "content": ". | 기존에 eureka에 등록되지 않은 서비스에 대한 loadbalance처리를 ribbon을 통해 처리하고 있었는데, eos되면서 spring-cloud-loadbalancer로 대체하게 되었습니다. | 상세 코드는 github에 올려두겠습니다(아직 작업중..) | . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_scl/#summary",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_scl/#summary"
  },"339": {
    "doc": "change netflix-ribbon to spring-cloud-loadbalancer",
    "title": "내용",
    "content": ". | sprig-cloud-gateway는 eureka에 올라간 서비스만 가능하기 때문에, registry에 등록되지 않은 서비스는 spring-cloud-loadbalancer를 통해 서비스 등록을 시켜서 loadbalancing시킵니다. | ribbon으로 구성했던 작업내용에서 변경작업합니다 | . Feign LB using nginx (without Eureka) . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_scl/#%EB%82%B4%EC%9A%A9",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_scl/#내용"
  },"340": {
    "doc": "change netflix-ribbon to spring-cloud-loadbalancer",
    "title": "register service",
    "content": ". | nginx를 통해서 외부API를 호출하는 서비스를 springbootapplication이 올라갈 때 등록하는 작업입니다. | . 1. replace dependency . | 스프링 버전 변경 | netflix-ribbon 제거 | loadbalancer dependency 추가 . &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-loadbalancer&lt;/artifactId&gt; &lt;/dependency&gt; . | . 2. register LoadBalancerClient . | LoadBalancerClientConfigurationRegistrar에 서비스를 등록시키기 위해 @LoadBalancerClient를 선언한 클래스 생성 . | @FeignClient 인터페이스 파일에 직접 선언해도 되지만, 저는 여러개의 FeignClient에서 공통으로 동작시키기 위해 별도의 클래스로 분리했습니다. import org.springframework.cloud.loadbalancer.annotation.LoadBalancerClient; @LoadBalancerClient(name=\"${crema.gateway.name}\", configuration = {FeignLBInstanceConfigurationWithHealthCheck.class}) public class FeignLBClientConfiguration { } . | LoadBalancerClient를 열어보면 @Configuration이 선언되어있는데요. 그래서 굳이 @FeignClient클래스에 개별적으로 선언할 필요없이 특정 클래스에 별도로 분리해주면 빈에 자동으로 등록됩니다. | . | LoadBalancerClient에 configuration으로 설정한 FeignLBInstanceConfigurationWithHealthCheck.java입니다. | serviceId는 여러군데에서 동일하게 사용하는 값이라서 yml로 옮겼습니다. public class FeignLBInstanceConfigurationWithHealthCheck { @Value(\"${crema.gateway.name:}\") private String serviceId; @Bean ServiceInstanceListSupplier serviceInstanceListSupplier(LoadBalancerClientFactory loadBalancerClientFactory, @Value(\"${crema.gateway.instances}\") String instances) { return new HealthCheckServiceInstanceListSupplier( InstanceConfigurationHelper.getServiceInstanceListSuppliers(serviceId, StringUtils.tokenizeToStringArray(instances, \",\")), loadBalancerClientFactory, healthCheckFunction(new RestTemplate()) ); } ... (중략)... } public class InstanceConfigurationHelper { static ServiceInstanceListSupplier getServiceInstanceListSuppliers(String serviceId, String[] instances) { return ServiceInstanceListSuppliers.from( serviceId, Arrays.stream(instances) .map(Host::new) .map(host -&gt; new DefaultServiceInstance(host.toString(), serviceId, host.host, host.port, false)) .toArray(ServiceInstance[]::new) ); } } . | healthcheck로 supplier를 선택한 이유는 여러 대의 서버 중 가용한 instance로만 서비스하기 위함입니다. | HealthCheckServiceInstanceListSupplier로 구현하지 않으면, 서버상태를 보지않고 round robin시키기 때문에 내부적으로는 실패가 발생한 이후에 retry하게 됩니다. | 자세한 내용은 spring docs 확인 (https://docs.spring.io/spring-cloud-commons/docs/current/reference/html/#instance-health-check-for-loadbalancer) | . | InstanceConfigurationHelper 에서 supplier에 lb시킬 서버정보를 등록합니다 . | 서버정보는 yml에 선언 | . | . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_scl/#register-service",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_scl/#register-service"
  },"341": {
    "doc": "change netflix-ribbon to spring-cloud-loadbalancer",
    "title": "Add healthcheck api",
    "content": ". | loadbalancer를 healthcheck를 통해서 사용하기 위해서는 healthcheck정보가 필요합니다 | 만약에 설정이 따로 없다면, actuator/healthcheck를 기본으로 호출하게 됩니다. | 저는 기존에 ribbon으로도 제공했던 pingurl이 있었기 때문에 그 설정 그대로 옮기기만 했습니다. spring: cloud: loadbalancer: health-check: path: crema-gateway: /ping crema-gateway: refetch-instances: false # refetch-instances-interval: 60 # repeat-health-check: false시 . | 실패 로그 . | 만약에 등록한 instance로 전송이 실패한 경우 connect refuse로 로깅됩니다. 서비스로 등록되어있지만 전송에 실패해서 그렇습니다. 그리고 나서 . 14:09:30.829 7-thread-5 DEBUG ockingLoadBalancerClient:130 ambda$execute$2 Service instance retrieved from LoadBalancedRetryContext: was null. Reattempting service instance selection 14:09:30.829 7-thread-5 DEBUG ockingLoadBalancerClient:138 ambda$execute$2 Selected service instance: DefaultServiceInstance{instanceId='localhost-8051', serviceId='crema-gateway', host='localhost', port=8051, secure=false, metadata={}} 14:09:30.830 7-thread-5 DEBUG ockingLoadBalancerClient:156 ambda$execute$2 Using service instance from LoadBalancedRetryContext: DefaultServiceInstance{instanceId='localhost-8051', serviceId='crema-gateway', host='localhost', port=8051, secure=false, metadata={}} 14:09:35.366 7-thread-5 DEBUG f.s.Slf4jLogger : 72 log [KakaoWriteClient#write] &lt;--- ERROR HttpHostConnectException: Connect to localhost:8051 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect (4538ms) 14:09:35.367 7-thread-5 DEBUG f.s.Slf4jLogger : 72 log [KakaoWriteClient#write] org.apache.http.conn.HttpHostConnectException: Connect to localhost:8051 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:156) at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376) at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393) at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236) at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186) at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89) at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110) at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56) at feign.httpclient.ApacheHttpClient.execute(ApacheHttpClient.java:83) at org.springframework.cloud.openfeign.loadbalancer.LoadBalancerUtils.executeWithLoadBalancerLifecycleProcessing(LoadBalancerUtils.java:57) at org.springframework.cloud.openfeign.loadbalancer.RetryableFeignBlockingLoadBalancerClient.lambda$execute$2(RetryableFeignBlockingLoadBalancerClient.java:167) at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329) at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:225) at org.springframework.cloud.openfeign.loadbalancer.RetryableFeignBlockingLoadBalancerClient.execute(RetryableFeignBlockingLoadBalancerClient.java:113) at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:119) at feign.SynchronousMethodHandler.invoke(SynchronousMethodHandler.java:89) at org.springframework.cloud.openfeign.FeignCircuitBreakerInvocationHandler.lambda$asSupplier$1(FeignCircuitBreakerInvocationHandler.java:128) at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266) at java.util.concurrent.FutureTask.run(FutureTask.java) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: java.net.ConnectException: Connection refused: connect at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method) at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85) at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172) at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) at java.net.Socket.connect(Socket.java:589) at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75) at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142) ... 24 more 14:09:35.370 7-thread-5 DEBUG f.s.Slf4jLogger : 72 log [KakaoWriteClient#write] &lt;--- END ERROR . | 두 번째로 다시 호출하면 UnknownHostException이 발생합니다. 14:11:16.528 7-thread-6 DEBUG ockingLoadBalancerClient:130 ambda$execute$2 Service instance retrieved from LoadBalancedRetryContext: was null. Reattempting service instance selection 14:11:16.528 7-thread-6 WARN c.RoundRobinLoadBalancer: 98 nstanceResponse No servers available for service: crema-gateway 14:11:16.528 7-thread-6 DEBUG ockingLoadBalancerClient:138 ambda$execute$2 Selected service instance: null 14:11:16.528 7-thread-6 WARN ockingLoadBalancerClient:145 ambda$execute$2 Service instance was not resolved, executing the original request 14:11:18.806 7-thread-6 DEBUG f.s.Slf4jLogger : 72 log [KakaoWriteClient#write] &lt;--- ERROR UnknownHostException: crema-gateway (2279ms) 14:11:18.807 7-thread-6 DEBUG f.s.Slf4jLogger : 72 log [KakaoWriteClient#write] java.net.UnknownHostException: crema-gateway at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method) at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:929) at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1324) at java.net.InetAddress.getAllByName0(InetAddress.java:1277) at java.net.InetAddress.getAllByName(InetAddress.java:1193) at java.net.InetAddress.getAllByName(InetAddress.java:1127) at org.apache.http.impl.conn.SystemDefaultDnsResolver.resolve(SystemDefaultDnsResolver.java:45) at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:112) at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376) at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393) at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236) at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186) at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89) at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110) at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56) at feign.httpclient.ApacheHttpClient.execute(ApacheHttpClient.java:83) at org.springframework.cloud.openfeign.loadbalancer.LoadBalancerUtils.executeWithLoadBalancerLifecycleProcessing(LoadBalancerUtils.java:57) at org.springframework.cloud.openfeign.loadbalancer.RetryableFeignBlockingLoadBalancerClient.lambda$execute$2(RetryableFeignBlockingLoadBalancerClient.java:167) at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329) at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:225) at org.springframework.cloud.openfeign.loadbalancer.RetryableFeignBlockingLoadBalancerClient.execute(RetryableFeignBlockingLoadBalancerClient.java:113) at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:119) at feign.SynchronousMethodHandler.invoke(SynchronousMethodHandler.java:89) at org.springframework.cloud.openfeign.FeignCircuitBreakerInvocationHandler.lambda$asSupplier$1(FeignCircuitBreakerInvocationHandler.java:128) at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266) at java.util.concurrent.FutureTask.run(FutureTask.java) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) . | exception에 대한 retry가 호출되어야합니다. 이건 다른 post로 정리하겠습니다. | . | . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_scl/#add-healthcheck-api",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_scl/#add-healthcheck-api"
  },"342": {
    "doc": "change netflix-ribbon to spring-cloud-loadbalancer",
    "title": "feignClient",
    "content": ". | 기존 FeignClient로 구현한 인터페이스는 변경사항이 없습니다. | 구현한 파일은 아래 정보로 되어있습니다 . | ribbon으로 구현했던 포스트에 설명했듯이, 사이트별로 서버 및 방화벽 상황에 맞게 중간에 dmz를 통해 제어를 해야한다고 하면 name을 통해서 gateway서비스를 하게 하고 | 그게 아니면, 외부API의 url에 direct로 통신하게 할 수 있고 | L4가 있으면 그또한 url을 통해서 통신하게 할 수도 있습니다 | 아래처럼 name과 url이 모두 설정된 경우, url이 빈값이면 name을 통해서 서비스하게 됩니다. 그래서 yml설정내용에 따라 유동적으로 사용할 수 있습니다. | . @FeignClient( contextId = \"KakaoWriteClient\", url = \"${crema.thirdparty.kakao.url.chat}\", name = \"${crema.gateway.name}\", configuration = {FeignConfiguration.class, FeignRetryConfiguration.class}, primary = false ) public interface KakaoWriteClient { @PostMapping(\"test\") KakaoWriteRdo send(); } . | . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_scl/#feignclient",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_scl/#feignclient"
  },"343": {
    "doc": "change netflix-ribbon to spring-cloud-loadbalancer",
    "title": "Modify yml file",
    "content": ". | 기존에 ribbon설정으로 되어있던 부분을 제거하고 loadbalancer설정으로 대체합니다. | https://docs.spring.io/spring-cloud-commons/docs/current/reference/html/#instance-health-check-for-loadbalancer | 설정한 serviceId의 health-check를 추가합니다. (없으면 actuator/healthcheck로 호출됨) | instance정보가 변경될 때 refetch할 수 있도록 설정할 수 있습니다.(refetch로 시작하는 설정) | repeat-health-check는 refetch가 일어날 때마다 health-check를 한다는 것입니다. | refetch를 false로 해도 instance가 절체되었을 때 재시도하므로 false로 해도 됩니다 | . | . spring: cloud: loadbalancer: enabled: true retry: enabled: true maxRetriesOnSameServiceInstance: 0 maxRetriesOnNextServiceInstance: 2 retryableStatusCodes: 502, 503 health-check: path: crema-gateway: /ping crema-gateway: refetch-instances: false # refetch-instances-interval: 60 # repeat-health-check: false . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_scl/#modify-yml-file",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_scl/#modify-yml-file"
  },"344": {
    "doc": "change netflix-ribbon to spring-cloud-loadbalancer",
    "title": "About ping",
    "content": ". | ribbon의 경우는 PingUrl을 상속받아 커스텀 구현이 가능했습니다. import com.netflix.loadbalancer.PingUrl; import com.netflix.loadbalancer.Server; import org.springframework.beans.factory.annotation.Value; public class FeignRibbonPing extends PingUrl { @Value(\"${crema.thirdparty.thirdparty-gateway.health-check-location:}\") private String healthCheckLocation; @Value(\"${crema.thirdparty.thirdparty-gateway.isSecure:false}\") private boolean isHealthCheckSecure; @Override public String getPingAppendString() { return healthCheckLocation; } @Override public boolean isAlive(Server server) { super.setSecure(isHealthCheckSecure); return super.isAlive(server); } } . | scl의 경우는 찾아봤지만, 없는 것으로 보아 위에 HealthCheckServiceInstanceListSupplier으로 대체되는 것 같습니다 | 꼭 필요하다고 하면 instance의 serviceId를 얻어와서 HealthCheckServiceInstanceListSupplier에 등록한 healthCheckFunction을 통해 구현하는 방법 뿐인 것 같습니다. | . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_scl/#about-ping",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_scl/#about-ping"
  },"345": {
    "doc": "change netflix-ribbon to spring-cloud-loadbalancer",
    "title": "기타",
    "content": ". | loadbalancer의 log를 보고 싶다면, 추가 . logging: level: org: springframework: cloud: openfeign: loadbalancer: debug . | loadbalancer policy에 대해 . | 찾아보니, scl의 경우 round-robin 또는 random 방식만 지원한다고 합니다. | 기존에 ribbon의 경우는 com.netflix.loadbalancer.AvailabilityFilteringRule을 사용했었는데요. 위에서 작업한 heathcheck가 비슷하다고 할 수 있겠습니다. | custom한 rule을 적용하고 싶다면 아래 내용을 참고해서 작업하면 됩니다. | https://blog.cnscud.com/springcloud/2021/06/07/springcloud-betazonedemo-6.html | . | . | . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_scl/#%EA%B8%B0%ED%83%80",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_scl/#기타"
  },"346": {
    "doc": "change netflix-ribbon to spring-cloud-loadbalancer",
    "title": "problems",
    "content": ". | 일부러 가용하지 않은 서버를 설정하지 않을 것 같지만, 만약에 여러대의 instance 중 가용하지 않은 서버가 있으면 첨에 서비스 올리고 최초로 인스턴스를 호출하면, 2~3초정도 걸린다. 그 이후로는 캐싱되어서 빠른 것 같은데. 최초로 전송할 땐, 실패할 경우에 대한 healthcheck를 최초 한번 하는 것 같다. 그 실패에 대한 delay가 발생하는 것으로 보인다. 2022-09-29 14:53:21.632 DEBUG 25112 --- [pool-1-thread-1] RetryableFeignBlockingLoadBalancerClient : Service instance retrieved from LoadBalancedRetryContext: was null. Reattempting service instance selection 2022-09-29 14:53:21.661 ERROR 25112 --- [nio-9097-exec-2] o.a.c.c.C.[.[.[/].[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.springframework.cloud.client.circuitbreaker.NoFallbackAvailableException: No fallback available.] with root cause java.util.concurrent.TimeoutException: TimeLimiter 'WorldClient#hello(String)' recorded a timeout exception. at java.util.concurrent.FutureTask.get(FutureTask.java:205) ~[na:1.8.0_202] at io.github.resilience4j.timelimiter.internal.TimeLimiterImpl.lambda$decorateFutureSupplier$0(TimeLimiterImpl.java:46) ~[resilience4j-timelimiter-1.7.0.jar:1.7.0] at io.github.resilience4j.circuitbreaker.CircuitBreaker.lambda$decorateCallable$3(CircuitBreaker.java:171) ~[resilience4j-circuitbreaker-1.7.0.jar:1.7.0] at io.vavr.control.Try.of(Try.java:75) ~[vavr-0.10.2.jar:na] at org.springframework.cloud.circuitbreaker.resilience4j.Resilience4JCircuitBreaker.run(Resilience4JCircuitBreaker.java:123) ~[spring-cloud-circuitbreaker-resilience4j-2.1.3.jar:2.1.3] at org.springframework.cloud.client.circuitbreaker.CircuitBreaker.run(CircuitBreaker.java:30) ~[spring-cloud-commons-3.1.3.jar:3.1.3] at org.springframework.cloud.openfeign.FeignCircuitBreakerInvocationHandler.invoke(FeignCircuitBreakerInvocationHandler.java:107) ~[spring-cloud-openfeign-core-3.1.3.jar:3.1.3] at com.sun.proxy.$Proxy103.hello(Unknown Source) ~[na:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_202] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_202] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_202] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_202] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) ~[spring-web-5.3.22.jar:5.3.22] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150) ~[spring-web-5.3.22.jar:5.3.22] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117) ~[spring-webmvc-5.3.22.jar:5.3.22] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) ~[spring-webmvc-5.3.22.jar:5.3.22] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) ~[spring-webmvc-5.3.22.jar:5.3.22] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.3.22.jar:5.3.22] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1070) ~[spring-webmvc-5.3.22.jar:5.3.22] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963) ~[spring-webmvc-5.3.22.jar:5.3.22] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ~[spring-webmvc-5.3.22.jar:5.3.22] at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) ~[spring-webmvc-5.3.22.jar:5.3.22] at javax.servlet.http.HttpServlet.service(HttpServlet.java:655) ~[tomcat-embed-core-9.0.65.jar:4.0.FR] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ~[spring-webmvc-5.3.22.jar:5.3.22] at javax.servlet.http.HttpServlet.service(HttpServlet.java:764) ~[tomcat-embed-core-9.0.65.jar:4.0.FR] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227) ~[tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-9.0.65.jar:9.0.65] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.65.jar:9.0.65] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-5.3.22.jar:5.3.22] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) ~[spring-web-5.3.22.jar:5.3.22] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.65.jar:9.0.65] at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.3.22.jar:5.3.22] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) ~[spring-web-5.3.22.jar:5.3.22] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.65.jar:9.0.65] at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:96) ~[spring-boot-actuator-2.7.2.jar:2.7.2] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) ~[spring-web-5.3.22.jar:5.3.22] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.65.jar:9.0.65] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) ~[spring-web-5.3.22.jar:5.3.22] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) ~[spring-web-5.3.22.jar:5.3.22] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197) ~[tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) [tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541) [tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135) [tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) [tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) [tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360) [tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399) [tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) [tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890) [tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1789) [tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191) [tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659) [tomcat-embed-core-9.0.65.jar:9.0.65] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-9.0.65.jar:9.0.65] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_202] 2022-09-29 14:53:25.163 DEBUG 25112 --- [pool-1-thread-1] RetryableFeignBlockingLoadBalancerClient : Selected service instance: DefaultServiceInstance{instanceId='localhost-9093', serviceId='world-no-eureka', host='localhost', port=9093, secure=false, metadata={}} 2022-09-29 14:53:25.163 DEBUG 25112 --- [pool-1-thread-1] RetryableFeignBlockingLoadBalancerClient : Using service instance from LoadBalancedRetryContext: DefaultServiceInstance{instanceId='localhost-9093', serviceId='world-no-eureka', host='localhost', port=9093, secure=false, metadata={}} . | | . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_scl/#problems",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_scl/#problems"
  },"347": {
    "doc": "change netflix-ribbon to spring-cloud-loadbalancer",
    "title": "reference",
    "content": "[SC14] Spring Cloud LoadBalancer 란 ? . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_scl/#reference",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_scl/#reference"
  },"348": {
    "doc": "change netflix-ribbon to spring-cloud-loadbalancer",
    "title": "change netflix-ribbon to spring-cloud-loadbalancer",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/spring_upgrade_scl/",
    "relUrl": "/docs/msa/spring-cloud/spring_upgrade_scl/"
  },"349": {
    "doc": "SpringCloud",
    "title": "SpringCloud",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/springcloud/",
    "relUrl": "/docs/msa/spring-cloud/springcloud/"
  },"350": {
    "doc": "ssl 셋팅 후 갖가지 에러",
    "title": "ssl 셋팅 후 갖가지 에러",
    "content": ". | XMLHttpRequest cannot load https://aaa.ma.com:7443/. Response | . to preflight request doesn’t pass access control check: No ‘Access-Control-Allow-Origin’ . header is present on the requested resource. Origin . ‘http://127.0.0.1:8080’ is therefore not allowed access. | . | 접근한 aaa.ma.com 주소는 헤더가 다른 http://127.0.0.1:8080을 ajax로 호출할 수 없다. cors 때문에 | . | . | 공인인증서라면 인증서 설치에 문제겠지만 사설인증서인라면 인터넷브라우저의 인증서관리 화면에서 신뢰할수 잇는 루트기관으로 등록해준다 | . | . | 사설 인증서 브라우저에서 저장하려면 | . | . (1) 인터넷옵션 &gt; 내용 &gt; 인증서 선택 . (2) 신뢰할 수 있는 루트인증기관 탭 선택 &gt; 가져오기 . (3) 루트CA의 crt파일을 선택한다. (4) 브라우저 재시작 . | 제우스에 ssl셋팅하고 재시작했는데..아래처럼 truststore가 없다고 나오면..키파일 위치를 잘못잡았거나, 키스토어가 이상하거나 ㅠㅜ | . jeus.servlet.deployment.StartingException: File Not Found: D:\\TmaxSoft\\jeus6\\config\\testdomain\\truststore . | ERR_SSL_WEAK_SERVER_EPHEMERAL_DH_KEY | . | 크롬 버전 : 45.0.2454.99에서 나오는 에러로 ssl셋팅했을 때 보안설정이 낮아서 그런것으로.. | 크롬으로 url쳐서 개발자모드 보면 콘솔에 아래처럼 찍히는데.. 먼가 이제까지 브라우저에서 커버된게 deprecated된건가.. 모르겠지만 | . /deep/ combinator is deprecated. See https://www.chromestatus.com/features/6750456638341120 for more details. | 해결은 ssl인증서거는 설정에 ciper설정을 추가하면 된다. | 만약 톰캣이라면 아래처럼 connector설정 | . | err_ssl_fallback_beyond_minimum_version | . | 이것도 크롬에서만 나타난다 | 블로그) http://ondemand.tistory.com/214 | . 1) 크롬은 여전히 v45 에서 TLS v1.0 을 지원하고 있으니 TLS 버전 이슈는 아님, 2) 다만 크롬이 접속하려는 서버가 TLS Handshake 하는 과정에 이슈가 있을 경우, 기존에는 크롬이 Workaround 해주었지만, 3) v45 부터는 더이상 해당 Workaround 를 지원하지 않아서 발생하는 문제다 정도입니다. 구체적으로 어떤 웹 서버의 특정 버전이 이슈가 있는 것인지는 명확하게 정리된 내용을 찾지 못했습니다만 조치를 위해서는 서버측의 TLS Handshake 에 대한 보완이 필요한 것으로 추정 . ",
    "url": "http://localhost:4000/docs/errors/ssl1/",
    "relUrl": "/docs/errors/ssl1/"
  },"351": {
    "doc": "Alias name [root] does not identify a key entry",
    "title": "problem",
    "content": "이제까지 server.ssl에 alias를 설정한 적이 없는데 . 갑자기 alias가 null이라고 하더니 . alias를 지정하면 . alias가 맞지않다고 나온다. ",
    "url": "http://localhost:4000/docs/errors/ssl_alias_error/#problem",
    "relUrl": "/docs/errors/ssl_alias_error/#problem"
  },"352": {
    "doc": "Alias name [root] does not identify a key entry",
    "title": "error",
    "content": "Caused by: java.lang.IllegalArgumentException: Alias name [root] does not identify a key entry at org.apache.tomcat.util.net.AbstractJsseEndpoint.createSSLContext(AbstractJsseEndpoint.java:99) at org.apache.tomcat.util.net.AbstractJsseEndpoint.initialiseSsl(AbstractJsseEndpoint.java:71) at org.apache.tomcat.util.net.NioEndpoint.bind(NioEndpoint.java:258) at org.apache.tomcat.util.net.AbstractEndpoint.bindWithCleanup(AbstractEndpoint.java:1204) at org.apache.tomcat.util.net.AbstractEndpoint.start(AbstractEndpoint.java:1290) at org.apache.coyote.AbstractProtocol.start(AbstractProtocol.java:614) at org.apache.catalina.connector.Connector.startInternal(Connector.java:1072) ... 20 common frames omitted Caused by: java.io.IOException: Alias name [root] does not identify a key entry at org.apache.tomcat.util.net.SSLUtilBase.getKeyManagers(SSLUtilBase.java:336) at org.apache.tomcat.util.net.SSLUtilBase.createSSLContext(SSLUtilBase.java:246) at org.apache.tomcat.util.net.AbstractJsseEndpoint.createSSLContext(AbstractJsseEndpoint.java:97) ... 26 common frames omitted . ",
    "url": "http://localhost:4000/docs/errors/ssl_alias_error/#error",
    "relUrl": "/docs/errors/ssl_alias_error/#error"
  },"353": {
    "doc": "Alias name [root] does not identify a key entry",
    "title": "try..",
    "content": "spring boot로 내장 tomcat 구동하고 yml에 ssl설정을 아래와 같이 했는데 . server: port: 19010 ssl: enabled: true key-store: /_WAS/ssl/new/keystore.jks key-store-type: JKS key-store-password: tmvprxmfk1! key-alias: root . keytool로 조회해도 alias는 root라고 나오는데 . ",
    "url": "http://localhost:4000/docs/errors/ssl_alias_error/#try",
    "relUrl": "/docs/errors/ssl_alias_error/#try"
  },"354": {
    "doc": "Alias name [root] does not identify a key entry",
    "title": "cause",
    "content": "keystore하위에 private key가 없고 가져온 인증서가 PrivatekeyEntyty 또는 trustedCertEntry인 경우 발생 . keytool로 조회했을 때 이런식으로 조회되어야 한다. 종류는 PrivateKeyEntry에 . 체인은 3개 . ",
    "url": "http://localhost:4000/docs/errors/ssl_alias_error/#cause",
    "relUrl": "/docs/errors/ssl_alias_error/#cause"
  },"355": {
    "doc": "Alias name [root] does not identify a key entry",
    "title": "reference",
    "content": "Unable to start Tomcat due to java.io.IOException Alias name not identifying a key entry . ",
    "url": "http://localhost:4000/docs/errors/ssl_alias_error/#reference",
    "relUrl": "/docs/errors/ssl_alias_error/#reference"
  },"356": {
    "doc": "Alias name [root] does not identify a key entry",
    "title": "Alias name [root] does not identify a key entry",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/ssl_alias_error/",
    "relUrl": "/docs/errors/ssl_alias_error/"
  },"357": {
    "doc": "Sub Projects",
    "title": "Sub Projects",
    "content": "Projects that I work on personally. ",
    "url": "http://localhost:4000/docs/sub-projects",
    "relUrl": "/docs/sub-projects"
  },"358": {
    "doc": "점층적 생성자 패턴",
    "title": "점층적 생성자 패턴",
    "content": " ",
    "url": "http://localhost:4000/docs/patterns/telescoping_constructor_pattern/",
    "relUrl": "/docs/patterns/telescoping_constructor_pattern/"
  },"359": {
    "doc": "Tesseract Ocr Study",
    "title": "tesseract ocr 공부",
    "content": "기술조사 ) Tesseract-ocr을 사용 . 순서1) 라이브러리설치에 앞서서, 맥으로 해야하기 때문에 홈브루 설치(https://whitepaek.tistory.com/3) . 순서2) tesseract, tesseract-lang설치 . brew install tesseract . brew install tesseract-lang . 순서3) sudo pip3 install pytesseract . sudo pip3 intall Image . 순서4) 실행한다. peter:~ peter$ tesseract /Users/peter/Downloads/IMG_5814.JPG /Users/peter/Downloads/aaa.txt -l kor . 순서4-1) 또는 파이썬으로 실행한다. import pytessearct . import PIL import Image . print(pytesseract.image_to_string(Image.open('/Users/peter/Downloads/IMG_5814.JPG'), lang='kor')) . 결과1) 별로 좋지 않은 결과 . 이 도 아이티 들으 그도 밸아차 가 소경더 [준공 023 자구 가바바 다자이 이누 그두자구 1611 11\\ 1000 너(|'0&gt;030)40) 이 지 성 지음 . 시도2) 이미지를 rotate시켜본다. &gt;&gt;&gt; im = Image.open('/Users/peter/Downloads/IMG_5814.JPG') &gt;&gt;&gt; img3 = im.rotate(90) &gt;&gt;&gt; print(pytesseract.image_to_string(img3, lang='kor')) . 결과2) 더 안좋음 ㅠㅜ . 몽|? 을 |? |0 도스 사기브 사고 ~ 요일 -………애 : 다 00000 0 디넌낸트이나 조는 [1 ~ 야 오어 1오 \" 0 . 시도3) tesseract의 train된 lang을 추가해본다. https://github.com/tesseract-ocr/tessdata/blob/master/kor.traineddata 에서 다운로드받고, . 받은 데이터파일을 아래에 추가. mac으로 terracert 를 설치한 경우, 추가할 위치는 /usr/local/share/tessdata 이다. 결과3) 첫번째에 비해 달라진걸 모르겠다 ㅠㅜ . 人 還 計生 lane Austen ()%+()&amp;1) 點 『 | 1 도 ~) 人 全 一 人 生 人 加 人 크 ” &gt; 재한 0 블 세 랐 도 기 ||” :( 총 니 . 내 - 올 를 SKIN 7! 올블 이 入 성 지음 . 시도4) 문제를 알았다… 폰트같은 글자 모양이나 길이에 대한 학습이 필요하다는 것을… . 시도5) 이미지를 box파일을 만든담에 https://hello-gg.tistory.com/5 에서처럼 하나씩 불러서 인식을 잡아준다. 그리고 학습 후 기존 학습파일에 add해준다. https://diyworld.tistory.com/114 . ",
    "url": "http://localhost:4000/docs/sub-projects/tesseract_ocr_study/#tesseract-ocr-%EA%B3%B5%EB%B6%80",
    "relUrl": "/docs/sub-projects/tesseract_ocr_study/#tesseract-ocr-공부"
  },"360": {
    "doc": "Tesseract Ocr Study",
    "title": "Tesseract Ocr Study",
    "content": " ",
    "url": "http://localhost:4000/docs/sub-projects/tesseract_ocr_study/",
    "relUrl": "/docs/sub-projects/tesseract_ocr_study/"
  },"361": {
    "doc": "TimedSupervisorTask task supervisor timed out - TimeoutException",
    "title": "problem",
    "content": "서비스 올릴 때 발생하는 오류로 오류와 무관하게 서비스는 잘 되고 있다. ",
    "url": "http://localhost:4000/docs/errors/timedSupervisorTask_timed_out/#problem",
    "relUrl": "/docs/errors/timedSupervisorTask_timed_out/#problem"
  },"362": {
    "doc": "TimedSupervisorTask task supervisor timed out - TimeoutException",
    "title": "error",
    "content": "07:53:02.003 ryClient-0 WARN .n.d.TimedSupervisorTask: 73 run task supervisor timed out java.util.concurrent.TimeoutException: null at java.util.concurrent.FutureTask.get(FutureTask.java:205) at com.netflix.discovery.TimedSupervisorTask.run(TimedSupervisorTask.java:68) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) 07:53:17.011 ryClient-0 WARN .n.d.TimedSupervisorTask: 73 run task supervisor timed out java.util.concurrent.TimeoutException: null at java.util.concurrent.FutureTask.get(FutureTask.java:205) at com.netflix.discovery.TimedSupervisorTask.run(TimedSupervisorTask.java:68) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) 07:53:25.348 main DEBUG s.a.c.s.c.c.CipherConfig: 19 cipherCrypto CipherCrypto:CipherCryptoProperties{encryptAlgorithm='AES/ECB/PKCS5Padding'} 07:53:25.363 main DEBUG s.a.c.s.c.c.JsonCrypto : 30 &lt;init&gt; JsonCrypto[CipherCrypto], CryptoProperties{enabled=true, encryptFields=[message, metadata.address, name, email, phone, extra, answerValues]} 07:53:37.015 ryClient-0 WARN .n.d.TimedSupervisorTask: 84 run task supervisor rejected the task java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.FutureTask@354aaa21 rejected from java.util.concurrent.ThreadPoolExecutor@704822ec[Running, pool size = 2, active threads = 2, queued tasks = 0, completed tasks = 0] at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063) at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830) at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379) at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:112) at com.netflix.discovery.TimedSupervisorTask.run(TimedSupervisorTask.java:66) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) . ",
    "url": "http://localhost:4000/docs/errors/timedSupervisorTask_timed_out/#error",
    "relUrl": "/docs/errors/timedSupervisorTask_timed_out/#error"
  },"363": {
    "doc": "TimedSupervisorTask task supervisor timed out - TimeoutException",
    "title": "try 1 (실패)",
    "content": "application.yml에 아래 속성 추가 . eureka: client: fetch-registry: true register-with-eureka: true . https://stackoverflow.com/questions/37542939/problems-spring-cloud-config-and-spring-cloud-bus . ",
    "url": "http://localhost:4000/docs/errors/timedSupervisorTask_timed_out/#try-1-%EC%8B%A4%ED%8C%A8",
    "relUrl": "/docs/errors/timedSupervisorTask_timed_out/#try-1-실패"
  },"364": {
    "doc": "TimedSupervisorTask task supervisor timed out - TimeoutException",
    "title": "try 2",
    "content": "eureka버그로 버전 업 필요 . ",
    "url": "http://localhost:4000/docs/errors/timedSupervisorTask_timed_out/#try-2",
    "relUrl": "/docs/errors/timedSupervisorTask_timed_out/#try-2"
  },"365": {
    "doc": "TimedSupervisorTask task supervisor timed out - TimeoutException",
    "title": "try 3",
    "content": "client.registryFetchIntervalSeconds를 30초로 늘려주라고 함 . 30초로 늘려도 발생해서 60초로 설정함. 60초로 늘려도 발생해서.. ",
    "url": "http://localhost:4000/docs/errors/timedSupervisorTask_timed_out/#try-3",
    "relUrl": "/docs/errors/timedSupervisorTask_timed_out/#try-3"
  },"366": {
    "doc": "TimedSupervisorTask task supervisor timed out - TimeoutException",
    "title": "cause",
    "content": "https://www.cnblogs.com/linus-tan/p/14814045.html . 여기서 말하는 원인은 . 프로젝트가 시작되고 초기화되면 두 가지 타이밍 작업이 시작됩니다. 하나는 유레카에 등록하는 것, 즉 하트비트 스레드이고, 다른 하나는 유레카에서 서비스 등록 목록을 가져오는 것, 즉 새로 고칠 스레드입니다. 등록 목록 캐시.위의 두 스레드는 30초마다 실행되며 기본 타임아웃 시간은 30초이므로 30초 이내에 작업이 완료되지 않으면 Timeout 예외가 발생합니다. 하트비트를 보내는 작업은 비교적 간단하며 일반적으로 시간이 초과되지 않습니다. 등록 목록을 얻는 작업은 오랜 시간이 걸립니다. 레지스트리는 모든 서비스 통신의 기반이므로 여러 서버에 배포된 응용 프로그램은 통신하는 데 시간이 걸릴 수 있으며 시간 초과가 자주 발생합니다. ",
    "url": "http://localhost:4000/docs/errors/timedSupervisorTask_timed_out/#cause",
    "relUrl": "/docs/errors/timedSupervisorTask_timed_out/#cause"
  },"367": {
    "doc": "TimedSupervisorTask task supervisor timed out - TimeoutException",
    "title": "TimedSupervisorTask task supervisor timed out - TimeoutException",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/timedSupervisorTask_timed_out/",
    "relUrl": "/docs/errors/timedSupervisorTask_timed_out/"
  },"368": {
    "doc": "Tolerant reader pattern",
    "title": "tolerant reader pattern",
    "content": " ",
    "url": "http://localhost:4000/docs/patterns/tolerant_reader_pattern/#tolerant-reader-pattern",
    "relUrl": "/docs/patterns/tolerant_reader_pattern/#tolerant-reader-pattern"
  },"369": {
    "doc": "Tolerant reader pattern",
    "title": "Tolerant reader pattern",
    "content": " ",
    "url": "http://localhost:4000/docs/patterns/tolerant_reader_pattern/",
    "relUrl": "/docs/patterns/tolerant_reader_pattern/"
  },"370": {
    "doc": "Twilio Studio Study",
    "title": "Studio",
    "content": ". | studio? . | low-code/no-code application builder | save the coding work | API 및 SDK를 제공한다. | UI를 통해서 설정할 수도 있다. | . | . ",
    "url": "http://localhost:4000/docs/etc/twilio_studio_study/#studio",
    "relUrl": "/docs/etc/twilio_studio_study/#studio"
  },"371": {
    "doc": "Twilio Studio Study",
    "title": "Main Domain",
    "content": " ",
    "url": "http://localhost:4000/docs/etc/twilio_studio_study/#main-domain",
    "relUrl": "/docs/etc/twilio_studio_study/#main-domain"
  },"372": {
    "doc": "Twilio Studio Study",
    "title": "Flow",
    "content": ". | Flow? . | 하나의 업무 흐름 단위로 여러 개의 단계로 구성이 되며, 시작과 끝을 가진다. | subflow를 정의할 수 있다. | . | Field . | Definition . | 복잡한 요구 사항을 정의하고 있다. | UI에서 Widget으로 표현되는 것들을 갖고 있다. | . | webhookUrl . | webhook url을 통해 Flow시작 | . | status . | flow의 상태 : draft or published | . | . | . { \"sid\": \"FWXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", \"account_sid\": \"ACXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", **\"definition\":** { \"description\": \"A New Flow\", \"states\": [ { \"name\": \"Trigger\", \"type\": \"trigger\", \"transitions\": [], \"properties\": { \"offset\": { \"x\": 0, \"y\": 0 } } } ], \"initial_state\": \"Trigger\", \"flags\": { \"allow_concurrent_calls\": true } }, \"friendly_name\": \"Main IVR\", **\"status\": \"draft\"**, \"revision\": 1, \"commit_message\": \"First draft\", \"valid\": true, \"errors\": [], \"warnings\": [], **\"webhook_url\":** \"http://webhooks.twilio.com/v1/Accounts/ACXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/Flows/FWXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", \"date_created\": \"2017-11-06T12:00:00Z\", \"date_updated\": null, \"url\": \"https://studio.twilio.com/v2/Flows/FWXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", \"links\": { \"test_users\": \"https://studio.twilio.com/v2/Flows/FWXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/TestUsers\", \"revisions\": \"https://studio.twilio.com/v2/Flows/FWXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/Revisions\", \"executions\": \"https://studio.twilio.com/v2/Flows/FWXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/Executions\" } } . ",
    "url": "http://localhost:4000/docs/etc/twilio_studio_study/#flow",
    "relUrl": "/docs/etc/twilio_studio_study/#flow"
  },"373": {
    "doc": "Twilio Studio Study",
    "title": "Definition",
    "content": ". | Fields . | initialState . | 정의한 흐름 순서의 첫번째로 보통 Trigger State에 해당된다. | . | States . | Widget Snippet을 통해 설정한 State들을 순서대로 갖고 있다. | 기본적으로 Trigger State로 시작한다. | . | . | . { \"states\": [ { \"transitions\": [ { \"event\": \"incomingMessage\", \"next\": \"send_message_1\" }, { \"event\": \"incomingCall\", \"next\": \"say_play_1\" }, { \"event\": \"incomingRequest\", \"next\": \"call_user_1\" } ], \"type\": \"trigger\", \"name\": \"Trigger\", \"properties\": { \"offset\": { \"y\": 0, \"x\": 0 } } }, { \"transitions\": [ { \"event\": \"audioComplete\" } ], \"type\": \"say-play\", \"name\": \"say_play_1\", \"properties\": { \"say\": \"Hello world!\", \"loop\": 1, \"offset\": { \"y\": 210, \"x\": 130 } } }, { \"transitions\": [ { \"event\": \"sent\" }, { \"event\": \"failed\" } ], \"type\": \"send-message\", \"name\": \"send_message_1\", \"properties\": { \"body\": \"Hello world!\", \"from\": \"\", \"service\": \"\", \"to\": \"\", \"offset\": { \"y\": 210, \"x\": -240 }, \"channel\": \"\" } }, { \"transitions\": [ { \"event\": \"answered\", \"next\": \"say_play_1\" }, { \"event\": \"busy\" }, { \"event\": \"noAnswer\" }, { \"event\": \"failed\" } ], \"type\": \"make-outgoing-call-v2\", \"name\": \"call_user_1\", \"properties\": { \"trim\": \"true\", \"machine_detection_silence_timeout\": \"5000\", \"from\": \"\", \"recording_status_callback\": \"\", \"record\": false, \"machine_detection_speech_threshold\": \"2400\", \"to\": \"\", \"detect_answering_machine\": false, \"sip_auth_username\": \"\", \"machine_detection\": \"Enable\", \"send_digits\": \"\", \"machine_detection_timeout\": \"30\", \"timeout\": 60, \"offset\": { \"y\": 210, \"x\": 490 }, \"machine_detection_speech_end_threshold\": \"1200\", \"sip_auth_password\": \"\", \"recording_channels\": \"mono\" } } ], \"initial_state\": \"Trigger\", \"flags\": { \"allow_concurrent_calls\": true }, \"description\": \"A New Flow\" } . ",
    "url": "http://localhost:4000/docs/etc/twilio_studio_study/#definition",
    "relUrl": "/docs/etc/twilio_studio_study/#definition"
  },"374": {
    "doc": "Twilio Studio Study",
    "title": "State",
    "content": ". | State? . | 위젯UI로 제공하는 Snippet을 바탕으로해서 state를 정의한다. | 각 state에서 동작하는 방식을 type으로 지정하고, 성공/실패에 대한 이벤트를 transition에 정의한다. | . | Fields . | transitions | type . | addTwimlRedirect | capturePayments | connectCallTo | enqueueCall | forkStream | gatherInputOnCall | makeHttpRequest | makeOutgoingCall | recordCall | recordVoicemail | runFunction | sayPlay | sendAndWaitForReply | sendMessage | sendToAutopilot | sendToFlex | setVariables | splitBasedOn . | 흐름에 조건을 줄 수 있다. | . | . | . | . ",
    "url": "http://localhost:4000/docs/etc/twilio_studio_study/#state",
    "relUrl": "/docs/etc/twilio_studio_study/#state"
  },"375": {
    "doc": "Twilio Studio Study",
    "title": "transition",
    "content": ". | state에서 실행되는 transition정보를 담고 있다. | . ",
    "url": "http://localhost:4000/docs/etc/twilio_studio_study/#transition",
    "relUrl": "/docs/etc/twilio_studio_study/#transition"
  },"376": {
    "doc": "Twilio Studio Study",
    "title": "기타 step, step context, execution",
    "content": ". | Flow가 실행되면 실시간으로 상태 및 변수에 관한 정보를 저장 | . { \"sid\": \"FTXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", \"account_sid\": \"ACXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", \"flow_sid\": \"FWXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", \"execution_sid\": \"FNXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", \"name\": \"incomingRequest\", \"context\": {}, \"transitioned_from\": \"Trigger\", \"transitioned_to\": \"Ended\", \"date_created\": \"2017-11-06T12:00:00Z\", \"date_updated\": null, \"url\": \"https://studio.twilio.com/v2/Flows/FWXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/Executions/FNXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/Steps/FTXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", \"links\": { \"step_context\": \"https://studio.twilio.com/v2/Flows/FWXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/Executions/FNXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/Steps/FTXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/Context\" } } . ",
    "url": "http://localhost:4000/docs/etc/twilio_studio_study/#%EA%B8%B0%ED%83%80-step-step-context-execution",
    "relUrl": "/docs/etc/twilio_studio_study/#기타-step-step-context-execution"
  },"377": {
    "doc": "Twilio Studio Study",
    "title": "reference",
    "content": "Studio Flow Definition . ",
    "url": "http://localhost:4000/docs/etc/twilio_studio_study/#reference",
    "relUrl": "/docs/etc/twilio_studio_study/#reference"
  },"378": {
    "doc": "Twilio Studio Study",
    "title": "Twilio Studio Study",
    "content": " ",
    "url": "http://localhost:4000/docs/etc/twilio_studio_study/",
    "relUrl": "/docs/etc/twilio_studio_study/"
  },"379": {
    "doc": "Type safe heterogeneous container pattern",
    "title": "타입 안전 이종 컨테이너 패턴",
    "content": "type safe heterogeneous container pattern . public class Favorites { public &lt;T&gt; void putFavorite(Class&lt;T&gt; type, T instance); public &lt;T&gt; T getFavorite(Class&lt;T&gt; type); } public static void main(String[] args) { Favorites f = new Favorites(); f.putFavorite(String.class, \"Java\"); f.putFavorite(Integer.class, 0xcafebabe); String favoritesString = f.getFavorite(String.class); } . | Favorites인스턴스는 String이 요청되면 Integer를 반환하는 일이 없기 때문에 타입안전하다고 볼 수 있다. | 일반 적인 맵과 달리 여러가지 타입의 원소를 담을 수 있어서, 타입안전이종 컨테이너라고 한다. | ex) DatabaseRow타입의 Column | . public class Favorites { private Map&lt;Class&lt;?&gt;, Object&gt; favorites = new HashMap&lt;&gt;(); public &lt;T&gt; void putFavorites(Class&lt;T&gt; type, T instance) { favorites.put(Objects.requireNonNull(type), type.cass(instance)); } } . | 타입을 한정시키고 싶다면? . | ex) annotation api | . public &lt;T extends Annotation&gt; T getAnnotation(Class&lt;T&gt; annotationType); static Annotation getAnnotation(AnnotatedElement element, String annotationTypeName) { Class&lt;?&gt; annotationType = null; // 비한정적 타입 토큰 try { annotationType = Class.forName(annotationTypeName); } catch (Exception ex) { throw new IllegalArgumentException(ex); } return element.getAnnotation(annotationType.asSubclass(Annotation.class)); } . | annotationType인수는 한정적 타입 토큰 | . | . ",
    "url": "http://localhost:4000/docs/patterns/typesafe_heterogeneous_container_pattern/#%ED%83%80%EC%9E%85-%EC%95%88%EC%A0%84-%EC%9D%B4%EC%A2%85-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%ED%8C%A8%ED%84%B4",
    "relUrl": "/docs/patterns/typesafe_heterogeneous_container_pattern/#타입-안전-이종-컨테이너-패턴"
  },"380": {
    "doc": "Type safe heterogeneous container pattern",
    "title": "Type safe heterogeneous container pattern",
    "content": " ",
    "url": "http://localhost:4000/docs/patterns/typesafe_heterogeneous_container_pattern/",
    "relUrl": "/docs/patterns/typesafe_heterogeneous_container_pattern/"
  },"381": {
    "doc": "Udacity",
    "title": "Udacity",
    "content": " ",
    "url": "http://localhost:4000/docs/mooc/udacity/udacity/",
    "relUrl": "/docs/mooc/udacity/udacity/"
  },"382": {
    "doc": "Udemy",
    "title": "Udemy",
    "content": " ",
    "url": "http://localhost:4000/docs/mooc/udemy/udemy/",
    "relUrl": "/docs/mooc/udemy/udemy/"
  },"383": {
    "doc": "UnixFileSystem.createFileExclusively",
    "title": "UnixFileSystem.createFileExclusively",
    "content": "problem . | apache poi로 엑셀 파일을 생성해서 unix시스템에 파일쓰기할 때 Permission denied 발생 | . error . java.io.IOException: Permission denied at java.io.UnixFileSystem.createFileExclusively(Native Method) at java.io.File.createTempFile(File.java:2063) at org.apache.poi.util.DefaultTempFileCreationsStrategy.createTempFile(DefaultTempFileCreationsStrategy.java:110) . solved . | 만약에 톰캣 기본 폴더를 지정하지 않았다면, /tmp 경로에 가면 아래 폴더들이 존재한다. | . | hsperfdata_로 시작하는 폴더와 poifiles폴더의 권한이 맞게 되어있는지 체크 | 또는 기본 폴더도 변경하자 (centos에서는 주기적으로 /tmp 하위 삭제함) | . server: tomcat: basedir: /tmp 외의 폴더로 변경 . reference . java.io.IOException: Permission denied . ",
    "url": "http://localhost:4000/docs/errors/unixfile/",
    "relUrl": "/docs/errors/unixfile/"
  },"384": {
    "doc": "jetbrains.vcs.server.api.VcsServiceException Failed to construct commits graph for...",
    "title": "upsource 동기화 오류",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/upsource1/#upsource-%EB%8F%99%EA%B8%B0%ED%99%94-%EC%98%A4%EB%A5%98",
    "relUrl": "/docs/errors/upsource1/#upsource-동기화-오류"
  },"385": {
    "doc": "jetbrains.vcs.server.api.VcsServiceException Failed to construct commits graph for...",
    "title": "problem",
    "content": "건물 정전되었을 때, upsource도 같이 고장나버렸다. 정전되면서 정리되지 못한 commit log파일들도 지우고, 어찌어찌 다시 살려냈는데 . hub의 프로젝트 목록에 들어가보면 이렇게 오류가 나있고 정전 이후에 커밋된 데이터를 가져오지 못했다. [error log] . Caused by: jetbrains.vcs.server.api.VcsServiceException: Failed to construct commits graph for talk-ui-backoffice{mappings: 1, mounts: 0}. Failed to const ruct graph for talk-ui-backoffice:. Failed to collect commits graph for talk-ui-backoffice:. jetbrains.buildServer.vcs.VcsException [2022-03-24 15:16:37,356] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.global.CompositeGraphFactory.fetchGraph(CompositeGraphFactory.java:103) [2022-03-24 15:16:37,356] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.GraphServiceImpl.fetchGraph(GraphServiceImpl.java:68) [2022-03-24 15:16:37,356] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.FetchServiceImpl.fetch(FetchServiceImpl.java:22) [2022-03-24 15:16:37,356] [Upsource Frontend Error] at com.jetbrains.upsource.backend.cli.vcs.service.VcsServiceClient.processNewRevisions(VcsServiceClient.java:72) [2022-03-24 15:16:37,357] [Upsource Frontend Error] ... 19 more [2022-03-24 15:16:37,357] [Upsource Frontend Error] Caused by: jetbrains.vcs.server.api.VcsServiceException: Failed to construct graph for talk-ui-backoffice:. Failed to collect commits graph for talk-ui-ba ckoffice:. jetbrains.buildServer.vcs.VcsException [2022-03-24 15:16:37,357] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.global.MappingCommitsGraphFutures$2.graph(MappingCommitsGraphFutures.java:41) [2022-03-24 15:16:37,357] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.global.CompositeGraphBuilder.includeMappings(CompositeGraphBuilder.java:128) [2022-03-24 15:16:37,357] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.global.CompositeGraphBuilder.loadGraphs(CompositeGraphBuilder.java:96) [2022-03-24 15:16:37,357] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.global.CompositeGraphBuilder.fetchAllGraphs(CompositeGraphBuilder.java:62) [2022-03-24 15:16:37,357] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.global.CompositeGraphFactory.fetchGraph(CompositeGraphFactory.java:99) [2022-03-24 15:16:37,357] [Upsource Frontend Error] ... 22 more [2022-03-24 15:16:37,357] [Upsource Frontend Error] Caused by: jetbrains.vcs.server.api.VcsServiceException: Failed to construct graph for talk-ui-backoffice:. Failed to collect commits graph for talk-ui-ba ckoffice:. jetbrains.buildServer.vcs.VcsException [2022-03-24 15:16:37,357] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.global.MappingCommitsGraphFutures.error(MappingCommitsGraphFutures.java:57) [2022-03-24 15:16:37,357] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.global.MappingCommitsGraphFutures.errorGraph(MappingCommitsGraphFutures.java:31) [2022-03-24 15:16:37,358] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.global.CompositeGraphBuilder.lambda$loadGraphs$0(CompositeGraphBuilder.java:117) [2022-03-24 15:16:37,358] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.threading.TrueParallelExecutionImpl$2.call(TrueParallelExecutionImpl.java:86) [2022-03-24 15:16:37,358] [Upsource Frontend Error] at __. project_talk-ui-backoffice .__.call(JavaGeneratorTemplate.java:39) [2022-03-24 15:16:37,358] [Upsource Frontend Error] at com.jetbrains.upsource.common.NamedFrameUtil.withProject(NamedFrameUtil.java:27) [2022-03-24 15:16:37,358] [Upsource Frontend Error] at com.jetbrains.upsource.backend.cli.vcs.service.VcsServiceConnections$2.lambda$wrapMappingTask$0(VcsServiceConnections.java:73) [2022-03-24 15:16:37,358] [Upsource Frontend Error] at java.util.concurrent.FutureTask.run(FutureTask.java:266) [2022-03-24 15:16:37,358] [Upsource Frontend Error] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [2022-03-24 15:16:37,358] [Upsource Frontend Error] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [2022-03-24 15:16:37,358] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.threading.TrueParallelExecutionImpl$1$1.run(TrueParallelExecutionImpl.java:51) [2022-03-24 15:16:37,358] [Upsource Frontend Error] ... 1 more [2022-03-24 15:16:37,358] [Upsource Frontend Error] Caused by: jetbrains.vcs.server.api.VcsServiceException: Failed to collect commits graph for talk-ui-backoffice:. jetbrains.buildServer.vcs.VcsException [2022-03-24 15:16:37,358] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.worker.VcsGraphSource.fetchCommits(VcsGraphSource.java:37) [2022-03-24 15:16:37,358] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.mapping.MappingCommitsGraphFactory.buildGraph(MappingCommitsGraphFactory.java:70) [2022-03-24 15:16:37,359] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.incremental.CachingCommitGraphFactory.buildGraph(CachingCommitGraphFactory.java:55) [2022-03-24 15:16:37,359] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.global.CompositeGraphFactory$1.buildGraph(CompositeGraphFactory.java:85) [2022-03-24 15:16:37,359] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.global.CompositeGraphBuilder.lambda$loadGraphs$0(CompositeGraphBuilder.java:110) [2022-03-24 15:16:37,359] [Upsource Frontend Error] ... 9 more [2022-03-24 15:16:37,359] [Upsource Frontend Error] Caused by: jetbrains.buildServer.vcs.VcsException: jetbrains.buildServer.vcs.VcsException [2022-03-24 15:16:37,359] [Upsource Frontend Error] at jetbrains.buildServer.buildTriggers.vcs.git.commitInfo.GitCommitsInfoBuilder.lambda$collectCommits$0(GitCommitsInfoBuilder.java:66) [2022-03-24 15:16:37,359] [Upsource Frontend Error] at jetbrains.buildServer.buildTriggers.vcs.git.RepositoryManagerImpl.runWithDisabledRemove(RepositoryManagerImpl.java:268) [2022-03-24 15:16:37,359] [Upsource Frontend Error] at jetbrains.buildServer.buildTriggers.vcs.git.commitInfo.GitCommitsInfoBuilder.collectCommits(GitCommitsInfoBuilder.java:59) [2022-03-24 15:16:37,359] [Upsource Frontend Error] at jetbrains.vcs.api.services.collectChanges.CommitsInfoServiceProvider$1.collectCommits(CommitsInfoServiceProvider.java:33) [2022-03-24 15:16:37,359] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.worker.VcsGraphSource.fetchCommits(VcsGraphSource.java:33) [2022-03-24 15:16:37,359] [Upsource Frontend Error] ... 13 more [2022-03-24 15:16:37,359] [Upsource Frontend Error] Caused by: jetbrains.buildServer.vcs.VcsException [2022-03-24 15:16:37,359] [Upsource Frontend Error] at jetbrains.buildServer.buildTriggers.vcs.git.GitCollectChangesPolicy.fetchAllRefs(GitCollectChangesPolicy.java:143) [2022-03-24 15:16:37,359] [Upsource Frontend Error] at jetbrains.buildServer.buildTriggers.vcs.git.GitFetchService.fetchRepositoryImpl(GitFetchService.java:59) [2022-03-24 15:16:37,359] [Upsource Frontend Error] at jetbrains.buildServer.buildTriggers.vcs.git.GitFetchService.getOrCreateRepositoryState(GitFetchService.java:72) [2022-03-24 15:16:37,359] [Upsource Frontend Error] at jetbrains.buildServer.buildTriggers.vcs.git.commitInfo.GitCommitsInfoBuilder.lambda$collectCommits$0(GitCommitsInfoBuilder.java:62) [2022-03-24 15:16:37,359] [Upsource Frontend Error] ... 17 more [2022-03-24 15:16:37,360] [Upsource Frontend Error] Caused by: java.lang.NegativeArraySizeException [2022-03-24 15:16:37,360] [Upsource Frontend Error] at org.eclipse.jgit.internal.storage.file.PackIndexV1.&lt;init&gt;(PackIndexV1.java:96) [2022-03-24 15:16:37,360] [Upsource Frontend Error] at org.eclipse.jgit.internal.storage.file.PackIndex$PackIndexFactory.read(PackIndex.java:436) [2022-03-24 15:16:37,360] [Upsource Frontend Error] at org.eclipse.jgit.internal.storage.file.PackIndex$PackIndexFactory.open(PackIndex.java:391) [2022-03-24 15:16:37,360] [Upsource Frontend Error] at org.eclipse.jgit.internal.storage.file.PackFile.idx(PackFile.java:170) [2022-03-24 15:16:37,360] [Upsource Frontend Error] at org.eclipse.jgit.internal.storage.file.PackFile.get(PackFile.java:258) [2022-03-24 15:16:37,360] [Upsource Frontend Error] at org.eclipse.jgit.internal.storage.file.ObjectDirectory.openPackedObject(ObjectDirectory.java:417) [2022-03-24 15:16:37,360] [Upsource Frontend Error] at org.eclipse.jgit.internal.storage.file.ObjectDirectory.openPackedFromSelfOrAlternate(ObjectDirectory.java:386) [2022-03-24 15:16:37,360] [Upsource Frontend Error] at org.eclipse.jgit.internal.storage.file.ObjectDirectory.openObject(ObjectDirectory.java:378) [2022-03-24 15:16:37,360] [Upsource Frontend Error] at org.eclipse.jgit.internal.storage.file.WindowCursor.open(WindowCursor.java:145) [2022-03-24 15:16:37,360] [Upsource Frontend Error] at org.eclipse.jgit.lib.ObjectReader.open(ObjectReader.java:229) [2022-03-24 15:16:37,360] [Upsource Frontend Error] at org.eclipse.jgit.revwalk.RevWalk.parseAny(RevWalk.java:840) [2022-03-24 15:16:37,360] [Upsource Frontend Error] at org.eclipse.jgit.transport.FetchProcess.askForIsComplete(FetchProcess.java:344) [2022-03-24 15:16:37,360] [Upsource Frontend Error] at org.eclipse.jgit.transport.FetchProcess.executeImp(FetchProcess.java:159) [2022-03-24 15:16:37,360] [Upsource Frontend Error] at org.eclipse.jgit.transport.FetchProcess.execute(FetchProcess.java:122) [2022-03-24 15:16:37,360] [Upsource Frontend Error] at org.eclipse.jgit.transport.Transport.fetch(Transport.java:1138) [2022-03-24 15:16:37,360] [Upsource Frontend Error] at jetbrains.buildServer.buildTriggers.vcs.git.GitServerUtil.fetch(GitServerUtil.java:522) [2022-03-24 15:16:37,361] [Upsource Frontend Error] at jetbrains.buildServer.buildTriggers.vcs.git.FetchCommandImpl.fetchInSameProcess(FetchCommandImpl.java:290) [2022-03-24 15:16:37,361] [Upsource Frontend Error] at jetbrains.buildServer.buildTriggers.vcs.git.FetchCommandImpl.fetch(FetchCommandImpl.java:88) [2022-03-24 15:16:37,361] [Upsource Frontend Error] at jetbrains.buildServer.buildTriggers.vcs.git.CommitLoaderImpl.fetch(CommitLoaderImpl.java:108) [2022-03-24 15:16:37,361] [Upsource Frontend Error] at jetbrains.buildServer.buildTriggers.vcs.git.GitCollectChangesPolicy$FetchAllRefs.fetchTrackedRefs(GitCollectChangesPolicy.java:268) [2022-03-24 15:16:37,361] [Upsource Frontend Error] at jetbrains.buildServer.buildTriggers.vcs.git.GitCollectChangesPolicy.fetchAllRefs(GitCollectChangesPolicy.java:140) [2022-03-24 15:16:37,361] [Upsource Frontend Error] ... 20 more ... 38 more [2022-03-24 15:20:37,732] [Upsource Frontend Error] [2022-03-24 15:20:37,727] WARN VcsService-7 k-ui-backoffice h.global.CompositeGraphBuilder - Failed to construct mounted graph for talk-ui-backoffice:. Failed to collect commits graph for talk-ui-backoffice:. jetbrains.buildServer.vcs.VcsException [2022-03-24 15:20:37,732] [Upsource Frontend Error] jetbrains.vcs.server.api.VcsServiceException: Failed to collect commits graph for talk-ui-backoffice:. jetbrains.buildServer.vcs.VcsException [2022-03-24 15:20:37,732] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.worker.VcsGraphSource.fetchCommits(VcsGraphSource.java:37) [2022-03-24 15:20:37,732] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.mapping.MappingCommitsGraphFactory.buildGraph(MappingCommitsGraphFactory.java:70) [2022-03-24 15:20:37,732] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.incremental.CachingCommitGraphFactory.buildGraph(CachingCommitGraphFactory.java:55) [2022-03-24 15:20:37,732] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.global.CompositeGraphFactory$1.buildGraph(CompositeGraphFactory.java:85) [2022-03-24 15:20:37,732] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.graph.global.CompositeGraphBuilder.lambda$loadGraphs$0(CompositeGraphBuilder.java:110) [2022-03-24 15:20:37,733] [Upsource Frontend Error] at jetbrains.vcs.server.core.impl.threading.TrueParallelExecutionImpl$2.call(TrueParallelExecutionImpl.java:86) [2022-03-24 15:20:37,733] [Upsource Frontend Error] at __. project_talk-ui-backoffice .__.call(JavaGeneratorTemplate.java:39) [2022-03-24 15:20:37,733] [Upsource Frontend Error] at com.jetbrains.upsource.common.NamedFrameUtil.withProject(NamedFrameUtil.java:27) [2022-03-24 15:20:37,733] [Upsource Frontend Error] at com.jetbrains.upsource.backend.cli.vcs.service.VcsServiceConnection . ",
    "url": "http://localhost:4000/docs/errors/upsource1/#problem",
    "relUrl": "/docs/errors/upsource1/#problem"
  },"386": {
    "doc": "jetbrains.vcs.server.api.VcsServiceException Failed to construct commits graph for...",
    "title": "solution",
    "content": "원인은 temp하위의 일부 파일이 서비스를 올린 계정과 달라서 접근할 수 없어서 동기화가 안되었던것 . /home/upsource/upsource-2020.1.1802/temp/upsource-frontend/vcs-service/caches/plugins/git . | ./upsource.sh stop | . 그래서 서비스 내리고 . | rm -rf * /home/upsource/upsource-2020.1.1802/temp | . temp폴더에 있는 파일들 모두 삭제하고 . | ./upsource.sh start | . 다시 재기동하니 solved~ . ",
    "url": "http://localhost:4000/docs/errors/upsource1/#solution",
    "relUrl": "/docs/errors/upsource1/#solution"
  },"387": {
    "doc": "jetbrains.vcs.server.api.VcsServiceException Failed to construct commits graph for...",
    "title": "jetbrains.vcs.server.api.VcsServiceException Failed to construct commits graph for...",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/upsource1/",
    "relUrl": "/docs/errors/upsource1/"
  },"388": {
    "doc": "upsource ReviewNotFoundException",
    "title": "problem",
    "content": ". #my라고 검색하면 서버에 이렇게 에러가 발생한다. com.jetbrains.upsource.backend.server.comments.db.ReviewNotFoundException: Review talk-api-mocha#675 not found at com.jetbrains.upsource.backend.server.comments.db.CrossProjectReviewsTable.getReview(ReviewsTable.kt:224) at com.jetbrains.upsource.backend.server.comments.db.CrossProjectReviewsTable$getReview$1.invokeSuspend(ReviewsTable.kt) at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:32) at kotlinx.coroutines.DispatchedTask.run(Dispatched.kt:236) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at com.jetbrains.upsource.util.NamedDaemonThreadFactory.a(NamedDaemonThreadFactory.java:34) . ",
    "url": "http://localhost:4000/docs/errors/upsource_reviewNotFoundException/#problem",
    "relUrl": "/docs/errors/upsource_reviewNotFoundException/#problem"
  },"389": {
    "doc": "upsource ReviewNotFoundException",
    "title": "cause",
    "content": "upsource가 설치된 서버를 이전하면서 . 이전에 마무리 되지 못한 review가 남아있었던 상태에서 백업파일로 덮어서 발생하는 것 같다. ",
    "url": "http://localhost:4000/docs/errors/upsource_reviewNotFoundException/#cause",
    "relUrl": "/docs/errors/upsource_reviewNotFoundException/#cause"
  },"390": {
    "doc": "upsource ReviewNotFoundException",
    "title": "solution",
    "content": "기존 계정을 삭제하고 새 계정을 생성해서 하면 된다. 만약에 진행 중이던 리뷰가 있었다면, 새 계정으로 새로 연결! . ",
    "url": "http://localhost:4000/docs/errors/upsource_reviewNotFoundException/#solution",
    "relUrl": "/docs/errors/upsource_reviewNotFoundException/#solution"
  },"391": {
    "doc": "upsource ReviewNotFoundException",
    "title": "upsource ReviewNotFoundException",
    "content": " ",
    "url": "http://localhost:4000/docs/errors/upsource_reviewNotFoundException/",
    "relUrl": "/docs/errors/upsource_reviewNotFoundException/"
  },"392": {
    "doc": "upsource resource제한",
    "title": "Project Add",
    "content": ". Project 메뉴에서 + 버튼을 통해 프로젝트를 추가합니다. Project화면에 등록한 프로젝트가 보이고, 우측에 설정 아이콘을 선택합니다. Project &gt; Settings . [Move resource here…] 버튼을 클릭해서, user별로 제한할 프로젝트들을 추가합니다. Project &gt; Access . 프로젝트에 설정한 리소스들에 접근할 group이나 role을 지정해줍니다. [Grant role..] 버튼을 클릭하면, Role, user, group을 선택할 수 있습니다. Role별로 업소스 기능 사용을 제한할 수 있습니다. roles메뉴에 가면 Hub 또는 Upsource 어플리케이션별 기능 제한을 할 수 있습니다. 저는 일반 개발자 user에는 코드리뷰 기능외에는 모두 막았습니다. 업소스 사업을 접으면서, 버그에 대한 조치는 이제 없을 듯합니다. 백업을 잘하고, 백업으로 롤백하는 것이 최선일 듯합니다. 오픈소스로 해주면 좋을꺼 같아요 . 여러가지 커스터마이징하고 싶은 기능도 있고, 수정하고 싶은 버그도 많은 것 같고.. 특히 카산드라는 장애가 많이 발생하네요. 암튼 저렇게 설정하고 일반 개발자 계정으로 로그인한 화면입니다. 전체 프로젝트가 150개 정도 되는데요. user가 속한 role에 연결된 프로젝트들만 보이고 있습니다. ",
    "url": "http://localhost:4000/docs/etc/upsource_setting/#project-add",
    "relUrl": "/docs/etc/upsource_setting/#project-add"
  },"393": {
    "doc": "upsource resource제한",
    "title": "upsource resource제한",
    "content": "회사에 외주인력도 투입되면서, 리소스 접근제한이 필요하게 되었습니다. 구글에서 업소스 리소스 제한하는 방법을 찾아봤는데요, . 못찾아서, role과 group과 project단위로 user의 권한을 제한하는 방법으로 설정했습니다. ",
    "url": "http://localhost:4000/docs/etc/upsource_setting/",
    "relUrl": "/docs/etc/upsource_setting/"
  },"394": {
    "doc": "vuejs-2-the-complete-guide 후기",
    "title": "강의 URL",
    "content": "https://www.udemy.com/course/vuejs-2-the-complete-guide/ . ",
    "url": "http://localhost:4000/docs/mooc/udemy/vuejs/#%EA%B0%95%EC%9D%98-url",
    "relUrl": "/docs/mooc/udemy/vuejs/#강의-url"
  },"395": {
    "doc": "vuejs-2-the-complete-guide 후기",
    "title": "학습 툴",
    "content": ". | visual studio code | . ",
    "url": "http://localhost:4000/docs/mooc/udemy/vuejs/#%ED%95%99%EC%8A%B5-%ED%88%B4",
    "relUrl": "/docs/mooc/udemy/vuejs/#학습-툴"
  },"396": {
    "doc": "vuejs-2-the-complete-guide 후기",
    "title": "강의 구성",
    "content": ". | 총 670강의로 49시간 정도 소요. | vuejs버전이 올라갔을 때 강의가 업데이트 된다. | 강의 하나당 최소 1분에서 최대 15분 안팍으로 짧게 나눠져 있어서 수강하기 수월 | 강좌마다 기본 프로젝트가 첨부되어 있고, 강의 내용 들으면서 해당 프로젝트에 코딩을 하면 된다. | 과제 : 건너뛰기가 가능하지만, 과제를 통해서 복습이 가능. | . 세션 1 ~ 세션 5 : Vuejs의 기본 . 세션 6 ~ 세션 9 : 컴포넌트 학습 . 세션 10 : 이제까지 배운 것으로 미니프로젝트 구성학습 . 세션 11 : 폼 학습 . 세션 12 : Http Request호출 . 세션 13 : 라우팅 학습 . 세션 14 : Animations &amp; Transitions . 세션 15 : Vuex 학습 . 세션 16 : Web app 프로젝트 구성 학습 . 세션 17 ~ 세션 44 : 기타 프로젝트에 필요한 학습 . ",
    "url": "http://localhost:4000/docs/mooc/udemy/vuejs/#%EA%B0%95%EC%9D%98-%EA%B5%AC%EC%84%B1",
    "relUrl": "/docs/mooc/udemy/vuejs/#강의-구성"
  },"397": {
    "doc": "vuejs-2-the-complete-guide 후기",
    "title": "선수 학습 조건",
    "content": ". | 기본 javascript 지식 필요 | ES6도 알아야하지만 필수는 아님. —&gt; 학습에 지장없음. | 기본 Html 및 CSS에 대해서 설명하지 않기때문에, 기본적인 것은 알고 있어야 한다. | . ",
    "url": "http://localhost:4000/docs/mooc/udemy/vuejs/#%EC%84%A0%EC%88%98-%ED%95%99%EC%8A%B5-%EC%A1%B0%EA%B1%B4",
    "relUrl": "/docs/mooc/udemy/vuejs/#선수-학습-조건"
  },"398": {
    "doc": "vuejs-2-the-complete-guide 후기",
    "title": "언어 지원",
    "content": "영어로 진행되는 수업으로 한글 자막은 없고 영어 및 유럽권 자막이 있다. 강사님 말투가 빠른 편이 아니여서, 충분히 이해하고 따라가기에 어렵지 않음. ",
    "url": "http://localhost:4000/docs/mooc/udemy/vuejs/#%EC%96%B8%EC%96%B4-%EC%A7%80%EC%9B%90",
    "relUrl": "/docs/mooc/udemy/vuejs/#언어-지원"
  },"399": {
    "doc": "vuejs-2-the-complete-guide 후기",
    "title": "학습 후기",
    "content": ". | 평일에는 1~2강의 정도 수강하고 있어서, 아직 세션10 ㅎ | 기초부터 실전까지 활용가능한 내용으로 잘 구성되어있는 것 같다. | 강의 속도도 빠르지 않고, Vuejs를 처음 접한 사람에게는 좋은 강의!! | 강의를 다 듣고 프로젝트에 바로 투입도 가능해보인다! | . ",
    "url": "http://localhost:4000/docs/mooc/udemy/vuejs/#%ED%95%99%EC%8A%B5-%ED%9B%84%EA%B8%B0",
    "relUrl": "/docs/mooc/udemy/vuejs/#학습-후기"
  },"400": {
    "doc": "vuejs-2-the-complete-guide 후기",
    "title": "학습 요약",
    "content": "1.75x 정주행 요약 . ",
    "url": "http://localhost:4000/docs/mooc/udemy/vuejs/#%ED%95%99%EC%8A%B5-%EC%9A%94%EC%95%BD",
    "relUrl": "/docs/mooc/udemy/vuejs/#학습-요약"
  },"401": {
    "doc": "vuejs-2-the-complete-guide 후기",
    "title": "vuejs-2-the-complete-guide 후기",
    "content": " ",
    "url": "http://localhost:4000/docs/mooc/udemy/vuejs/",
    "relUrl": "/docs/mooc/udemy/vuejs/"
  },"402": {
    "doc": "1.75x 정주행 요약",
    "title": "1.75x 정주행 요약",
    "content": " ",
    "url": "http://localhost:4000/docs/mooc/udemy/vuejs_sub/",
    "relUrl": "/docs/mooc/udemy/vuejs_sub/"
  },"403": {
    "doc": "웹API 디자인",
    "title": "웹API 디자인",
    "content": "API 설계시 꼭 체크해보기 . | 사용자를 위한 API 디자인하기 2.3.5 API 목표 캔버스 . | 누가 - API를 사용하는 사용자들을 나열 | 무엇을 - API로 사용자들이 할 수 있는 것을 나열 | 어떻게 - 무엇을 단계별로 분해해 나열 | 입력(원천) - 각 단계를 진행하기 위해 필요한 요소들과 그것들의 원천을 나열(누락된 누가, 무엇을 또는 어떻게를 찾기 위함) | 출력(사용처) - 각 단계의 반환과 그 쓰임새를 나열(누락된 누가, 무엇 또는 어떻게를 찾기 위함) | 목표 - 명시적이고 간결하게 각각의 어떻게 + 입력 + 출력을 재구성 | . | 기존 API를 변경할 때 . | 브레이킹 체인지가 일어나지 않도록해야한다. | . | . ",
    "url": "http://localhost:4000/docs/clipping/java/webapi/",
    "relUrl": "/docs/clipping/java/webapi/"
  },"404": {
    "doc": "webpage 스크랩핑 후 갱신여부 체크하는 어플리케이션 개발",
    "title": "요건",
    "content": "서드파티 api 페이지의 버전이 안올라가도 가끔 변경되고 있음. 이력을 알 수 없어서 . 스크랩핑해서 변경된 이력을 일단위로 체크하는 것 필요 . ",
    "url": "http://localhost:4000/docs/etc/webpage_scrapping/#%EC%9A%94%EA%B1%B4",
    "relUrl": "/docs/etc/webpage_scrapping/#요건"
  },"405": {
    "doc": "webpage 스크랩핑 후 갱신여부 체크하는 어플리케이션 개발",
    "title": "기술검토",
    "content": "Web Scraping vs Web Crawling . https://stackhoarder.com/2019/08/18/python부터-web-scraping-까지-최단-시간에-익혀보자/ . ",
    "url": "http://localhost:4000/docs/etc/webpage_scrapping/#%EA%B8%B0%EC%88%A0%EA%B2%80%ED%86%A0",
    "relUrl": "/docs/etc/webpage_scrapping/#기술검토"
  },"406": {
    "doc": "webpage 스크랩핑 후 갱신여부 체크하는 어플리케이션 개발",
    "title": "webpage 스크랩핑 후 갱신여부 체크하는 어플리케이션 개발",
    "content": " ",
    "url": "http://localhost:4000/docs/etc/webpage_scrapping/",
    "relUrl": "/docs/etc/webpage_scrapping/"
  },"407": {
    "doc": "WebSocket connection error - nginx",
    "title": "WebSocket connection error - nginx",
    "content": "problem . nginx를 통해서 ui와 api간 ws통신하는데, . 개발자 도구에서 아래와 같은 에러메시지가 계속 발생하고 401 오류가 난다. error . WebSocket connection to 'ws:127.0.0.1:9091/websocket/112/gfwerwer/websocket?access_token=asdasdasdasda' failed: . cause . 웹소켓 통신을 하려면 헤더에 이 패킷이 upgrade될 패킷임을 웹서버가 알수 있도록 설정이 필요한대 . 그게 nginx.conf에 누락되어 있었음 . 그래서 바꾼 nginx.conf . [nginx.conf] server { listen 9091; location ~ /websocket/[0-9]+/ { proxy_pass http://localhost:9092; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"Upgrade\"; } location / { proxy_pass http://localhost:9092; } } . reference . nginx 에서 WebSocket Proxy 설정하기 . ",
    "url": "http://localhost:4000/docs/etc/websocket_connection_error/",
    "relUrl": "/docs/etc/websocket_connection_error/"
  },"408": {
    "doc": "우아한 CRUD - Spring Data JDBC Advanced",
    "title": "강의 주소",
    "content": "[우아한테크세미나] 200507 우아한CRUD by 정상혁&amp;이명현님 . github . https://github.com/mhyeon-lee/spring-data-sample-codes . ",
    "url": "http://localhost:4000/docs/mooc/youtube/woowahan_crud_jdbc_advanced/#%EA%B0%95%EC%9D%98-%EC%A3%BC%EC%86%8C",
    "relUrl": "/docs/mooc/youtube/woowahan_crud_jdbc_advanced/#강의-주소"
  },"409": {
    "doc": "우아한 CRUD - Spring Data JDBC Advanced",
    "title": "O/R Mapping",
    "content": ". | jpa와 차이점 . | @Value : jpa는 proxy로 만들어야하는데 @Value로 선언한 것들은 불변 final객체여서 이것들을 proxy로 만들수 없다. 반면 spring data jdbc는 proxy로 만들지 않기 때문에 가능하다. | @PersistenceConstructor . | jpa의 경우는 기본적으로 프록시로 만들기 때문에, Bean 객체에 @NoArgsConstructor를 필수로 붙이고 reflection을 사용해서 결과를 필드와 바인딩하는 방식인데, spring data jdbc는 그런방식을 선호하지 않는다 (final을 사용하지 않으려고 reflection을 쓰지도 았는다.) 그래서 PersistenceConstructor를 생성자에 붙이고 생성자를 통해서 객체를 구현할 수 있도록 하고 있다. 생성자가 하나면 안붙여도 되고, 생성자가 여러개 인 경우 붙여서 db를 통해 맵핑하는게 먼지 알려줘야한다. | . | . | 연관 관계 . | spring data jdbc는 entity 설계시 Aggregate 개념 적용을 하라고 말한다. 안그러면 사용하기 어려워진다. | AggregateRoot 하나에 Repository 하나로 구성 | OneToOne, OneToMany 지원 . | 하위 클래스를 맵핑하게 되는데, 그 엔티티들이 db상으로는 pk가 존재하지만, 객체 클래스에는 @id 를 선언하지 않아도 된다. (jpa와의 차이점) | . | ManytoOne, ManyToMany 미지원 . | Aggregate의 개념에 위배되므로 향후에도 지원하지 않을 것으로 보임 | . | 양방향 연관관계 매핑 금지 | Aggregate간의 관계는 Reference Id로 관리한다. | AggregateReferene로 타입지원 가능 | . | . | Embedded . | @Embeded를 jpa와 마찬가지로 지원하는데, 차이가 있다면, @Embedded.Nullable와 @Embedded.Empty가 있다. | . | Type Converter 설정 . | jdbc driver에서 지원하지 않는 타입들은 custom converter를 작성해야한다. | jpa처럼 특정 필드에 @Converter를 설정할 수 없기 때문에, 별도의 타입을 선언하고 해당 타입 전용 Converter를 등록해줘야한다. | . | DDL 관리 . | hibernate와 같은 자동 ddl생성기능은 없다. | 대신 liquibase나 flyway와 같은 schema관리 솔루션을 활용가능하다. | . | Spring Data R2DBC . | 연관관계나 Embedded 미지원 | . | . ",
    "url": "http://localhost:4000/docs/mooc/youtube/woowahan_crud_jdbc_advanced/#or-mapping",
    "relUrl": "/docs/mooc/youtube/woowahan_crud_jdbc_advanced/#or-mapping"
  },"410": {
    "doc": "우아한 CRUD - Spring Data JDBC Advanced",
    "title": "CRUD - Create",
    "content": ". | jpa의 @GeneratedValue 기능이 없기 때문에, 그냥 save호출하면 insert가 아니라 update가 실행된다. 그래서 insert를 해야한다고 하면 @id속성 값 존재여부로 update와 분기해야하는데 | auto_increment를 사용하지 않고, 직접 id값을 할당하는 경우는 아래 전략을 취해야한다. | Persistable인터페이스 구현 . | 필드하나를 생성해서 지금 실행하는게 insert인지 update인지를 분기하도록 한다. | jpa의 postPersist 비슷한 클래스를 생성해서 bean으로 등록한 후, insert실행된 이후에 위에서 선언한 필드의 값을 update가 되도록 값을 변경하는 인터페이스를 구현 | AfterSaveEvent 또는 AfterSaveCallback을 등록해서 insert후 값 변경 가능 | . | BeforeSaveEvent / BeforeSaveCallback 등록 . | save나 callback을 bean으로 등록하고 나서 insert나 update되기전에 callback이 실행되고, callback이 들어가기전에 id를 할당하고 그담에 callback실행시키게 하는 것 | . | @Version 사용 . | 2.0.0.RC2에 추가된 기능 | Optimistic Locking을 사용하기 위해서 쓴다. @Version 값이 0 또는 널이라면, @Id값이 존재해도 save실행시 insert 동작한다. | . | Insert 지원 CustomRepository 구현 . | spring data의 customRepository 확장해서 쓰는 방법을 활용하는 것 | . | . | Lifecycle Events vs. Entity Callbacks . | 다른 비즈니스를 처리하기 위한 Trigger는 Event를 사용하고, 영속 대상이 되는 Aggregate 객체의 속성을 조작할 때는 Callback을 사용한다. | . | 연관관계 Cascade . | AggregateRoot에서부터 연결되는 엔티디들에 다 적용된다. | OneToOne/ OneToMany 구분없이 동일한 순서로 insert실행된다. | . | . ",
    "url": "http://localhost:4000/docs/mooc/youtube/woowahan_crud_jdbc_advanced/#crud---create",
    "relUrl": "/docs/mooc/youtube/woowahan_crud_jdbc_advanced/#crud---create"
  },"411": {
    "doc": "우아한 CRUD - Spring Data JDBC Advanced",
    "title": "CRUD - Update",
    "content": ". | 순서 . | root부터 update하고, 연관관계를 가지는 하위를 다 삭제하고 다시 다 insert한다. | update root → delete all referenced → insert all referenced | . | 문제 . | 하위의 pk가 auto_increment라고 하면 id가 변경되니까 문제된다. 그래서 id 없이 하는 것이 좋다. | . | 동시 수정 데이터 유실 가능성 . | 현재 aggregate상태를 그대로 저장하기 때문에 데이터에 동시에 접근한 후 update하면, 데이터 유실 가능성이 있다. | . | Optimistic Locking (2.0.0.RC2) . | @Version을 지정하면 update구문의 where절에서 version matching을 한 후 결과를 체크한다. | . | Pessimistic Locking . | update를 수행하기 전에 for update로 조회하면, pessimistic locking을 걸수 있다. 이러면 동시 데이터 update로 인한 유실을 막을 수 있다. | . | 비효율 . | 연관관계를 모두 삭제하고 다시 넣기 때문에 비효율적인 측면이 있다. | 복잡한 연관관계 설계를 지양한다. | 일부 속성 변경할 땐 @Modifying을 사용할 수 있다. | 데이터 수정/삭제는 한 방향으로 진행되어야 경합 상황에서 dead lock발생을 줄일 수 있다. | . | . | . ",
    "url": "http://localhost:4000/docs/mooc/youtube/woowahan_crud_jdbc_advanced/#crud---update",
    "relUrl": "/docs/mooc/youtube/woowahan_crud_jdbc_advanced/#crud---update"
  },"412": {
    "doc": "우아한 CRUD - Spring Data JDBC Advanced",
    "title": "CRUD - Delete",
    "content": ". | Soft Delete . | hibernate에서는 @SQLDelete를 사용해서 Delete실행시 삭제 판별 Column을 update하는 soft delete를 구현할 수 있다. → 실제로 row를 삭제하는 것이 아니라 상태만 delete되었다고 데이터 update하는 것을 말한다. | . | . ",
    "url": "http://localhost:4000/docs/mooc/youtube/woowahan_crud_jdbc_advanced/#crud---delete",
    "relUrl": "/docs/mooc/youtube/woowahan_crud_jdbc_advanced/#crud---delete"
  },"413": {
    "doc": "우아한 CRUD - Spring Data JDBC Advanced",
    "title": "CRUD - Read",
    "content": ". | findById | n+1 fetch 문제있다. - entityrowmapper에 대해서 학습 후 다시 보자 | derived query . | findBy~~, countBy~ 로 할 수 있게 | 이것도 n+1문제 있음 | . | 복합View조회 . | 서비스가 고도화될수록 다양한 view제공 요구사항이 발생한다. | 복잡한 조회조건과 데이터를 도메인 모델(aggregate)에 녹이려고 노력하지 말아야 한다. | 도메인(비즈니스) 요구사항이 변경되면 View가 변경되는가? - 아니다. | View가 변경되면 도메인(비즈니스) 요구사항이 변경되는가? - 아니다. | . | 도메인(Command) 요구사항과 조회(Query)요구사항은 다뤄야 하는 범위가 다르다 | 서로 다른 논리를 합치면 복잡도는 N+N이 아니라 N*N이상이 된다. | 시스템이 고도화 될 수록 새로운 비즈니스 요구사항 수용과 확장에 어려움을 겪게 된다 | 그래서 별도의 쿼리 모델을 만들어야 한다 → CQRS . | Presentation Model을 Domain Model에서 분리한다. | Spring JDBC를 사용한다 | 다양하고 복잡한 조회 요구사항 수용과 최적화를 위한 SQL튜닝이 가능해야 한다 | SQL작성이 조금 간편했음 좋겠다 | Spring Data Jdbc의 객체-컬럼 매핑은 활용하고 싶다. | Query Model은 불변 객체(Immutable Obejct)로 만들고 싶다 | N+1 Fetch로 1:N 구조의 조회 모델에는 Spring Data Jdbc의 ENtityRowMapper를 활용하기 어렵다 | naver에서 이걸 해결하기 위한 라이브러리 작성 (spring jdbc plus) . | https://github.com/naver/spring-jdbc-plus | spring data jdbc의 객체-컬럼 매핑 활용 | 매핑을 활용한 select statements작성 지원 | 개선된 sqlParameterSource 제공 | 1:N조회 결과 매핑을 지원하는 AggregateResultSetExtractor제공 | . | . | . | . ",
    "url": "http://localhost:4000/docs/mooc/youtube/woowahan_crud_jdbc_advanced/#crud---read",
    "relUrl": "/docs/mooc/youtube/woowahan_crud_jdbc_advanced/#crud---read"
  },"414": {
    "doc": "우아한 CRUD - Spring Data JDBC Advanced",
    "title": "우아한 CRUD - Spring Data JDBC Advanced",
    "content": " ",
    "url": "http://localhost:4000/docs/mooc/youtube/woowahan_crud_jdbc_advanced/",
    "relUrl": "/docs/mooc/youtube/woowahan_crud_jdbc_advanced/"
  },"415": {
    "doc": "우아한 CRUD - 퍼시스턴스 프레임워크 정리",
    "title": "강의 주소",
    "content": "[우아한테크세미나] 200507 우아한CRUD by 정상혁&amp;이명현님 . ",
    "url": "http://localhost:4000/docs/mooc/youtube/woowahan_crud_persistence/#%EA%B0%95%EC%9D%98-%EC%A3%BC%EC%86%8C",
    "relUrl": "/docs/mooc/youtube/woowahan_crud_persistence/#강의-주소"
  },"416": {
    "doc": "우아한 CRUD - 퍼시스턴스 프레임워크 정리",
    "title": "model1",
    "content": ". | 우리가 흔히 과거에 했던 jsp에 sql까지 다 있던 코드패턴 | smart ui패턴이라고도 한다(ddd 에릭에반스) | . ",
    "url": "http://localhost:4000/docs/mooc/youtube/woowahan_crud_persistence/#model1",
    "relUrl": "/docs/mooc/youtube/woowahan_crud_persistence/#model1"
  },"417": {
    "doc": "우아한 CRUD - 퍼시스턴스 프레임워크 정리",
    "title": "JPA",
    "content": ". | User*Account클래스를 보면 ORM사용 성숙도를 알 수 있다 | 부작용 . | 성능저하 . | 항상 연관된 객체를 다 조회한다면 불필요한 쿼리 실행 | N+1 쿼리 주의 | lazy loading을 쓰지않고 수동으로 값을 채울 때의 난관 . | 비슷한 메서드가 여러개 생길 수 있다. (find로 찾는 여러개의 메서드) | . | . | . | . ",
    "url": "http://localhost:4000/docs/mooc/youtube/woowahan_crud_persistence/#jpa",
    "relUrl": "/docs/mooc/youtube/woowahan_crud_persistence/#jpa"
  },"418": {
    "doc": "우아한 CRUD - 퍼시스턴스 프레임워크 정리",
    "title": "VO vs DTO",
    "content": ". | Value Object . | 값이 같으면 동일하다고 간주되는, 식별성 없는 작은 객체 | hibernate 매뉴얼의 Value Type도 Value Object를 포함한다고 생각됨 | DTO와 혼용해서 쓰여있다. | . | Data Transfer Object . | 원격 호출을 효율화하기 위해 나온 패턴 | . | . ",
    "url": "http://localhost:4000/docs/mooc/youtube/woowahan_crud_persistence/#vo-vs-dto",
    "relUrl": "/docs/mooc/youtube/woowahan_crud_persistence/#vo-vs-dto"
  },"419": {
    "doc": "우아한 CRUD - 퍼시스턴스 프레임워크 정리",
    "title": "Entity 감추기",
    "content": ". | 이유 . | entity가 뷰, API의 response에 바로 노출될 때의 비용이 발생 . | 캡슐화를 지키기 어려워진다 : 꼭 필요하지 않은 속성도 외부로 노출되어 향후 수정하기 어려워진다. | JSP, Freemarker에서의 객체 참조 . | 컴파일 시점의 검사 범위가 좁다 | jpa를 쓴다면 , OpenEntityManageInViewFilter를 고려해야한다. 예를 들어서 jsp에서 쿼리 호출할 경우 | . | JSON 응답시 . | JsonIgnore, JsonView 같은 선언이 많아지면, JSON형태만 보고 예측하는 난이도가 올라간다. | . | . | . | 해결 . | 외부 노출용 DTO를 따로 만들기 . | entity → dto 변환 로직은 컴파일 타임에 체크된다 | dto는 비교적 구조를 단순하게 가져갈 수 있다 (더 단순한 json응답 구조로) | dto변화는 외부 인터페이스로 의식해서 관리하는 범위가 된다. (예를 들어 swagger의 스펙으로 활용) | 여러 entity를 조합할 수 있는 여지가 생긴다. | . | . | . ",
    "url": "http://localhost:4000/docs/mooc/youtube/woowahan_crud_persistence/#entity-%EA%B0%90%EC%B6%94%EA%B8%B0",
    "relUrl": "/docs/mooc/youtube/woowahan_crud_persistence/#entity-감추기"
  },"420": {
    "doc": "우아한 CRUD - 퍼시스턴스 프레임워크 정리",
    "title": "Aggregate로 Entity 간의 선긋기",
    "content": ". | Aggregate는? . | 하나의 단위로 취급되는 연관된 객체군, 객체망 | entity와 vo의 묶음 | 엄격한 데이터 일관성, 제약사항이 유지되어야 하는 단위 | transaction, lock의 필수 범위 | 불변식이 적용되는 단위(데이터가 변경될 때마다 유지돼야 하는 규칙) | . | Aggregate 1개 당 repository 1개 . | Aggregate root를 통해서 aggregate밖에서 aggregate안의 객체로 접근한다. | Aggregate root로 저장 대상 타입을 표현하는 CrudRepository | . | Aggregate 경계가 있는 시스템 . | 별도의 저장소나 API서버를 분리할 때 상대적으로 유리 . | Aggregate밖은 eventual consistancy를 목표로 할 수 있다 | 여러 Aggregate의 변경은 Event, SAGA, TCC 등의 패턴을 활용할 수 있다 | . | Aggregate별로 Cache를 적용하기에 좋다 | 분리할 계획이 없더라도 코드를 고칠 때 영향성을 파악하기가 유리하다. | . | Aggregate 식별시 의식할 점 . | CUD + 단순(findById)에 집중 . | 모든 R( = read)를 다 포용하려고 한다면 깊은 객체 그래프가 나온다. | . | JPA를 쓴다면 Cascade를 써도 되는 범위인가?? . | cascade를 꼭 써야한다고 하면, entity의 경계가 잘못된건 아닌지 다시 생각해봐야하는 신호라고 봐야한다!! | . | . | . ",
    "url": "http://localhost:4000/docs/mooc/youtube/woowahan_crud_persistence/#aggregate%EB%A1%9C-entity-%EA%B0%84%EC%9D%98-%EC%84%A0%EA%B8%8B%EA%B8%B0",
    "relUrl": "/docs/mooc/youtube/woowahan_crud_persistence/#aggregate로-entity-간의-선긋기"
  },"421": {
    "doc": "우아한 CRUD - 퍼시스턴스 프레임워크 정리",
    "title": "Aggregate 간의 참조",
    "content": ". | 다른 Aggregate를 참조할때, 객체로 참조하지 않고 ID로만 참조하도록 한다. | Spring Data Jdbc의 AggregateReference도 같은 역할 | . ",
    "url": "http://localhost:4000/docs/mooc/youtube/woowahan_crud_persistence/#aggregate-%EA%B0%84%EC%9D%98-%EC%B0%B8%EC%A1%B0",
    "relUrl": "/docs/mooc/youtube/woowahan_crud_persistence/#aggregate-간의-참조"
  },"422": {
    "doc": "우아한 CRUD - 퍼시스턴스 프레임워크 정리",
    "title": "여러 Aggregate에 걸쳐 조회",
    "content": ". | Service레이어에서 여러개를 조합한다. | 쿼리 하나로 하면 비용이 적게 든다고 생각할 수 있지만, 여러 아이디를 findBy하면 DB성능에 더 유리할 수 있다. 각각의 쿼리가 더 단순하고 Application DB레벨의 캐시에 더 유리하다 | Join이 필수적인 경우 . | 예를 들어, where절에 다른 aggregate속성이 조건으로 들어가는 경우는 . | Repository에 조회조건 정도(findByCreatorEmail(String email)이렇게 추가하고 Service단에서 다시 조합하는 방법이 있다.. | . | . | select 결과까지 다른 aggregate의 속성을 포함할 경우 . | 맞춤형 전용 dto를 만드는 방법이 있다. 이러면 . | Aggregate를 단순하게 유지할 수 있고 | JPA의 경우: Persistent Context를 의식하지 않아도 된다. | . | . | . ",
    "url": "http://localhost:4000/docs/mooc/youtube/woowahan_crud_persistence/#%EC%97%AC%EB%9F%AC-aggregate%EC%97%90-%EA%B1%B8%EC%B3%90-%EC%A1%B0%ED%9A%8C",
    "relUrl": "/docs/mooc/youtube/woowahan_crud_persistence/#여러-aggregate에-걸쳐-조회"
  },"423": {
    "doc": "우아한 CRUD - 퍼시스턴스 프레임워크 정리",
    "title": "Repository vs DAO",
    "content": ". | Dao는 퍼시스턴스 레이어를 캡슐화 | ddd의 repository는 도메인 레이어에 객체 지향적인 컬렉션 관리 인터페이스를 제공 | Lazy Loading이 필요하다는 것은 모델링을 다시 생각해봐야한다는 신호일 수도 있다. | . ",
    "url": "http://localhost:4000/docs/mooc/youtube/woowahan_crud_persistence/#repository-vs-dao",
    "relUrl": "/docs/mooc/youtube/woowahan_crud_persistence/#repository-vs-dao"
  },"424": {
    "doc": "우아한 CRUD - 퍼시스턴스 프레임워크 정리",
    "title": "Immutable과 rich domain object",
    "content": ". | 캐시 부작용 사례 . | 캐시된 값을 findbyid로 가져와서, 객체의 상태를 바꿔버리는 것으로 의도치 않게 오류가 발생할 수 있다. | 사내에서 발생한 사례로 .. 아래처럼 코딩했을 때 캐시 변경이 일어났다고 한다. public static InternalApprovalReviewCdo from(ApprovalRequest approvalRequest, IdList essentialApproverIds) { IdList approverIds = approvalRequest.getApproverIds(); approverIds.addAll(essentialApproverIds); return new InternalApprovalReviewCdo( approverIds, approvalRequest.getCreatedAt(), approvalRequest.getDueDate() ); } . | from메서드의 인자 approvalRequest는 Repository에서 findBy로 리턴받은 캐시 객체인데, 라인3 에서 addAll하면 approvalRequest 저장된 값이 변경되는 것과 같은 사례인 것 같다. | . | immutable 객체의 장점 . | cache하기에 안전하다 | 다른 레이어에 메서드 파라미터로 보내도 값이 안 바뀌었다는 확신을 할 수 있다. | dto류가 여러 레이어를 오간다면 immutable하면 더 좋다. | . | Rich Domain Object . | Domain Object가 가진 속성과 연관된 행위 . | 해당 객체에 있는 것이 책임이 자연스럽다(information expert패턴) | 데이터 중심에서 책임 중심의 설계로 진화할 수 있다. | . | 상태를 바꾸는 메서드가 포함될 수 있다 . | 상태를 바꿀 때의 정합성 검사를 포함 | Domain event 추가(Spring Data의 AbstractAggregateRoot)로 해볼 수 있다. | . | Immutable이 아니게 될 수 있다 | 영속화될 Domain Object라면 상태를 바꾸는건 시스템의 상태를 바꾸는 경우에 한해야한다. | 메서드명도 그 행위를 잘 들어내어야 한다(setTitle() → changeTitle()) | . | . | . ",
    "url": "http://localhost:4000/docs/mooc/youtube/woowahan_crud_persistence/#immutable%EA%B3%BC-rich-domain-object",
    "relUrl": "/docs/mooc/youtube/woowahan_crud_persistence/#immutable과-rich-domain-object"
  },"425": {
    "doc": "우아한 CRUD - 퍼시스턴스 프레임워크 정리",
    "title": "실무 사례",
    "content": ". | 복합조회 API를 통해 화면을 만들어야 하는 경우 . | 복잡한 쿼리를 담당하는 API서버 분리 개발 (read를 담당하는) | Aggregate경계를 넘어서는 복잡한 조회이기 때문에 Repository가 아닌 Dao개념으로 접근하고 | Native Sql 중심의 개발로 - 쿼리 힌트, 최적화를 위해 복잡한 형태의 쿼리가 들어가게 됨 | Spring jdbc+ Spring data jdbc의 일부 기능 사용 . | jpa dialect가 없는 자체 분산 DB(NBase-T)사용 | jpa를 쓸 수 있다고 해도 적용의 이득이 없는 상황 | . | . | . ",
    "url": "http://localhost:4000/docs/mooc/youtube/woowahan_crud_persistence/#%EC%8B%A4%EB%AC%B4-%EC%82%AC%EB%A1%80",
    "relUrl": "/docs/mooc/youtube/woowahan_crud_persistence/#실무-사례"
  },"426": {
    "doc": "우아한 CRUD - 퍼시스턴스 프레임워크 정리",
    "title": "결론",
    "content": ". | Aggregate | 객체지향 설계는 (j2ee나 자바같은) 특정 구현 기술보다 더 중요하다(로드 존슨) . | entity 설계는 (jpa나 spring jdbc같은) 특정 구현기술 보다 더 중요하다 | . | . ",
    "url": "http://localhost:4000/docs/mooc/youtube/woowahan_crud_persistence/#%EA%B2%B0%EB%A1%A0",
    "relUrl": "/docs/mooc/youtube/woowahan_crud_persistence/#결론"
  },"427": {
    "doc": "우아한 CRUD - 퍼시스턴스 프레임워크 정리",
    "title": "우아한 CRUD - 퍼시스턴스 프레임워크 정리",
    "content": " ",
    "url": "http://localhost:4000/docs/mooc/youtube/woowahan_crud_persistence/",
    "relUrl": "/docs/mooc/youtube/woowahan_crud_persistence/"
  },"428": {
    "doc": "Youtube",
    "title": "Youtube",
    "content": " ",
    "url": "http://localhost:4000/docs/mooc/youtube/youtube/",
    "relUrl": "/docs/mooc/youtube/youtube/"
  },"429": {
    "doc": "zuul routes 404 not found error",
    "title": "요구사항",
    "content": "웹/모바일 프론트에서 호출하는 백엔드API는 test서비스의 rest로 시작하는 API로만 접근하도록 한다. https://stackoverflow.com/questions/12569308/spring-difference-of-and-with-regards-to-paths . eureka에 등록된 serviceId를 test라고 했을 때 . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/zuul_route_not_found/#%EC%9A%94%EA%B5%AC%EC%82%AC%ED%95%AD",
    "relUrl": "/docs/msa/spring-cloud/zuul_route_not_found/#요구사항"
  },"430": {
    "doc": "zuul routes 404 not found error",
    "title": "AS-IS",
    "content": "기존에는 아래 설정으로 프론트엔드에서 http://localhost:8080/test/users라는 API를 호출했다면 . zuul: routes: test: path: /test/** . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/zuul_route_not_found/#as-is",
    "relUrl": "/docs/msa/spring-cloud/zuul_route_not_found/#as-is"
  },"431": {
    "doc": "zuul routes 404 not found error",
    "title": "TO-BE",
    "content": "http://localhost:8080/test/rest/users 처럼 특정 프론트에서 호출하는 API는 /rest하위의 리소스로만 접근하도록 해야한다. try.. zuul: routes: test: path: /test/rest/** . | 이렇게 변경하면, 일반 requestmapping의 경우는 동작하는데, pathVariable로 path에 변수가 들어가게 되면 404 not found 에러가 난다. | . @RequestMapping(\"rest/centers/{centerId}/receptions\") . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/zuul_route_not_found/#to-be",
    "relUrl": "/docs/msa/spring-cloud/zuul_route_not_found/#to-be"
  },"432": {
    "doc": "zuul routes 404 not found error",
    "title": "solution",
    "content": "zuul: routes: test: path: /rest/** . 이유는 알수 없지만, 뎁스로 체크가 안되는 것 같다. 관련 reference도 못찾았다. ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/zuul_route_not_found/#solution",
    "relUrl": "/docs/msa/spring-cloud/zuul_route_not_found/#solution"
  },"433": {
    "doc": "zuul routes 404 not found error",
    "title": "addition",
    "content": "사실 원하는 것은 restapi는 /test/rest/하위의 API로만 접근하도록 하고 싶었다. zuul에 routes를 추가하고 ignorePattern을 설정하는 것으론 불가능했다. (/test하위로 접근하면 안되고 /test/rest하위로만 접근되도록 하는 것) . 그래서 서비스에서 보안요건으로 authority를 체크하는 기능이 있었는데, 거기에 허용 path로 설정하는 방식으로 작업을 했다. 그래서 접근불가한 path는 403 에러로 뱉게 했다. (zuul의 ignorePattern이나 ignoreServices로 설정하면 404 에러로 되므로 403이 맞는 것 같다.) . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/zuul_route_not_found/#addition",
    "relUrl": "/docs/msa/spring-cloud/zuul_route_not_found/#addition"
  },"434": {
    "doc": "zuul routes 404 not found error",
    "title": "reference",
    "content": "https://cloud.spring.io/spring-cloud-netflix/multi/multi__router_and_filter_zuul.html . ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/zuul_route_not_found/#reference",
    "relUrl": "/docs/msa/spring-cloud/zuul_route_not_found/#reference"
  },"435": {
    "doc": "zuul routes 404 not found error",
    "title": "zuul routes 404 not found error",
    "content": " ",
    "url": "http://localhost:4000/docs/msa/spring-cloud/zuul_route_not_found/",
    "relUrl": "/docs/msa/spring-cloud/zuul_route_not_found/"
  }
}
